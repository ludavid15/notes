<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

 <title>Notes</title>
 <link href="https://ludavid15.github.io//atom.xml" rel="self"/>
 <link href="https://ludavid15.github.io//"/>
 <updated>2023-02-25T21:02:31-08:00</updated>
 <id>https://ludavid15.github.io/</id>
 <author>
   <name>David Lu</name>
   <email></email>
 </author>

 
 <entry>
   <title>Full Stack Development on AWS</title>
   <link href="https://ludavid15.github.io//fullStack/"/>
   <updated>2023-02-25T00:00:00-08:00</updated>
   <id>https://ludavid15.github.io//fullStack</id>
   <content type="html">&lt;p&gt;In the frontend post, we explored React and how to build a dynamic website with it. Now let’s focus on developing a full stack application, using React for the frontend, and AWS to support the backend.&lt;/p&gt;

&lt;h3 id=&quot;overview&quot;&gt;Overview&lt;/h3&gt;

&lt;p&gt;Lets begin by discussing the pieces of our project. There’s a lot of different tools required to make this whole thing work.&lt;/p&gt;

&lt;h4 id=&quot;1-react-code&quot;&gt;1. React Code&lt;/h4&gt;

&lt;p&gt;This is the javascript code that makes up the frontend. A bundling tool is usually used to turn the React code you write into the final scripts that your browser will run.&lt;/p&gt;

&lt;h4 id=&quot;2-aws-s3-bucket&quot;&gt;2. AWS S3 Bucket&lt;/h4&gt;

&lt;p&gt;This is a file hosting service that we’ll use to store our React Code. When a user tries to access our website, they’ll be sent the react code stored in S3 (technically actually the build version, not the source React scripts).&lt;/p&gt;

&lt;h4 id=&quot;3-aws-route-53&quot;&gt;3. AWS Route 53&lt;/h4&gt;

&lt;p&gt;This is a DNS service that connects the human readable domain name (e.g. www.coolwebsite.com), to the actual machine readable IP address (194.34.25445).&lt;/p&gt;

&lt;h4 id=&quot;4-aws-cloudfront&quot;&gt;4. AWS Cloudfront&lt;/h4&gt;

&lt;p&gt;This is an optional service, but recommended. Cloudfront is a content delivery network, which gives you more options and control in how users access your website. One feature that Cloudfront enables is HTTPS instead of HTTP (the S stands for secure).&lt;/p&gt;

&lt;h4 id=&quot;5-aws-dynamodb&quot;&gt;5. AWS DynamoDB&lt;/h4&gt;

&lt;p&gt;A noSQL database service. This is the primary repository for user data. Databases provide a nice way to manage and read from large datasets. The benefit of using an AWS database is that it is managed for us. All we have to take care of is our data structure.&lt;/p&gt;

&lt;h4 id=&quot;6-api&quot;&gt;6. API&lt;/h4&gt;

&lt;p&gt;Since we’re using a database service, we’ll need an API to fetch/write data from/to the database. In other words, it is like the doorway connecting our frontend to our backend. Our React frontend will use this API to connect a user’s interactions with data in our database. For this project, I’m going to use REST since I have a pretty basic application, but GraphQL is a popular alternative.&lt;/p&gt;

&lt;h4 id=&quot;7-aws-lambda&quot;&gt;7. AWS Lambda&lt;/h4&gt;

&lt;p&gt;This is an optional component. If we are only making simple read/write requests to our database, we can skip this. However, if we need complex functions, we can use AWS Lambda. AWS Lambda is a serverless compute service, which runs a function based on a trigger. This provides a nice way to code more complex processes.&lt;/p&gt;

&lt;p class=&quot;message&quot;&gt;
There&apos;s another AWS tool called AWS amplify which helps you quickly setup a website. It&apos;s worth noting that all it does is basically set up the aforementioned resources for you. In other words, it&apos;s not a fundamental service, but rather a tool to help setup other services. If you know what you&apos;re doing, this is a very handy tool, but if you&apos;re new I recommend building everything from scratch. This will help you learn and also avoid suprise fees. 
&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Frontend Development</title>
   <link href="https://ludavid15.github.io//frontend/"/>
   <updated>2023-01-29T00:00:00-08:00</updated>
   <id>https://ludavid15.github.io//frontend</id>
   <content type="html">&lt;p&gt;Join me as I document the things I learn while developing a custom application! I’m starting with a frontend, which is the code that is a user interface. The frontend connects the user (via buttons and pretty images) to the backend (the business logic).&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;1-html-and-css&quot;&gt;1. HTML and CSS&lt;/h2&gt;

&lt;p&gt;Underneath the hood all websites are coded using HTML and CSS. These are like the fundamental building blocks which tell your browser what to render and how to render it.&lt;/p&gt;

&lt;p&gt;But HTML and CSS are static. This means you can’t code things like a clock that updates in real time (but you could code a static clock). Luckily there’s Javascript. Javascript is a multi-purpose language which can create the illusion of a dynamic website.&lt;/p&gt;

&lt;p class=&quot;message&quot;&gt;
This website you&apos;re reading right now is a static website. Underneath the hood, it&apos;s just a bunch of HTML and CSS that gets rendered by your browser. I use a program called Jekyll, which is a content management system. It converts the content I write (which is in markdown) into a .html file. 
&lt;/p&gt;

&lt;h2 id=&quot;2-javascript-libraries&quot;&gt;2. Javascript Libraries&lt;/h2&gt;

&lt;p&gt;Javascript by itself is plenty powerful, but still many steps removed from the end product (the visual UI). In the same way that you would use something like TensorFlow instead of raw Python for machine learning, you’d likely use a JS library instead of raw JS for UI development. For my project, I’m using React. There’s also something called a JS framework, which is a bit different from a &lt;em&gt;library&lt;/em&gt;. Two popular JS frameworks are Angular and Vue.&lt;/p&gt;

&lt;h2 id=&quot;3-ui-design-tools&quot;&gt;3. UI Design Tools&lt;/h2&gt;

&lt;p&gt;Let’s step away from code and talk about UI as a visual design task. Questions like, what’s the right spacing? What’s the right color? Where should the navigation bar be? You could, and probably should, answer questions like this on a canvas. It’s a lot of work to code a visual element, and it’s all work that isn’t needed to answer these questions. For this kind of task there are vector design tools. Two popular ones are Adobe XD and Figma.&lt;/p&gt;

&lt;h2 id=&quot;4-features&quot;&gt;4. Features&lt;/h2&gt;

&lt;p&gt;Before jumping into React, I want to take a step back and think about the different types of features we could expect to see in a website, in a very generic sense.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Rendering Dynamic Values&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Unless you’re building a static website, you’ll have components that can change value depending on how your users are interacting with your site. For these kind of components, you’ll need to think about their state and their lifecycle.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Routing&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Chances are your website will have multiples pages (e.g. about, contact, products). You will need a system for re-directing users to and from these pages.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Queries&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Queries are requests from a server or database. For a query, you’ll need to handle making the external connection, saving the variable once you’ve acquired it, and dealing with any potential delays or errors along the way.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Writes&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Just like a query, you’ll need to transfer something from the local browser to an external server or database. Unique to a write request, you may need to consider how to save the user’s inputs, and how to handle re-directs after the write request is complete.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;5-setting-up-a-project&quot;&gt;5. Setting Up a Project&lt;/h2&gt;

&lt;h4 id=&quot;install-nodejs&quot;&gt;Install Node.js&lt;/h4&gt;

&lt;p&gt;Do it! It’s easy. Node is a javascript runtime. Normally, your browser can run javascript and for frontends this is the runtime we use. But, sometimes we might want to run js locally on our machine and not through a browser.&lt;/p&gt;

&lt;h4 id=&quot;package-manager&quot;&gt;Package Manager&lt;/h4&gt;

&lt;p&gt;Once you have Node.js, you’re gonna want a package manager. This is a tool to help you install, track, and manage libraries. For JS, you’ll probably want either NPM or YARN.&lt;/p&gt;

&lt;h4 id=&quot;bundlers&quot;&gt;Bundlers&lt;/h4&gt;

&lt;p&gt;Next, you’ll want to think about a bundler. A bundler takes the files you have written (with all their messy dependencies) and turns it into static assets for your browser to run. Most bundlers will also throw up a local server, allowing you to check out how your website actually renders without pushing to the internet. As of this writing, webpack is the most popular, but I’m using parcel, because it’s simpler.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Simpler how? Well there’s nothing to configure with parcel. You just write your .js and .html and .jsx files and then run parcel!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Install parcel with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;npm install -g parcel&lt;/code&gt; (the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-g&lt;/code&gt; is an option tag which tells npm to install as a global package).&lt;/p&gt;

&lt;p&gt;If you’re using parcel, I’ve found that your &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;index.html file&lt;/code&gt; needs this in the body section. Also, I place the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;index.html&lt;/code&gt; file into the /src/ folder.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;div id=&quot;root&quot;&amp;gt;&amp;lt;/div&amp;gt;
&amp;lt;script type=&quot;module&quot; src=&quot;./index.js&quot;&amp;gt;&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;components-of-a-react-project&quot;&gt;Components of a React Project&lt;/h3&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;package-lock.json&lt;/code&gt; records the exact version of each installed package which allows you to re-install them. Future installs will be able to build an identical dependency tree.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;package.json&lt;/code&gt; records the minimum version your app needs. If you update the versions of a particular package, the change is not going to be reflected here. If you’ve lost your node_modules folder somehow, you can call &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;npm install&lt;/code&gt; which will look at this .json file and install your dependencies.&lt;/p&gt;

&lt;p&gt;To create a package.json file, you can run &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;npm init -y&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;node_modules&lt;/code&gt; this stores all your project dependencies. For the most part, you won’t need to change anything in here.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;src&lt;/code&gt; this folder contains 99% of the files you’ll be working with. Here is where you will initialize your index.js, and create your React components.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;index.js&lt;/code&gt; this usually contains a simple section of code which just renders your &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;App.js&lt;/code&gt; component to your DOM, and then this gets placed into your &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;index.html&lt;/code&gt; file.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;index.css&lt;/code&gt; this is a .css file which provides all the styling for your project. A quirk about React is that different .css files are combined into a single file when you compile your code. This means that even if you create many components, they’ll all share the same css.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;App.js&lt;/code&gt; this is usually the &lt;em&gt;root&lt;/em&gt; component. It serves as the container which holds all your other components (maybe your navbars, your content, your sidebars, etc.). You can think of a React project as basically just a tree of components, all pointing back to your root, which is what gets rendered to the reactROM in your &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;index.js&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&quot;6-using-react&quot;&gt;6. Using React&lt;/h2&gt;

&lt;h3 id=&quot;jsx&quot;&gt;JSX&lt;/h3&gt;

&lt;p&gt;In JSX, you can indicate a dynamic variable using a curly bracket. Here’s a few examples:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;const Title = My Blog
const link = http://google.com

&amp;lt;h1&amp;gt;{Title}&amp;lt;/h1&amp;gt;
&amp;lt;a hred={link}&amp;gt; Google &amp;lt;/a&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;click-events&quot;&gt;Click Events&lt;/h3&gt;

&lt;p&gt;It’s important that the onclick event is provided a function reference, and that you aren’t actually calling the function. The following code won’t work, because &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;doSomething()&lt;/code&gt; with the parentheses is a function call.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;button onClick() = {doSomething(variable)}&amp;gt;Do It!&amp;lt;/button&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Instead, place the function into an anonymous wrapper.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;button onClick() = {() =&amp;gt; doSomething(variable)}&amp;gt;Do It!&amp;lt;/button&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;hooks&quot;&gt;Hooks&lt;/h3&gt;

&lt;p&gt;At a high level, hooks are like functions, which help you manage stateful objects in your project.&lt;/p&gt;

&lt;p class=&quot;message&quot;&gt;
In React, the state of a component is like its memory. Things like the items added to your cart, or the current image in a carousel of images you&apos;re scrolling through. 
&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import { useState } from &apos;react&apos;;

const [number, setNumber] = useState(25);

const handleClick = () =&amp;gt; {
    setNumber(50)
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;lists&quot;&gt;Lists&lt;/h3&gt;

&lt;p&gt;Let’s say you wanted to maintain a list of something on your website (maybe a directory of employees). To store this information, we want a variable that can be edited and additionally one that is Reactive.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;const [employees, setEmployees] = useState([
    { name: Joe, id: 1},
    { name: Bob, id: 2}
]);
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And then to display these items, we can use the map function from javascript.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{employees.map((employee) =&amp;gt; (
    &amp;lt;div className=&quot;employee-preview&quot; key={employee.id}&amp;gt;
        &amp;lt;h2&amp;gt;Name&amp;lt;/h2&amp;gt;
    &amp;lt;/div&amp;gt;
))};
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;props&quot;&gt;Props&lt;/h3&gt;

&lt;p&gt;Props are used to pass data from a parent component into a child component. Conceptually, this is like passing argument to a function. This makes a lot of sense since components in React are basically declared as functions.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;const function = (props)
const name = props.name     
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;serve-it-up&quot;&gt;Serve it Up&lt;/h3&gt;

&lt;p&gt;Bundle your &lt;del&gt;home and auto insurance&lt;/del&gt; project and launch with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;npx parcel src/index.html&lt;/code&gt;. You can also adjust you .json file to shortcut this call.&lt;/p&gt;

&lt;h3 id=&quot;material-ui&quot;&gt;Material UI&lt;/h3&gt;

&lt;p&gt;MUI is a React library, which implements Google’ material design guidelines. In other words, it provides a bunch of &lt;em&gt;components&lt;/em&gt; which you can import and use without having to style them! It’s very easy, and the website is pretty well documented.&lt;/p&gt;

&lt;h2 id=&quot;7-conclusion&quot;&gt;7. Conclusion&lt;/h2&gt;

&lt;p&gt;And that’s it for now! For further reading, I highly recommend NetNinja’s youtube series on React.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>The Math of Dice Rolling</title>
   <link href="https://ludavid15.github.io//dice/"/>
   <updated>2022-12-29T00:00:00-08:00</updated>
   <id>https://ludavid15.github.io//dice</id>
   <content type="html">&lt;p&gt;Have you ever been a DM and wondered what it means to roll with disadvantage? Or why some weapons are 2d6 instead of 1d12? It all has to do with the statistics of dice rolls!&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;Let’s start with something pretty basic to understand. If you are rolling a single dice, there is an equal probability of any number landing face up. This means a flat distribution across the board.&lt;/p&gt;

&lt;h3 id=&quot;taking-the-sum-of-2-dice&quot;&gt;Taking the Sum of 2 Dice&lt;/h3&gt;

&lt;p&gt;Now instead of rolling a single dice, we’ll take the sum of two dice. So instead of rolling 1d12, we can roll 2d6. The first obvious change is that now it’s no longer possible to roll a 1. However, the distribution is now also way different! Averages values (like a 6, 7, 8) are way more likely than the extremes (a 2 or a 12).&lt;/p&gt;

&lt;p&gt;Here’s a fairly straightforward snippet of code to help us analyze the distribution. We’re getting the every combination from 2 dice rolls, summing them, and then tallying up each sum.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def distribution_sum(a, b):
    result = []
    total = max(a)*max(b)
    for roll_1 in a:
        for roll_2 in b:
            result.append(roll_1 + roll_2)
            
    x = np.arange(1, max(result)+1)
    y = np.zeros(max(result))
    for sum in result:
        y[sum-1] += 1
    return x, y/total
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;When we plot the results, we can see that the sum of two dice is actually &lt;strong&gt;not&lt;/strong&gt; a bell curve, but a triangle.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/d6d6.png&quot; alt=&quot;SumOfTwo&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;However, as we increase the difference between the two die used (e.g. d12 and d8), we also “flatten” the top. You can think of this as the bigger dice “enveloping” the smaller dice so to speak.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/d12d8.png&quot; alt=&quot;SumOfTwoDifferent&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;sum-of-more-than-2-dice&quot;&gt;Sum of More than 2 Dice&lt;/h3&gt;

&lt;p&gt;When we increase the number of dice (for example, 3d4 instead of 1d12), we end up both flattening the curve, as well as shifting it to the right. Here’s a few examples all together:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/2d63d4.png&quot; alt=&quot;MultipleDice&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;rolling-with-advantagedisadvantage&quot;&gt;Rolling with Advantage/Disadvantage&lt;/h3&gt;

&lt;p&gt;When you roll with advantage, you roll two dice and take the higher value. We could take the same approach as before, and find every combination, compare the results, and only record the higher value, and that code would look like this:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def distribution_advantage(a):
    result = []
    total = max(a)**2
    for roll_1 in a:
        for roll_2 in a:
            result.append(max([roll_1, roll_2]))
            
    x = np.arange(2, max(a)+1)
    y = np.zeros(max(result)-1)
    for sum in result:
        y[sum-2] += 1
    return x, y/total
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;But there’s a faster way to come to an answer. Let’s say that on one d20 die you rolled a 20. This means that the other die can be literally anything, and you’d still take the 20. But now let’s say you roll a 2 on the first die. Well now there’s only one number on the other die for which you’d still take the 2 from the first die.&lt;/p&gt;

&lt;p&gt;So the idea I’m trying to convey here is that larger numbers are &lt;em&gt;dominant&lt;/em&gt; over smaller numbers, in the same way as with dominant and recessive genes. So back to our previous analogy, all 20 combinations with a 20 results in a 20, but only 1 combination with a 1 results in a 1 (whew take a second to digest that, that was confusing).&lt;/p&gt;

&lt;p&gt;All this means that a 20 is going to be about 20 times more likely than a 1 in a roll with advantage. If we plot the distribution, it’ll look something like this.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/advantaged20.png&quot; alt=&quot;Advantage&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Rolling with diadvantage is going to be the same, but in reverse, where 1 becomes more likely, and 20 becomes less likely.&lt;/p&gt;

&lt;p&gt;The weighted average of an advantaged d20 roll (result * probability) is 13.825, compared to 10.5 for a straight roll. In other words, you can think of an advantaged roll as approximately equivalent to adding 3.325 to a roll.&lt;/p&gt;

&lt;h3 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;And that’s it! Those should cover most cases you’ll encounter as a player or DM. Next up, a chapter on why paladin crits are ridiculous.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Satellite Architecture</title>
   <link href="https://ludavid15.github.io//satellitesIntro/"/>
   <updated>2022-12-10T00:00:00-08:00</updated>
   <id>https://ludavid15.github.io//satellites</id>
   <content type="html">&lt;p&gt;Finally we’re getting to stuff that I work with. There’s a lot to know when it comes to satellites, so in this post we’re just going to stick to the basics.&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;Before we design any hardware, first we need to understand our mission objective. Once that’s determined, we’ll be able to select an appropriate orbit. The orbit is very important because that decides our operating environment (for example, solar intensity, exposure to radiation, available communication stations, etc).&lt;/p&gt;

&lt;h2 id=&quot;orbits&quot;&gt;Orbits&lt;/h2&gt;

&lt;p&gt;In this post we’ll focus on Earth Orbits (in constrast to interplanetary missions). For the most part these can be roughly categorized by their altitude, eccentricity, and inclination.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Name&lt;/th&gt;
      &lt;th&gt;Description&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;HEO&lt;/td&gt;
      &lt;td&gt;Highly Elliptical Orbit&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;These have a perigee relatively close to Earth, but have a very high apogee. This means that the satellite spends a lot of time at apogee, but swings through perigee pretty quickly.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;LEO&lt;/td&gt;
      &lt;td&gt;Low Earth Orbit&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;Roughly any orbit below 2000km in altitude. These orbits are convenient and accessible, but have a limited field of view.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;GEO&lt;/td&gt;
      &lt;td&gt;Geosychonous Earth Orbit&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;These orbits have a period equal to 24 hours, which means they sit over the same spot on earth.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Orbits will high inclination are typically called “polar” (i.e. they fly over the poles of the Earth). Generally, changing an orbit’s inclination is pretty expensive in terms of delta-V, so many polar satellites are launched at higher latitudes (which puts you naturally into a high inclination orbit).&lt;/p&gt;

&lt;h2 id=&quot;hardware&quot;&gt;Hardware&lt;/h2&gt;

&lt;p&gt;Regardless of where you go, almost every satellite is going to have some form of each of the following.&lt;/p&gt;

&lt;h3 id=&quot;communication&quot;&gt;Communication&lt;/h3&gt;

&lt;p&gt;Your comm system will be unique to your application, but in general some kind of antenna will be required. More importantly perhaps, is &lt;em&gt;what and when&lt;/em&gt; you plan to communicate. A few questions to ponder:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Are there specific ground stations you want to point to? Or will you have an omni-directional antenna onboard?&lt;/li&gt;
  &lt;li&gt;What are the security needs? If there’s data to protect, you’ll probably want some kind of encoding or encryption.&lt;/li&gt;
  &lt;li&gt;How are you going to communicate with the satellite from the ground? Will you have an antenna that points to it? If so, how are you going to track the satellite’s position in the sky?&lt;/li&gt;
  &lt;li&gt;What are the signal to noise (S/N) and latency requirements?&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Also worth thinking about is the &lt;a href=&quot;https://en.wikipedia.org/wiki/OSI_model&quot;&gt;OSI Model&lt;/a&gt;. For a satellite’s comm system, you’ll need to consider all layers.&lt;/p&gt;

&lt;p&gt;Especially for satellites, the distances between your sending and receiving terminal can be significant. You’ll want to pay careful attention to the required power of your signal, and balance that against noise and signal degradation.&lt;/p&gt;

&lt;p&gt;Once the main downlink path has been designed, you’ll want to think about what actual content you want. Will you have telemetry to monitor the health and status of your system? How often will it be collected and reported? How will it be identified?&lt;/p&gt;

&lt;h3 id=&quot;propulsion&quot;&gt;Propulsion&lt;/h3&gt;

&lt;p&gt;The propulsion system provides Delta-V capacity to your satellite. This could be used initially for getting into your orbit, but also after the fact for maintaining your orbit, or for emergency collision avoidance maneuvers.&lt;/p&gt;

&lt;p class=&quot;message&quot;&gt;
Why do orbits need to be maintained? Well, atmospheric drag for one. But also the Earth isn&apos;t perfectly spherical and this causes orbits to drift over time (called precession).
&lt;/p&gt;

&lt;p&gt;Depending on your design, propulsion thrusters are usually classified in two ways: either as primary thrusters, which provide delta-V, or as attitude control thrusters. The latter needs less thrust, but are used more, so a higher specific impulse would be good.&lt;/p&gt;

&lt;h3 id=&quot;attitude-control&quot;&gt;Attitude Control&lt;/h3&gt;

&lt;p&gt;The attitude control system serves effectively the same role as your car’s steering. In zero-G however, the only way to control your pointing is to control your momentum. The primary methods are:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Thrusters&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;This one’s pretty straightforward. If you have thrusters that aren’t pointed through the center of mass, firing them will create a torque. The obvious downside here is that fuel is a limited resource.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Magnetic Torque Rods&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;If you’re orbiting the Earth, you have the benefit of orbiting in a magnetic field. If you pass current through a wire, it will interact with this magnetic field and generate a force, which you can harness for attitude control.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Wheels or Gyros&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;These are maybe less intuitive. First, we should remember that total momentum is conserved. This means that if we change the momentum of one thing on the spacecraft, something else will change as well to preserve the total. On a satellite, we can change the speed/orientation of a heavy wheel or gyro using an electric motor, which induces a corresponding change in the angular momentum in the rest of the satellite, thereby providing us with a means of attitude control.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;If you’ve taken a controls class, you may also know that effective controller design requires knowledge of your mass distribution. Some of the more important external placements are going to be your:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Solar arrays&lt;/li&gt;
  &lt;li&gt;Comm Antennas&lt;/li&gt;
  &lt;li&gt;Payload&lt;/li&gt;
  &lt;li&gt;Radiator&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Which is going to be constrained primarily by your orbit, power needs, thermal needs, and mission needs. In other words, any controller needs are usually going to come second. This is usually fine - it’s easier to size up your control mechanism than to realize later that your radiator accidently gets pointed into the sun while pointing the payload!&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Propulsion tanks tend to be placed towards the center of your satellite. This just works overall because tanks tend to be both big and heavy, but also over time as you use up propellant, this minimizes how far the center of mass shifts.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;attitude-determination&quot;&gt;Attitude Determination&lt;/h3&gt;

&lt;p&gt;Control doesn’t do much good unless you know where you are. For a satellite, two important things to know are your 1) ephemeris (position along the orbit) and 2) attitude. This gets a little bit into the world of controls, which we won’t dive into, but you’ll always want sensors to collect data. A few options include:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;GPS Receiver&lt;/li&gt;
  &lt;li&gt;Star Tracker&lt;/li&gt;
  &lt;li&gt;Sun Sensor&lt;/li&gt;
  &lt;li&gt;Inertial Measurement or Reference Unit&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As for actually determining your attitude and ephemeris from sensor data, you could try some kind of Kalman filter.&lt;/p&gt;

&lt;h3 id=&quot;power&quot;&gt;Power&lt;/h3&gt;

&lt;p&gt;For Earth orbiting satellites, your primary source of power is almost always going to be solar, it’s just too easy not to!&lt;/p&gt;

&lt;p class=&quot;message&quot;&gt;
The only time you wouldn&apos;t use solar is for deep space missions. As you move away from the sun, solar intensity drops proportionally to the inverse square of your distance. So if you were going out to Pluto for example, nuclear power might be a better option.
&lt;/p&gt;

&lt;p&gt;If you’re in LEO or even HEO orbit, there will likely be times when you are eclipsed by the Earth. You’ll need to size your batteries accordingly so you can get through this period without solar power.&lt;/p&gt;

&lt;p&gt;If your position and attitude are changing rapidly, you may also want some way to gimbal your solar panels into or out of the sun, to control the flow of power/heat.&lt;/p&gt;

&lt;h3 id=&quot;thermal&quot;&gt;Thermal&lt;/h3&gt;

&lt;p&gt;Thermal gets tricky in space, because there’s no convection or conduction, only radiation. This means that spacecraft are often subjected to enormous temperature ranges (-100 to 100 deg celsius is not a bad estimate). Heaters are essential to prevent things from freezing, while radiators are just as important to prevent things from overheating.&lt;/p&gt;

&lt;p&gt;For any given piece of hardware, there’s usually an operating temperature range, and a survival temperature range. And then on the structural side of things, you may need to think about your coefficients of thermal expansion. This can be a primary source for structural stress.&lt;/p&gt;

&lt;h3 id=&quot;launch-vehicle-intefacing&quot;&gt;Launch Vehicle Intefacing&lt;/h3&gt;

&lt;p&gt;An equally important piece of your design is your launch vehicle interface. After all, the LV is what takes you into space. Do you have special environmental needs while you’re in the fairing? Can you survive the g’s during launch? How will you ensure a clean separation?&lt;/p&gt;

&lt;h2 id=&quot;systems-engineering&quot;&gt;Systems Engineering&lt;/h2&gt;

&lt;p&gt;In the real world, no task is performed in isolation. A lot of supporting infrastructure goes a long way towards making programs safe, reliable, and effective. A satellite is no different. In addition to hardware to perform the basic functions, we also need hardware to support them. This can look like a number of things:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Fault Detection and Response&lt;/li&gt;
  &lt;li&gt;Software Updates&lt;/li&gt;
  &lt;li&gt;Health and Status Monitoring&lt;/li&gt;
  &lt;li&gt;Redundant/Emergency Systems&lt;/li&gt;
  &lt;li&gt;Data Verification and Validation&lt;/li&gt;
  &lt;li&gt;Security Systems&lt;/li&gt;
&lt;/ul&gt;

</content>
 </entry>
 
 <entry>
   <title>Model Based Systems Engineering</title>
   <link href="https://ludavid15.github.io//mbse/"/>
   <updated>2022-12-09T00:00:00-08:00</updated>
   <id>https://ludavid15.github.io//mbse</id>
   <content type="html">&lt;p&gt;With better computers, engineers have increasingly turned to model based systems engineering, or MBSE as a solution to the engineering process. After all, things like CAD, CFD, and FEM have enabled us to model complex physics, so why not model a project?&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;The goal of model based systems engineering is to improve upon two things that happen very slowly with traditional requirements documents:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;A way to track the design baseline.&lt;/li&gt;
  &lt;li&gt;Once a change is made, an easy way to explore how it impacts other systems.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The primary advantage of using a model is to quickly see connections while keeping a single point of truth. For instance, if the total mass of your spacecraft is an important parameter, everything which references that number can point directly to that parameter. This way, when that parameter gets updated (hopefully in real time), its effect becomes instantly tangible.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;For you programmers, this is like passing-by-reference.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;So that’s the first important concept of MBSE - this idea of the model as a series of connections between parameters. The second concept is &lt;em&gt;visualization&lt;/em&gt;, or how humans actually interface with the model. So far, a series of variables and their connections is easily achievable with a database, or even through lines of code, but neither of these are very accessible to a person. Instead we map the model to visualizations so we can have something useful for our human designers. Operations can be still be shown as flowcharts, hardware can still be shown as block diagrams, and of course we can still fall back on tables and matrices where it makes sense (like with data). The key is that each diagram is not static, but is a connected view &lt;em&gt;into&lt;/em&gt; the model.&lt;/p&gt;

&lt;h2 id=&quot;the-model&quot;&gt;The Model&lt;/h2&gt;

&lt;p&gt;What aspects of a system can we model? Here’s a list.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Physical Configuration&lt;/li&gt;
  &lt;li&gt;Function/Behavior&lt;/li&gt;
  &lt;li&gt;Interactions/Data&lt;/li&gt;
  &lt;li&gt;Heirarchies/Definitions&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;physical-configuration&quot;&gt;Physical Configuration&lt;/h4&gt;

&lt;p&gt;Fairly straightfoward, we need to track the hardware, physical connectors, and physical properties (shape, weight, thermal resistence, etc.). If our project was a sentence, the physical configuration would be the nouns.&lt;/p&gt;

&lt;h4 id=&quot;functionbehavior&quot;&gt;Function/Behavior&lt;/h4&gt;

&lt;p&gt;Verbs. Things that happen. You could say that function is the first thing we choose. Hardware is designed to meet a function, not the other way around.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Technically this isn’t always true. When a heritage (proven) piece of hardware is selected, its function is already defined, and then engineers build the rest of the system around it.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;interactions&quot;&gt;Interactions&lt;/h4&gt;

&lt;p&gt;Interactions can be very abstract, but are also very important. A function might include an interaction, (i.e. a satellite interacts with a ground station by sending telemetry), but a physical configuration might also include an interaction (i.e. the baseplate on a satellite draws heat away from the electronics).&lt;/p&gt;

&lt;p&gt;And inherent to interactions is data and information. What information is tranferred? How is information formatted? Where does information go?&lt;/p&gt;

&lt;h4 id=&quot;definitions&quot;&gt;Definitions&lt;/h4&gt;

&lt;p&gt;Definitions explain the words we create to group stuff together. If many pieces of hardware work together to provide telemetry, we might designate a “telemetry subsystem”. These abstractions are an important part of communicating complex ideas, but can also get messy. Definitions are applicable to any of the three prior groupings: hardware, functions, and interactions.&lt;/p&gt;

&lt;h3 id=&quot;dodaf&quot;&gt;DoDAF&lt;/h3&gt;

&lt;p&gt;The Department of Defense Architecture Framework is an effort to generalize how we explain complex systems. Before getting into what DodAF is, let’s be clear that DoDAF is not necessarily model based systems engineering. DoDAF only defines a set of “viewpoints”, with each viewpoint showing a different aspect of the system. For example, systems viewpoint 4 (SV4) shows functional flow diagrams, while SV1’s show a high level overview of the physical elements.&lt;/p&gt;

&lt;p&gt;Consider an analogy - in CAD, we build 3D shapes. When we try to represent them on a 2D screen, we must choose a viewing angle and projection, but there are likely some standard views that everyone expects. Maybe a cross section to show the internal structure, or a profile view if it’s a flat plate. DoDAF (and in fact any system diagram) follows the same idea.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;DoDAF Views&lt;/th&gt;
      &lt;th&gt;Explanation&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;SV-1&lt;/td&gt;
      &lt;td&gt;High level hardware overview&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;SV-2&lt;/td&gt;
      &lt;td&gt;Detailed hardware overview&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;SV-4&lt;/td&gt;
      &lt;td&gt;Functional flow diagram&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;SV-6&lt;/td&gt;
      &lt;td&gt;Resource flow matrix&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;SV-10b&lt;/td&gt;
      &lt;td&gt;States and Modes transitions&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;SV-10c&lt;/td&gt;
      &lt;td&gt;Sequence Diagrams&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;DIV-1&lt;/td&gt;
      &lt;td&gt;Conceptual Data Model&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;DIV-2&lt;/td&gt;
      &lt;td&gt;Logical Data Model&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;DIV-3&lt;/td&gt;
      &lt;td&gt;Physical Data Model&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;sv-4&quot;&gt;SV-4&lt;/h3&gt;

&lt;p&gt;This is the functional viewpoint. In contrast to an SV-10c, an SV-4 is the functional model of your hardware, and NOT necessarily your order of operations. You can think of these a bit like a user story.&lt;/p&gt;

&lt;p&gt;In an SV-4, we can either state a heirarchy, (A consists of B, C, D), or we can show it using a flow chart (B, C, and D interact to accomplish A). The first version is known as an SV-4a, and the latter, more complex version is called an SV-4b.&lt;/p&gt;

&lt;h3 id=&quot;sv-6&quot;&gt;SV-6&lt;/h3&gt;

&lt;p&gt;This is a table of all your producing and consuming functions (and by extension, the performer of that function) for each resource. In a perfectly connected model, these resource interactions should appear on your functional diagrams (SV-4), physical diagrams (SV-1 and SV-2) and your data diagrams (DIV).&lt;/p&gt;

&lt;h3 id=&quot;sv-10c&quot;&gt;SV-10c&lt;/h3&gt;

&lt;p&gt;This is a sequence diagram. In contrast to the SV-4, an SV-10c is not primarily to meant to show the structure of your functions and hardware performers. Instead, an SV-10c tends to be a more explicit (and better) representation of your order of operations. An SV-10c also places greater emphasis on the &lt;em&gt;messages&lt;/em&gt; and ownership of an operation. For instance, will you provide me an update, or am I responsible for reaching out and asking for it? As such, SV-10c diagrams are great for modeling detailed behaviors.&lt;/p&gt;

&lt;h3 id=&quot;div&quot;&gt;DIV&lt;/h3&gt;

&lt;p&gt;The Data information viewpoint breaks down the heirarchy of data. Like functions, we can think of data both in the abstract, or by implementation. For instance, the attitude of a spacecraft is abstract (DIV-1). A set of quaternions stored into memory is an implementation (DIV-2). Whether those quaternions are stored with any identifying bit headers, or in little or big Endian is physical (DIV-3).&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;CAMEO gives us many tools for representing data. Exchange Elements are the default unit, and can be further refined with Signals. For instance, an exchange element might be created called “Power Command”, which refines into two signals “Power On” and “Power Off”.&lt;/p&gt;
&lt;/blockquote&gt;

</content>
 </entry>
 
 <entry>
   <title>Music and AI - Part 4</title>
   <link href="https://ludavid15.github.io//musicAI4/"/>
   <updated>2022-12-01T00:00:00-08:00</updated>
   <id>https://ludavid15.github.io//musicAI4</id>
   <content type="html">&lt;p&gt;Just some closing thoughts on this topic, as well as some random notes and questions I’ve left for myself in the future.&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;In the second post on AI and Music, we discussed why it’s difficult to generate music with AI. Along the way, we presented different learning &lt;em&gt;archictures&lt;/em&gt;, and how they were applied to the problem through different &lt;em&gt;strategies&lt;/em&gt;. Here is a quick summary of everything we went through:&lt;/p&gt;

&lt;h3 id=&quot;list-of-architectures&quot;&gt;List of Architectures&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;Feedforward&lt;/li&gt;
  &lt;li&gt;Autoencoder&lt;/li&gt;
  &lt;li&gt;Variational Autoencoder&lt;/li&gt;
  &lt;li&gt;Restricted Boltzman Machine&lt;/li&gt;
  &lt;li&gt;Recurrent Networks&lt;/li&gt;
  &lt;li&gt;Convolutional Networks&lt;/li&gt;
  &lt;li&gt;Conditioning Convolutional Networks&lt;/li&gt;
  &lt;li&gt;Generative Adversarial Networks&lt;/li&gt;
  &lt;li&gt;Reinforcement Learning&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;list-of-strategies&quot;&gt;List of Strategies&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;Single step feedforward&lt;/li&gt;
  &lt;li&gt;Decoder feedforward&lt;/li&gt;
  &lt;li&gt;Sampling based methods&lt;/li&gt;
  &lt;li&gt;Iterative feedforward&lt;/li&gt;
  &lt;li&gt;Input manipulation&lt;/li&gt;
  &lt;li&gt;Reinforcement&lt;/li&gt;
  &lt;li&gt;Unit Selection&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;list-of-challenges&quot;&gt;List of Challenges&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;Creatio Ex nihilo (creation from nothing)&lt;/li&gt;
  &lt;li&gt;Length variability (music of different lengths)&lt;/li&gt;
  &lt;li&gt;Content variability (is it deterministic?)&lt;/li&gt;
  &lt;li&gt;Expressiveness (dynamics and feeling)&lt;/li&gt;
  &lt;li&gt;Melody-harmony consistency&lt;/li&gt;
  &lt;li&gt;Control (user ability to affect outcome)&lt;/li&gt;
  &lt;li&gt;Style transfer (applicable to images, but can it apply to music?)&lt;/li&gt;
  &lt;li&gt;Structure (songs formats, AABA, etc.)&lt;/li&gt;
  &lt;li&gt;Originality (not just repeating information from training data)&lt;/li&gt;
  &lt;li&gt;Incrementality&lt;/li&gt;
  &lt;li&gt;Adaptability&lt;/li&gt;
  &lt;li&gt;Explainability&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;recurrent-vs-convolutional-networks&quot;&gt;Recurrent vs Convolutional Networks&lt;/h3&gt;

&lt;p&gt;Convolutional networks have not been explored thoroughly as a way to generate or recognize music. Maybe this is because music representation is so complex that it’s difficult to visualize how a CNN would apply.&lt;/p&gt;

&lt;p&gt;That being said, convolutional networks do have two advantages:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Faster to train and easier to parallelize&lt;/li&gt;
  &lt;li&gt;By nature of their implementation, convolutional networks increase the volume of data.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;transfer-learning&quot;&gt;Transfer Learning&lt;/h3&gt;

&lt;p&gt;Transfer learning for music is another area that really hasn’t been explored in depth, but which could be enormously useful, if we use the (more developed) subject of image generation as a sign of things to come.&lt;/p&gt;

&lt;h3 id=&quot;open-questions&quot;&gt;Open Questions&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Why do some training sets transpose all songs into a single key, while other training sets transpose all songs into every key? Is there a difference?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Can we use a lead sheet as the input, with a polyphonic melody/solo as the output? Maybe the pianist can be the conditional input (i.e. toggle style for different players)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Can we apply Elgammal’s CAN, to create jazz solos that seem real, but which are not easily classified into an existing musicians’s style?&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

</content>
 </entry>
 
 <entry>
   <title>Music and AI - Part 3</title>
   <link href="https://ludavid15.github.io//musicAI3/"/>
   <updated>2022-11-19T00:00:00-08:00</updated>
   <id>https://ludavid15.github.io//musicAI3</id>
   <content type="html">&lt;p&gt;In the previous post, we looked at how different architectures have been applied to music generation. But this is a bit like putting your cart before the horse, since we haven’t discussed in detail the kind of attributes we’re looking for. This post goes over some high level considerations - things that could serve as requirements for a project. Depending on your specific needs and desires, you may end up selecting a different architecture.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;part-1---content-variety&quot;&gt;Part 1 - Content Variety&lt;/h2&gt;

&lt;p&gt;In music, there is not going to be a “best” or most “optimal” solution. This means that we actually do want some way to add randomness into our process.&lt;/p&gt;

&lt;h3 id=&quot;11---sampling&quot;&gt;1.1 - Sampling&lt;/h3&gt;

&lt;p&gt;Sampling methods work a little like the feedforward decoder, but instead of generating examples which are &lt;em&gt;deterministic&lt;/em&gt; based on a seed, examples are randomly generated to match a probability distribution. Some famous sampling strategies include: Metropolis-Hastings algorithm, Gibbs Sampling, and block Gibbs Sampling.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Another way to think about sampling methods is that they are a form of generative AI that is based on stochastic models which learn probability distributions (variational autoencoders, RBM’s, etc.). For this reason, we talk about them as a different type of solution, but conceptually, they can manifest just like the decoder in example 2 (i.e. a seed is used to randomly generate examples).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;With regard to music, there are two ways to apply this type of sampling approach. The first, is in the vertical dimension, (i.e. chord - does the voicing of this chord make sense?). Recurrent Boltzman Machines are effective for this kind of work. The second is in the horizontal dimension (i.e. a melody or sequence of notes - does this sequence of notes make a coherent melody?). This kind of sampling is better achieved by an RNN.&lt;/p&gt;

&lt;h3 id=&quot;12---sampling-control-through-interpolation&quot;&gt;1.2 - Sampling Control through Interpolation&lt;/h3&gt;

&lt;p&gt;So we mentioned earlier that decoders only allow information to pass through one way, but there’s a way around this: interpolation in the latent space.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The latent space is the space formed by the latent variables. (e.g. if our seed was (8,4,5,2), there are 4 latent variables). We could perform clustering in the latent space to identify patterns to the seeds which produce our training data.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In this sense, we aren’t really feeding information back through the decoder, but rather applying even more machine learning on the seeds to understand the significance of each digit. In other words, given a set of coordinate &lt;em&gt;numbers&lt;/em&gt;, we’re learning if they are for a cartesian, polar, or spherical &lt;em&gt;system&lt;/em&gt;.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Hadjeres and Nielsen discuss something called geodesic latent space regularization, which is supposed to be better than linear interpolation.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;13---training-for-originality&quot;&gt;1.3 - Training for Originality&lt;/h3&gt;

&lt;p&gt;For many skills, copying is easier than creating, and this is certainly true for generative AI as well. How can we bias our architecture to create original content, and not just poor copies? Importantly, we would like this to happen &lt;em&gt;a priori&lt;/em&gt;, and not &lt;em&gt;a posteriori&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;The first approach involves a sort of &lt;em&gt;ad hoc&lt;/em&gt; tuning of parameters within the archicture until we get results that mostly seem original. This can certainly be effective, but maybe lacks some of the intentionality we’re going for.&lt;/p&gt;

&lt;p&gt;A second approach is a modification of the traditional generative adversarial network. In a traditional GAN, the classifier returns a signal of how easily/confidently it was able to classify the generated content as real or fake. The new approach, as outlined by Elgammal, called a &lt;em&gt;creative&lt;/em&gt; adversarial network (CAN), uses these two contradictory forces:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The same signal in a traditional GAN about how easily it is able to distinguish between real and fake input.&lt;/li&gt;
  &lt;li&gt;The ease with which it is able to classify the input into a learned style.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Thus, the generative part of the network is incentived to create ouput that feels real, but also difficult to classify (hence, creative!). Elgammal’s work is primarily applicable to art, and has not yet been applied to music.&lt;/p&gt;

&lt;h2 id=&quot;part-2---more-complex-representations&quot;&gt;Part 2 - More Complex Representations&lt;/h2&gt;

&lt;p&gt;Thus far we’ve talked pretty simply about music as basically a collection of notes through time, but there are plenty of other details we can think about.&lt;/p&gt;

&lt;h3 id=&quot;21---richer-chord-encodings&quot;&gt;2.1 - Richer Chord Encodings&lt;/h3&gt;

&lt;p&gt;We introduced sampling as a means to create something from nothing, but sampling is also useful because it is non-deterministic. (i.e. instead of choosing the most probable solution, we can randomly choose a solution based on the probability distribution).&lt;/p&gt;

&lt;p&gt;An early application of sampling is the CONCERT Bach Melody generation system by Mozer (1994). The program generates melodies with a chord accompaniment, where the chords are just another aspect of each note, alongside pitch and duration. We’ll discuss each of these in order, starting first with pitch.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;The pitch of each note has three components, which are the pitch height, the (modulo) chroma circle cartesion coordinates, and the (harmonic) circle of fifths cartesian coordinates. The second two coordinates help capture the similarity of the octave, and the harmonic importance of the fifth respectively.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The duration is subdivided into 12, to accomodate both regular divisions as well as triplets. As with the pitch, there are 3 coordinates to the duration, the absolute duration, the 1/3 beat circle, and the 1/4 beat circle.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The chords are always structured the same, with a root, a third that can be major or minor, a fifth that can be perfect, augmented, or diminished, and an optional 7th that can be major or minor.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;One of the reasons why the CONCERT program uses such a complex representation is because it pre-dates modern deep learning algorithms. Instead of allowing an archicture to learn these relationships, the authors manually design them into the representation.&lt;/p&gt;

&lt;h3 id=&quot;22---dynamics&quot;&gt;2.2 - Dynamics&lt;/h3&gt;

&lt;p&gt;Music played by a human rarely ends up sounding exactly like it is written on the page. Musicians will adjust the dynamics, and take liberties on tempo in an actual performance which are not captured by sheet music. These decisions are often made live, and are based on the musician’s understanding of the music and personal opinion.&lt;/p&gt;

&lt;p&gt;One way to capture this information is to work directly with the audio waveforms rather than symbolic representation. Of course, the obvious downside to this strategy is that we lose the symbolic representation. A second alternative is to add this information to our training data as another aspect of the input and output.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;In their program, called Performance RNN, Simon and Oore capture MIDI performance data and introduce an additional time shift and dynamic value to each time step. The time shift ranges from 10 ms to 1 sec, and the dynamics are captured by the 128 possible MIDI velocities quantized into 32 bins.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;part-3---other-desireable-qualities&quot;&gt;Part 3 - Other Desireable Qualities&lt;/h2&gt;

&lt;h3 id=&quot;31---control&quot;&gt;3.1 - Control&lt;/h3&gt;

&lt;p&gt;Stepping back for a moment, let’s think about how we could apply generative AI. The first thing to realize is that most tools are designed to help a real person, and lack direction by themselves. Even the most advanced AI’s - like those that drive your car - still need a destination. So the primary question is: how can we exert control over the result?&lt;/p&gt;

&lt;p&gt;One way we’ve already discussed is through sampling. Like the predictive speech capability on your phone, non-deterministic algorithms are important because they provide &lt;em&gt;options&lt;/em&gt;. But a big problem with sampling methods is that decoders only work in one direction. There’s no easy way to take the output and feed it back to learn a “better” seed. Luckily, we are not without options.&lt;/p&gt;

&lt;p&gt;For RNNs, one option we have is to threshold out low probability options (remember that notes are often predicted with a softmax function). This prevents these a bad note from propagating into futue time steps.&lt;/p&gt;

&lt;p&gt;For single step feedforward networks, we can reduce the sampling scope. Instead of generating large chunks of music, we generate shorter phrases, or fewer voices within a larger and constrained piece.&lt;/p&gt;

&lt;h4 id=&quot;311---conditioning&quot;&gt;3.1.1 - Conditioning&lt;/h4&gt;

&lt;p&gt;Conditioning an architecture means to bias it’s output, based on some extra information (typically applied as an additional input layer). For example, this could be a genre label, a chord progression, or maybe even the previously generated note.&lt;/p&gt;

&lt;h4 id=&quot;312---unit-selection&quot;&gt;3.1.2 - Unit Selection&lt;/h4&gt;

&lt;p&gt;At its core, unit selection is an interative feedforward network, but instead of writing music note by note, it selects measures from a database, which when concatenated together, form a coherent musical idea. This approach needs metadata to represent the musical quality of each measure but unfortunately, music theory doesn’t really think of music in terms of measures. This means we as humans lack the language to think about what these pieces of metadata might be!&lt;/p&gt;

&lt;h3 id=&quot;32---adaptable-networks&quot;&gt;3.2 - Adaptable Networks&lt;/h3&gt;

&lt;p&gt;Another common problem with networks is that they cannot learn after they’ve been trained. How do you reinforce good patterns, and discourage bad ones? One option is to feed good outputs back into the training pool, but this risks over-fitting, and there is no practical way to punish bad behavior.&lt;/p&gt;

&lt;p&gt;In practice, this kind of objective mostly has to be achieved by looking more closely at the generation step, and taking advantage of &lt;em&gt;control&lt;/em&gt; strategies (like reinforcement, conditioning, constraints, etc.). Over-time, we can “learn” values for these parameters that improve the ouput.&lt;/p&gt;

&lt;h3 id=&quot;33---explainable-networks&quot;&gt;3.3 - Explainable Networks&lt;/h3&gt;

&lt;p&gt;The challenge of explaining how AI “thinks” is not unique to music. In general, deep learning architectures are a bit of a black box, but a few basic approaches have been tried to “understand” what patterns each node, or collection of nodes is responding to.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;This task gets a lot easier on simple inputs. For instance, in a low rank matrix, we can look at the vectors which span the matrix space, and understand that each vector captures one essential piece of information. But then again, if patterns were easy to spot, we wouldn’t need such complex deep learning archictures to begin with.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ol&gt;
  &lt;li&gt;Gradient sensitivity - seeing how changes to the inputs affect the result&lt;/li&gt;
  &lt;li&gt;Signal isolation - attempting to isolate particular input patterns to trigger activation in high level neurons&lt;/li&gt;
  &lt;li&gt;Attribution - looking at a specific location in the output, and seeing the contributions from each input dimension.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;34---refinement-over-time&quot;&gt;3.4 - Refinement over Time&lt;/h3&gt;

&lt;p&gt;In the real world, your first draft is rarely your final draft. You’ll go back through and make edits, but taking into account now your better understanding of where you’re coming from and where you’re going.&lt;/p&gt;

&lt;p&gt;When applied to music generation and machine learning, this changes the input structure from maybe just a frame or structure, to something more constrained.&lt;/p&gt;

&lt;p&gt;DeepBach is one such example, which uses two LSTM’s and two feedforward networks. The two LSTM’s approach from different sides of the music - one from the past and one from the future. A third network handles harmonic information, and the three together are passed into a final network for the output.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Incremental networks like the one just mentioned are great candidates for providing a user interface, and hence, control over the result!&lt;/p&gt;
&lt;/blockquote&gt;

</content>
 </entry>
 
 <entry>
   <title>Coding ML with Julia</title>
   <link href="https://ludavid15.github.io//mlcode/"/>
   <updated>2022-11-01T00:00:00-07:00</updated>
   <id>https://ludavid15.github.io//mlcode</id>
   <content type="html">&lt;p&gt;A short reference for using the Flux package in Julia to setup and train deep learning networks. The offical website can be found &lt;a href=&quot;https://fluxml.ai/Flux.jl/stable/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h3 id=&quot;basics&quot;&gt;Basics&lt;/h3&gt;

&lt;p&gt;An efficient way to use one-hot encoding (better than regular arrays). This produces a one-hot vector of length 5, with a 1 at the second position.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;onehot(2, 1:5)  
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Softmax normalizes a vector such that the sum of all entries is exactly equal to 1 (as it should be for probability distributions). Here, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;xs[2]&lt;/code&gt; is a vector representing the 2nd training example.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;softmax(model(xs[2])) 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And now setting up a neural network:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;model = Dense(2,3,sigma)
L(x,y) = Flux.mse(model(x),y)
opt = ADAM()
Flux.train!(L, zip(xs, ys), opt)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Where:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;xs&lt;/code&gt; is the feature vector&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ys&lt;/code&gt; is the label vector&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;L(x,y)&lt;/code&gt; is the loss function&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;deep-learning&quot;&gt;Deep Learning&lt;/h3&gt;

&lt;p&gt;We can build deep learning networks (i.e. networks with more than 1 layer) by using the Chain function.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;layer1 = Dense(2, 3, sigma)
layer2 = Dense(3, 2, identity)
layer3 = softmax

model = Chain(layer1, layer2, layer3)  
L(x,y) = Flux.crossentropy(model(x), y)
opt = SGD(params(model))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;batching&quot;&gt;Batching&lt;/h3&gt;

&lt;p&gt;Batching is a function that merges many data points into a single matrix. This is more efficient to train because matrix-matrix multiplication has been heavily optimized. To create mini-batches, we can call the batch function on a subset of our data.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;databatch = (Flux.batch(xs), Flux.batch(ys))
Flux.train!(L, Iterators.repeated(databatch, 1000), opt)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Second line: Flux takes the model, and trains it on the dataset in databatch, and repeats 1000 times.&lt;/p&gt;

&lt;h3 id=&quot;callbacks&quot;&gt;Callbacks&lt;/h3&gt;

&lt;p&gt;A function that we’d like Flux to call every so often. This is useful for capturing the loss or learning progress while we’re training a model. We can wrap our callback function with the throttle function to set how often (in seconds).&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Flux.throttle(callback, 1)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>Machine Learning Architectures</title>
   <link href="https://ludavid15.github.io//mlarchitectures/"/>
   <updated>2022-11-01T00:00:00-07:00</updated>
   <id>https://ludavid15.github.io//mlarchitectures</id>
   <content type="html">&lt;p&gt;At its core, machine learning is a &lt;strong&gt;statistical science&lt;/strong&gt;, and like statistics, a great deal of care must be taken when formatting and analyzing data. They way we chose to quantify abstract topics and/or measure error will have a significant impact on the quality of our result.&lt;/p&gt;

&lt;p&gt;This post lays a stronger mathematical foundation for machine learning, but if you are just looking for a high level overview of what machine learning is, I recommend reading this post on &lt;a href=&quot;/notes/mlintroduction&quot;&gt;how to think about machine learning&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;For a discussion of machine learning as a wandering exploration of linear algrebra, see the post on &lt;a href=&quot;/notes/linearAlgebra&quot;&gt;linear algebra&lt;/a&gt;. In fact, I’d recommend starting on that page first! Matrices are the bedrock of machine learning.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;part-1---basic-architectures&quot;&gt;Part 1 - Basic Architectures&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;On the linear algrebra post, we’ve talked a lot about what we can do with matrices, and we’ve done this because many problems can be solved without reaching for a neural network that has millions of weights which need to be optimized. Just something to keep in mind!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;linear-regression&quot;&gt;Linear Regression&lt;/h3&gt;

&lt;p&gt;To start, let’s review the most basic type of machine learning problem - linear regression. The aim is to find a linear best-fit relationship between (x) and (y). Note that (x) can be a vector.&lt;/p&gt;

\[h(x) = b + \theta_1x_1 + ... + \theta_nx_n = b + \sum_{i=1}^{n}theta_1x_i\]

&lt;p&gt;Where \(h\) is the model, $b$ is an offset, and the \(\theta\)’s are the weights to be learned.&lt;/p&gt;

&lt;p&gt;Sometimes, the weights are represented by the character \(w\), which makes sense.&lt;/p&gt;

&lt;h3 id=&quot;k-means-clustering&quot;&gt;K-Means Clustering&lt;/h3&gt;

&lt;p&gt;Minimizes the intra-cluster variance. The strength of clustering algorithms lies in the fact that it is an unsupervised learning method, i.e., data does not have to come pre-labeled. The process goes:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Propose N cluster centers.&lt;/li&gt;
  &lt;li&gt;Assign every pixel to the closest cluster center.&lt;/li&gt;
  &lt;li&gt;Calculate new cluster centers using the average of assigned pixels.&lt;/li&gt;
  &lt;li&gt;Repeat until centers have stabilized.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;For data classification, there typically needs to be as many dimensions as independent features (N) we’d like to distinguish. This means that for a task like image classification, we’ll need to find a way to transform a 2D image into a single point in 2D dimensional space.&lt;/p&gt;

&lt;h3 id=&quot;feed-forward-neural-networks&quot;&gt;Feed Forward Neural Networks&lt;/h3&gt;

&lt;p&gt;Networks are function approximators. Each node consists of any number of inputs and any number of outputs, but is itself a simple activation function (relu, sigmoid, tangent, etc.) These functions generally produce an output in the range of 0 to 1 or -1 to 1. For each node, there are a series of weights and offsets to be calculated/tuned by the learning process.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/dnn.png&quot; alt=&quot;deep neural net&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The benefit of deep nets is that they can separate non-linear shapes, at the downside of long computation times and unreliable convergence of results. Also, results depend a lot on how error is measured, the function of each node, etc.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Back in the day, pre-training a neural network demonstrated that these could actually be trained efficiently, but since then other strategies have taken over. These include batch normalization and deep residual learning.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;mathematical-fundamentals-for-nns&quot;&gt;Mathematical Fundamentals for NN’s&lt;/h3&gt;

&lt;p&gt;A neural network (deep or otherwise), can be broken down into this simple equation:&lt;/p&gt;

\[y = h(x) = AF(b + Wx)\]

&lt;p&gt;Where $h(x) = y$ is the model to be trained, $b$ is some kind of offset (sometimes ignored), $W$ the set of weights to be calculated, $x$ the set of inputs, and $AF$ is some activation function. If this looks familiar, it’s because this is just a slightly modified linear regression! This mathematical basis should also reveal that neural networks are deterministic - the same input will always produce the same output!&lt;/p&gt;

&lt;p&gt;But what purpose does the non-linear activation function serve? Well it turns out, without the non-linearity of the activation function, the composition of two linear functions is just yet another linear function. In other words, the activation function is ultimately what allows a NN to accomplish complex tasks.&lt;/p&gt;

&lt;p&gt;Depending on the type of task we are training our Neural Network to do, there are different ways to encode our solution, which demand different types of activation functions, which demand different cost functions. These are outlined here:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Task&lt;/th&gt;
      &lt;th&gt;Output&lt;/th&gt;
      &lt;th&gt;Target Encoding&lt;/th&gt;
      &lt;th&gt;Activation Function&lt;/th&gt;
      &lt;th&gt;Cost Function&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Regression&lt;/td&gt;
      &lt;td&gt;Real&lt;/td&gt;
      &lt;td&gt;Real&lt;/td&gt;
      &lt;td&gt;Identity&lt;/td&gt;
      &lt;td&gt;Mean squared error&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Classification&lt;/td&gt;
      &lt;td&gt;Binary&lt;/td&gt;
      &lt;td&gt;0,1&lt;/td&gt;
      &lt;td&gt;Sigmoid&lt;/td&gt;
      &lt;td&gt;Cross Entropy&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Classification&lt;/td&gt;
      &lt;td&gt;Single Label&lt;/td&gt;
      &lt;td&gt;One-hot&lt;/td&gt;
      &lt;td&gt;Sigmoid&lt;/td&gt;
      &lt;td&gt;Cross Entropy&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Classification&lt;/td&gt;
      &lt;td&gt;Many Label&lt;/td&gt;
      &lt;td&gt;Many-hot&lt;/td&gt;
      &lt;td&gt;Softmax&lt;/td&gt;
      &lt;td&gt;Cross Entropy&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;Consider:&lt;/strong&gt; Why do we use one-hot encoding, and not just assign different numbers to things? For example, if we wanted to classify apples from bannanas from oranges, why can’t we use the labels 0, 1, 2?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Answer:&lt;/strong&gt; Numbers are in sequence, and when we encode three different objects as 0,1,2 we’ve accidently introduced the concept of order, where in reality there is none (sometimes).&lt;/p&gt;

&lt;h3 id=&quot;a-note-on-activation-functions&quot;&gt;A Note on Activation Functions&lt;/h3&gt;

&lt;p&gt;On hidden nodes, the ReLU or tanh function is almost always better than the sigmoid function.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Sigmoid Function&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The sigmoid function ranges from 0 to 1:&lt;/p&gt;

\[h(x) = \frac{1}{1-e^{-x}}\]

&lt;p&gt;&lt;strong&gt;Rectified Linear Unit - ReLU&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Unlike the tanh or sigmoid function which approaches a slope of zero at the extremes, ReLU maintains a constant slope, which usually allows machine learning algorithms to converge faster.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Tanh Function&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Hyperbolic tangent and unlike Relu or Sigmoid, this function ranges from -1 to 1.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Softmax&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The Softmax functions converts a vector of numbers into a vector of probabilities which sum to one. (Good for a final layer when making predictions)&lt;/p&gt;

&lt;h3 id=&quot;overfitting&quot;&gt;Overfitting&lt;/h3&gt;

&lt;p&gt;Overfitting is a common issue of machine learning algorithms, where we increase the accuracy with respect to the training data, at the cost of decreased predictive accuracy. This exists because we expect some random error in the training data. When an algorithm is overfit, it tries to accomodate this random noise, and can lose track of the global trends.&lt;/p&gt;

&lt;p&gt;An overfit model is also said to have high &lt;strong&gt;variance&lt;/strong&gt;. A tell-tale sign of high variance is having low error on the training set, but high error on the dev or test set.&lt;/p&gt;

&lt;h3 id=&quot;receiver-operator-characteristic-curve&quot;&gt;Receiver Operator Characteristic Curve&lt;/h3&gt;

&lt;p&gt;The R.O.C plots the probability of correct classification vs the probability of false positive. In an ideal case, the area under the curve will be equal to 1. A random guesser achieves a straight line on this plot, so a classifier needs to beat this result. Placement along the curve is also important, and changes depending on the application.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/roc.png&quot; alt=&quot;roc curve&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;embeddings&quot;&gt;Embeddings&lt;/h3&gt;

&lt;p&gt;Remember when we defined a one-hot encoding for our multi-classification tasks? One property of this method is that all encodings are equidistant from one another. This may be desireable sometimes, but in certain applications, this is not a good strategy. For example, in language processing, we’d like certain word pairs to be more closely associated than others (i.e. apple/orange vs apple/llama).&lt;/p&gt;

&lt;p&gt;To solve this problem, we can use &lt;em&gt;embeddings&lt;/em&gt; to represent distinct items. An embedding is a dense vector, where each dimension represents the “something-ness” of that class. For example, maybe the first dimension represents “animal-ness”, and the second represents “food-ness”.&lt;/p&gt;

&lt;p&gt;In practice, these dimensions are not defined by us, but identified through an algorithm (duh!) and don’t always reflect concepts we know. To create embedding vectors for each label, first let’s define some variables:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;O_i     #one-hot vector representing word [i]
E       #embedding matrix of shape (n,m)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Where n is the dimension of our embedding vectors, and m is the number of words. Then the embedded representation can be calculated with:&lt;/p&gt;

\[e_i = E \cdot O_i\]

&lt;p&gt;Next let’s frame the problem statement which will yield the embedding matric E. Given some context, we’d like to predict a target word to fit that context.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Inputs = e_1, e_2, e_3, ... e_7     //context
Outputs = e_t                       //target
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The input and output can be connected using a basic feed forward network, maybe something like this&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;layer1 = Dense(100, 70, ReLU)
layer2 = Softmax
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And finally, we initialize E with random variables, and allow the algorithm to train E along with the network.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;It turns out, if we’re only trying to learn embeddings, we don’t need that much “context” - it can be as little as a single random word selected from nearby the target! More context tends to be required if we’re also trying to learn a language model (with grammer).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;part-2---deep-learning-architectures&quot;&gt;Part 2 - Deep Learning Architectures&lt;/h2&gt;

&lt;p&gt;Deep learning algorithms are more powerful, but messier, versions of their linear algebra counterparts. A lot of optimization and more complex architectures are used to learn more abstract behaviors. A few common deep learning architectures are:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Feedforward NN’s&lt;/li&gt;
  &lt;li&gt;Autoencoders&lt;/li&gt;
  &lt;li&gt;Restricted Boltzman Machine&lt;/li&gt;
  &lt;li&gt;Recurrent Neural Network&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;multi-layer-nn-aka-feedforward-neural-network&quot;&gt;Multi-Layer NN aka Feedforward Neural Network&lt;/h3&gt;

&lt;p&gt;A Feedforward neural network is also your classic “deep” learning network. It’s called deep because there are additional hidden layers between the input and output. In general, adding more layers is not the same as adding more nodes to an existing layer, and the relationship between the two is still being explored today. That being said, adding more layers tends to be more efficient than adding more nodes to existing layers.&lt;/p&gt;

&lt;h3 id=&quot;batch-normalization-for-deep-nns&quot;&gt;Batch Normalization for Deep NN’s&lt;/h3&gt;

&lt;p&gt;When we train a neural network, we tune each node with the assumption that everywhere else remains static. In truth, the entire set of weights are changed in each step. This can be problematic for training deep networks, because when we tune weights in the early layers, we drastically change the distribution of inputs into the deeper layers. In this sense, we can end up “chasing a moving target” (to quote Jason Brownlee).&lt;/p&gt;

&lt;p&gt;The solution to this is called batch normalization. This simple idea is that we normalize the output of every layer (technically not the output, actually we normalize the input to the activation function). We then give this normalized distribution some trainable weight and bias, before it gets passed through.&lt;/p&gt;

\[\mu = \frac{1}{m} \sum z\]

\[\sigma^2 = \frac{1}{m} \sum (z-\mu)^2\]

\[z_{norm} = \frac{z-\mu}{\sqrt{\sigma^2 + \epsilon}}\]

\[\tilde{z} = \gamma z_{norm} + \beta\]

&lt;p&gt;Where \(\mu\) and \(\sigma\) are our normalization parameters, applied to an output &lt;em&gt;z&lt;/em&gt;. The epsilon is used to stabilize our fraction and avoid dividing by zero when \(\sigma\) is very small. Finally, \(\gamma\) and \(\beta\) are trainable weights. This scaled value, \(\tilde{z}\) is what gets passed into the activation layer. Notice that if we use \(\beta\) in this context, we don’t actually need &lt;em&gt;b&lt;/em&gt; later.&lt;/p&gt;

\[a = ReLU(w\tilde{z}+b)\]

&lt;h3 id=&quot;autoencoders&quot;&gt;Autoencoders&lt;/h3&gt;

&lt;p&gt;An autoencoders is a form of unsupervised learning. The goal is to compress and decompress information, which forces the algorithm to find key features to “encode” useful patterns. These can be implemented as a deep neural net, but one in which the output has the same dimension as the input. Additionally, the hidden layer(s) must have fewer nodes than either the input or output.&lt;/p&gt;

&lt;p&gt;There are two flavors of autoencoders:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Regularized autoencoders, or sometimes called sparse autoencoders, are effective for classification tasks.&lt;/li&gt;
  &lt;li&gt;Variational autoencoders use probability distributions instead of discrete variables, and are effective for generating new content.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;restricted-boltzmann-machine-rbm&quot;&gt;Restricted Boltzmann Machine (RBM)&lt;/h3&gt;

&lt;p&gt;A restricted Boltzmann machine has two layers - a visible layer, and a hidden layer. Every node between the two layers are connected, but none of the nodes within a layer are connected.&lt;/p&gt;

&lt;p&gt;The general idea behind a RBM is that there are hidden triggers which result in the data we see. The weights tie each cause (hidden layer) to each effect (visible layer). These result in probabilities, so we just have to tune our weights until the predicted probability of each event matches the probability distribution we see in our training data!&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The words “trigger” and “result-in” are here to illustrate the idea, but in reality no causal relationship is being proven here! A more accurate version would be to say that there are hidden “indicators” which “correlate to” the data we see.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;One advantage to unsupervised learning with an RBM is that results can be obtained with only a few examples. Today, training is performed using an algorithm called &lt;strong&gt;constrastive divergence&lt;/strong&gt;, which overcomes some of the scaling issues with RBM’s.&lt;/p&gt;

&lt;h3 id=&quot;recurrent-neural-networks-rnn&quot;&gt;Recurrent Neural Networks (RNN)&lt;/h3&gt;

&lt;p&gt;Before we jump into an RNN, consider a simple sentence generation program, which predicts the next word based only on the last word it encountered. Maybe the output looks something like this:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;gt; he drinks f(&quot;drinks&quot;)
&amp;gt; he drinks water f(&quot;water&quot;)
&amp;gt; he drinks water park f(&quot;park&quot;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This is clearly limited because each prediction is made without the context of the rest of the sentence (“drinks” and “water” go together, as does “water” and “park”, but all three certainly do not make sense together!). Flip this around in terms of a learning algorithm and you can run into the same problem.&lt;/p&gt;

&lt;p&gt;A recurrent neural networks is structured such that the output of a hidden layer is used as an additional input back into the same hidden layer. This allows them to learn based on the current AND previous state. But what does the previous state depend on? The state before that. So by recusion, an RNN learns on the entire sequence. Hence’s RNN’s are useful when data is temporal.&lt;/p&gt;

&lt;p&gt;The output layer of an RNN is usually just the input layer but shifted by one step. Think about it with this example: If the sequence to be predicted by the RNN is ABCD, then for every step of the sequence, a trained RNN would generate:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;y(A) = AB
y(AB) = ABC
y(ABC) = ABCD
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;See how the input sequence can also act as the labeled output used in a supervised learning algorithm?&lt;/p&gt;

&lt;p class=&quot;message&quot;&gt;
Long-Short Term Memory is the preferred training algorithm for RNN&apos;s. This helps reduce amplification or minimization due to recursion (e.g. 2 * 2 * 2 grows very quickly, while 0.5 * 0.5 * 0.5 shrinks very quickly). LSTM&apos;s also solve the issue of long term memory. Even though a basic RNN should &quot;in theory&quot; be able to remember information from long ago, in practice they are unable to. 
&lt;/p&gt;

&lt;p&gt;Also note, RNN’s can be bi-directional! This is good for natural language processing applications, where a word later in the sentence could be relevant to a word earlier in the sentence. The downside to a bi-directional RNN is that the complete sequence is required before an output can be created. This can be a problem for real-time applications.&lt;/p&gt;

&lt;h3 id=&quot;long-short-term-memory&quot;&gt;Long Short Term Memory&lt;/h3&gt;

&lt;p&gt;For this topic, I recommend reading colah’s blog post on &lt;a href=&quot;https://colah.github.io/posts/2015-08-Understanding-LSTMs/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;understanding LSTM’s&lt;/a&gt;. He explains it much better than I can, plus he’s got pictures to go along with.&lt;/p&gt;

&lt;p&gt;But in summary, within an LSTM there are two additional variables called the hidden state, and the cell state, which are used to carry long term, and short term signals respectively. A series of gates, like a forget gate and an update gate, determine how much these signals are modified at each step.&lt;/p&gt;

&lt;h3 id=&quot;attention-model&quot;&gt;Attention Model&lt;/h3&gt;

&lt;p&gt;An attention model is basically any model which includes an “attention parameter”. This is a learned variable which describes how “important” something is to something else.&lt;/p&gt;

&lt;p&gt;A basic implementation of attention might look like this.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/attentionmodel.png&quot; alt=&quot;Attention Model&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Where &lt;strong&gt;a&lt;/strong&gt; is the activation output from a bi-directional RNN, and &lt;strong&gt;S&lt;/strong&gt; is the state output from a forward only RNN. The input to each block &lt;strong&gt;S&lt;/strong&gt; will be called the &lt;em&gt;context&lt;/em&gt;, which is computed as the sum of attention weighted activations.&lt;/p&gt;

\[c^{&amp;lt;1&amp;gt;} = \sum_{t=1} \alpha^{&amp;lt;1,t&amp;gt;} a^{&amp;lt;t&amp;gt;}\]

&lt;p&gt;Since alpha is a weighting term, it also makes sense to make sure the vector of alphas will sum to one, like with a softmax function. Now that’s all set up, the only remaining question is how to actually compute each attention parameter. Turns out, this can be done by training a small neural network.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Input = S_t_prev, a_t
Output = e_t
model = Dense(2, 1)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Keeping in mind that the output &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;e_t&lt;/code&gt; needs to be passed through a softmax before we actually get alpha. By this point, you can probably tell that this is a lot of computation. The results are maybe better than something we could obtain with a simpler network, but this is a &lt;em&gt;quadratic&lt;/em&gt; time algorithm (very costly!).&lt;/p&gt;

&lt;h3 id=&quot;convolutional-neural-networks&quot;&gt;Convolutional Neural Networks&lt;/h3&gt;

&lt;p&gt;The principle of a CNN is that a smaller matrix (aka, kernel, feature detector, filter), is passed over (i.e. convolved ) with the raw data. This is repeated over and over, and eventually passed through a fully connected layer (like in regular Neural Networks).&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;In a sense, convolutional networks juxtapose recurrent networks. Where RNN’s are deep, CNNs are shallow.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The key to CNN’s is the kernel matrix. Different kernels can be trained to identify different “features” from the data, ranging from the very basic (e.g. an edge or a corner), to more advanced objects (e.g. an eye or a nose), and finally to the most high level (e.g. a face).&lt;/p&gt;

&lt;p&gt;CNN’s are an effective tool for processing very large images, that would take up too much memory using a standard deep neural net.  This is accomplished by:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Parameter sharing - only a few filters of all the same parameters are used everywhere.&lt;/li&gt;
  &lt;li&gt;Low connectivity - not every pixel depends on every other pixel, only its neighbors.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;cnn-is-3d&quot;&gt;CNN is 3D&lt;/h3&gt;

&lt;p&gt;Although we think of images as 2D, there are actually three layers in a standard RBG layer, one for each color. This means that images are actually (h, w, d) matrices, and when we perform convolutions, our filters also need to be three-dimensional.&lt;/p&gt;

&lt;p&gt;Because of how convolutions work, doing so shrinks the height and width of our image. To avoid this, we can add “padding” to the original image.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Valid - no padding&lt;/li&gt;
  &lt;li&gt;Same - enough padding to keep original dimensions.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The output image will have a number of channels equal to the number of filters we apply. So for instance, an input image that is (10, 10, 3), convolved with five filters that are (3, 3, 3), will produce an output of shape (8, 8,5 ), assuming that we did not add any padding.&lt;/p&gt;

&lt;h3 id=&quot;pooling-layer&quot;&gt;Pooling Layer&lt;/h3&gt;

&lt;p&gt;Pooling layers are “kernels” which use the function max or average. They are used to reduce the height and width of an input, but not the number of channels. This reduces the size of data.&lt;/p&gt;

&lt;h3 id=&quot;unit-or-pointwise-convolutions&quot;&gt;Unit or Pointwise Convolutions&lt;/h3&gt;

&lt;p&gt;Consider what happens when you use a (1x1) kernel. The output doesn’t get reduced in dimension, but the number of &lt;em&gt;channels&lt;/em&gt; is changed depending on the number of kernels. This type of convolution is often used to reduce the # of channels, and you can think of it as a channel-wise version of a pooling layer.&lt;/p&gt;

&lt;h3 id=&quot;transpose-convolution&quot;&gt;Transpose Convolution&lt;/h3&gt;

&lt;p&gt;Tranpose convolution is the opposite of regular convolution. Instead of shrinking the dimension of an input image, we increase the dimension by multiplying each input by a filter/kernel. This type of CNN is used when we start with something small, and want to increase its size.&lt;/p&gt;

&lt;p&gt;Semantic segmention is one such application for this type of convolution. In segmentation segmention, we often start with a regular CNN to first shrink/identify the input, and then grow it out again to it’s original dimension for pixel classification. In this particular case, semantic segmentation usually also involves the use of a skip connection. As we increase the image size, we re-incorporate earlier outputs from our CNN.&lt;/p&gt;

&lt;h3 id=&quot;residual-connections&quot;&gt;Residual Connections&lt;/h3&gt;

&lt;p&gt;In a deep convolutional neural network, a residual connection (or sometimes called a “skip connection”) is a connection from an earlier layer, to a later layer. For instance, the input to layer 4 is usually the output from layer 3, but a residual connection means it might also receive the output from layer 1 or layer 2. In effect, residual connections allows us to train deeper networks!&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Another way to think about these is that they work sort of like bypass diodes in a solar panel, which provide a path for the current to continue flowing, even if the cell becomes faulty.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;transformer-network-2017&quot;&gt;Transformer Network (2017)&lt;/h3&gt;

&lt;p&gt;A transformer network is a CNN inspired, attention-based approach to natural language processing. In a transformer network, we do away with the recursive component all together, and instead play a game of “word association”.&lt;/p&gt;

&lt;p&gt;To begin, let’s define a term called &lt;strong&gt;self-attention&lt;/strong&gt;. This is an attention based representation of a word. In contrast to embedding vectors which are static, these are context specific. For example, in a sentence containing the words &lt;em&gt;company&lt;/em&gt;, &lt;em&gt;phone&lt;/em&gt;, and &lt;em&gt;technology&lt;/em&gt;, we would guess that the world &lt;strong&gt;apple&lt;/strong&gt; is unlikely to refer to a fruit.&lt;/p&gt;

&lt;p&gt;We’ll make this a function of three parameters, q (query), K (Key), and V (Value). These are computed with a weight matrix and your input word.&lt;/p&gt;

\[A(q, K, V) = softmax\left(\frac{QK^T}{\sqrt{d_k}}\right)V\]

\[q^{&amp;lt;3&amp;gt;} = W^Q x^{&amp;lt;3&amp;gt;}\]

&lt;p&gt;Next, we would like to take the inner product of every query and key pair. This is akin to asking the question, “how relevant is this word towards the meaning of this other word?” (see how this is a type of &lt;em&gt;attention&lt;/em&gt;?). These query “answers” are first softmaxed, and then multiplied by each value to compute the total “self attention” of that word.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/transformer.jpg&quot; alt=&quot;Self Attention&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The next concept to discuss is &lt;strong&gt;multi-head attention&lt;/strong&gt;. Basically, we are recomputing the self-attention parameter for each word, but now with different weight matrices which determine q, K, and V. This is tricky, but the idea is that each “head” is asking a different relational question (e.g. what, when, how, why, etc.). Having multiple “heads” allows for a richer representation of the sentence.&lt;/p&gt;

&lt;p&gt;And finally, to put this all together towards an actual translation algorithm, a number of these multi-head attention blocks are set up in an encoder/decoder structure. For more details, you can check out the original paper, called &lt;em&gt;Attention Is All You Need&lt;/em&gt; by Vaswani (2017).&lt;/p&gt;

&lt;h3 id=&quot;compound-architectures&quot;&gt;Compound Architectures&lt;/h3&gt;

&lt;p&gt;In recent years, many people have proposed combined approaches, which make use of more than one architecture. There is for instance, something called an RNN Encoder-Decoder, which attempts to learn the relationship between two different encodings of two different sequences.&lt;/p&gt;

&lt;p&gt;Or to express it another way, the goal is to encode the sequence learned by one RNN into another sequence produced by another RNN. The main application here being translation, where two languages expressing the same idea can have entirely different lengths and grammers.&lt;/p&gt;

&lt;h3 id=&quot;generative-adversarial-modeling&quot;&gt;Generative Adversarial Modeling&lt;/h3&gt;

&lt;p&gt;A generative adversarial model, or GAN, is a method to train a generative modeling algorithm. GAN’s consist of two parts - a generative model to create plausible examples, and a supervised learning/classifier that tries to distinguish the fake ones from the real ones. They are trained against one another (hence adversarial), until the classifier is no longer able to distinguish between the two.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Tuning ML for Performance</title>
   <link href="https://ludavid15.github.io//mltuning/"/>
   <updated>2022-09-20T00:00:00-07:00</updated>
   <id>https://ludavid15.github.io//mltuning</id>
   <content type="html">&lt;p&gt;In practice, machine learning algorithsm can be tricky to setup and tune. This post discusses the different metrics you can use to evaluate your algorithm, and how to fine-tine your setup based on how those metrics perform.&lt;/p&gt;

&lt;h3 id=&quot;hyper-parameters&quot;&gt;Hyper Parameters&lt;/h3&gt;

&lt;p&gt;Your hyper parameters are governing parameters that shape your architecture. This includes things like your step size, regularization parameters, number of hidden units, and number of hidden layers (among other things!).&lt;/p&gt;

&lt;p&gt;There’s no telling what combination of parameters might be most effective, and in fact there are so many possibilities that a methodical search is often too expensive to perform. Rather, a random approach might get you to a better solution faster.&lt;/p&gt;

&lt;h3 id=&quot;training-dev-and-test-data-sizes&quot;&gt;Training, Dev, and Test Data Sizes&lt;/h3&gt;

&lt;p&gt;For very large datasets (hundreds of thousands or millions), it usually makes sense to put the majority of your data towards training, like a 96/2/2 split.&lt;/p&gt;

&lt;p&gt;With smaller datasets, you need to make sure that your dev and tests sets are large enough to still cover a full distribution of cases, so a 70/20/10 split might be more appropriate.&lt;/p&gt;

&lt;p&gt;Then there’s also the unique case of &lt;strong&gt;one-shot learning&lt;/strong&gt;, where you might have only one or two examples for each label (like with face recognition). The key to this type of problem is to re-examine your architecture. Rather than training an algorithm to identify each face (like in a classification problem), you can train an algorithm to tell if two pictures show the same person. (Do you see how by reframing the question we increase the effective data set size?)&lt;/p&gt;

&lt;h3 id=&quot;high-bias&quot;&gt;High Bias&lt;/h3&gt;

&lt;p&gt;High bias means that we’ve underfit the data, and failed to capture some important, high-level trends in our data. Your bias is the difference between the training set error, and the bayes error.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Bayes error is the minimum possible error, and indicates some inherent ambiguity in the data. No algorithm or human can achieve an error below the “bayes” error.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The solution to high bias is often to use a bigger network, or to change up your architecture entirely.&lt;/p&gt;

&lt;h3 id=&quot;high-variance&quot;&gt;High Variance&lt;/h3&gt;

&lt;p&gt;High variance means that we’ve overfit the data, and are capturing too much noise. The best solution to a high variance result is to increase your data set, or to try regularization. A third, less recommended approach, is to try early stopping, where you stop training the network before you’ve actually minimized the cost. The principle here is that additional gains are actually achieved by fitting to the noise, so if we stop before this point, we can avoid overfitting. While effective, this can be problematic because it forces us to trade-off between bias and variance - a compromise that we (and not the data) are forcing on ourselves.&lt;/p&gt;

&lt;p&gt;Variance is typically the difference between your training error, and dev error.&lt;/p&gt;

&lt;h3 id=&quot;regularization&quot;&gt;Regularization&lt;/h3&gt;

&lt;p&gt;Regularization is a method for reducing overfitting, or high variance. The basic principle is that the sum of all weights are added into the cost function, thereby encouraging the algorithm to keep weights small.&lt;/p&gt;

\[Cost(w,b) = \frac{1}{m} \displaystyle \sum_{i=1}^m L(\hat{y}, y) + \frac{\lambda}{2m} \|w\|_2^2\]

&lt;p&gt;Another way to achieve regularization is using something called &lt;strong&gt;dropout regulization&lt;/strong&gt;. While training, we randomly remove some nodes in the network. This way, we’re effectively training many smaller networks instead. The result is a more evenly distributed set of weights.&lt;/p&gt;

&lt;h3 id=&quot;precision-and-recall&quot;&gt;Precision and Recall&lt;/h3&gt;

&lt;p&gt;Precision and Recall are two common parameters used for classification and identification tasks.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Precision - how much of your calculated result was right?&lt;/li&gt;
  &lt;li&gt;Recall - how much of all that was right did you calculate?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;They can be combined into something known as an F1 score.&lt;/p&gt;

\[F = 2 \cdot \frac{P*R}{P+R}\]

&lt;p&gt;In practice, it’s nice to have a single numeric value for evaluation, because then you can optimize for it. The tricky bit is figuring out what the right metric is.&lt;/p&gt;

&lt;h3 id=&quot;mini-batch-gradient-descent&quot;&gt;Mini-Batch Gradient Descent&lt;/h3&gt;

&lt;p&gt;A mini-batch is a subset of your total training data. By calculating the cost and gradient on less data, we can perform this operation faster, and take a descent step before laboriously computing the total cost across all our data (which can be a lot!).&lt;/p&gt;

&lt;p&gt;Instead of randomly pulling data for each mini-batch, we usually just shuffle our training set, and then take chunks of data in order. This makes sure we use all our data at some point. Once all mini-batches have been used to make a descent step, that’s called 1 &lt;strong&gt;epoch&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Also for computer architecture reasons, we often size batches by squares of two (64, 128, 256, etc.). In fact, you usually don’t need your batches to be much larger than 256 or sometimes 512.&lt;/p&gt;

&lt;h3 id=&quot;transfer-learning&quot;&gt;Transfer Learning&lt;/h3&gt;

&lt;p&gt;Transfer learning works best when you lack data for your specific task, but know what there is plenty of data for a different but similar task. For instance, let’s say you are making a cat classifier, but lack cat images. However, you have plenty of animal and non-animal images. To use transfer learning, you would initalize and train a classifier first on the second task, and then fine tune those weights for your cat classifier.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Communications Technology</title>
   <link href="https://ludavid15.github.io//Communications/"/>
   <updated>2022-07-09T00:00:00-07:00</updated>
   <id>https://ludavid15.github.io//communications</id>
   <content type="html">&lt;p&gt;A random assortment of communications technology terms I’ve encountered over the years. Please keep in mind that electrical engineering and signal processing is &lt;em&gt;not&lt;/em&gt; one of my subjects, so take everything here with a grain of salt.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h4 id=&quot;ml-std-1553&quot;&gt;ML-STD 1553&lt;/h4&gt;

&lt;p&gt;A traffic control protocol for managing information traffic from multiple sources on a shared physical line. 1553 requires a controlling bus computer (BC) and an addresses for each terminal. The underlying constraint of 1553 is that traffic is never parrallel. In other words, each terminal takes turns using the line, and ignores any information on the line while not actively in use. On any given 1553 line, there can be up to 31 &lt;em&gt;remote terminals&lt;/em&gt; (RTs), each with their own &lt;em&gt;subaddresses&lt;/em&gt;. A number of messages types are defined:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Controller to RT&lt;/li&gt;
  &lt;li&gt;RT to Controller&lt;/li&gt;
  &lt;li&gt;RT to RT&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;bi-level&quot;&gt;Bi-Level&lt;/h4&gt;

&lt;p&gt;Consisting of two states (i.e. 0 and 1). In constrast to &lt;em&gt;analog&lt;/em&gt;.&lt;/p&gt;

&lt;h3 id=&quot;serial-communication&quot;&gt;Serial communication&lt;/h3&gt;

&lt;p&gt;Commmunication that consists of sending data one bit at a time.&lt;/p&gt;

&lt;h4 id=&quot;rs-422&quot;&gt;RS-422&lt;/h4&gt;

&lt;p&gt;A point to point interface which transmits digital/bi-level information by changing the difference in voltage between two lines. This allows for higher data rates and lower noise in comparison to a single voltage line because we can achieve the same total change in the difference with only half the voltage change in each line. This is comparable to things like ethernet or USB.&lt;/p&gt;

&lt;h4 id=&quot;parity&quot;&gt;Parity&lt;/h4&gt;

&lt;p&gt;A single bit which tells you if there is an even or odd number of 1’s in the transmitted signal. Used to check the integrity of a message.&lt;/p&gt;

&lt;h3 id=&quot;hardware&quot;&gt;Hardware&lt;/h3&gt;

&lt;h4 id=&quot;traveling-wave-tube-amplifier&quot;&gt;Traveling Wave Tube Amplifier&lt;/h4&gt;

&lt;p&gt;Often abbreviated to just TWTA, this is a device used for amplifying radio signals. Satellites often need this since they communicate over large distances.&lt;/p&gt;

&lt;h4 id=&quot;waveguide&quot;&gt;Waveguide&lt;/h4&gt;

&lt;h4 id=&quot;coax-cable&quot;&gt;Coax-Cable&lt;/h4&gt;

</content>
 </entry>
 
 <entry>
   <title>Agile Engineering</title>
   <link href="https://ludavid15.github.io//agileEngineering/"/>
   <updated>2022-06-14T00:00:00-07:00</updated>
   <id>https://ludavid15.github.io//agile</id>
   <content type="html">&lt;p&gt;A few notes on the Agile method for engineering, based on on my own experience working on an “agile” team and Google’s Agile Project Management class on Coursera.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h3 id=&quot;personal-impressions-of-agile&quot;&gt;Personal Impressions of Agile:&lt;/h3&gt;

&lt;p&gt;Before getting into the details, just a few of my personal impressions on agile and scrum.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Agile is all about trusting in people. It’s the belief that capable individuals will deliver better products. To this end, everything in agile is designed to make individuals feel empowered, supported, and motivated. It encourages people to think for themselves, and to think critically, instead of relying on tradition.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;In the absense of process and planning, something is needed to guide people towards an objective. This is achieved by literally that - a reminder to everyone that the objective is more important than any plan or process designed to get you there.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Ironically, rules or processes designed to promote agile can be inherently un-agile. Agile is a culture, not a process.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Agile can be rather “capitalist”. The disregard of rules and tradition usually benefits those who are loudest or already in power. Maybe rules and processes slow down a project, but they also protect people who are vulnerable. As with all things, there’s a balance to be struck.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;vuca&quot;&gt;VUCA&lt;/h3&gt;

&lt;p&gt;Before adopting an agile product management strategy, consider if agile is right for your project. An easy acronym to use is VUCA, which stands for:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Volatility - rate of change in an industry&lt;/li&gt;
  &lt;li&gt;Uncertainty - lack of predictability&lt;/li&gt;
  &lt;li&gt;Complexity - high number of interelated forces&lt;/li&gt;
  &lt;li&gt;Ambiguity - lack of definition&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Agile is best suited for project that have high VUCA (volatility, uncertainty, complexity, and ambiguity). In constrast, if you are working in an industry that is steady, well-defined and simple, waterfall may be a better strategy.&lt;/p&gt;

&lt;h3 id=&quot;scrum&quot;&gt;Scrum&lt;/h3&gt;

&lt;p&gt;Scrum is a framework (alongside things like Kanban, XP, or lean) that implements the principles of agile. Within a Scrum organization, there are three roles.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The &lt;strong&gt;Product Owner&lt;/strong&gt; acts like the customer, and sets the content of what to make. The product owner also prioritizes the backlog and promotes transparency with the development team.&lt;/li&gt;
  &lt;li&gt;The &lt;strong&gt;Development Team&lt;/strong&gt; builds the product. A team should be self-organized, customer-oriented, and cross-functional.&lt;/li&gt;
  &lt;li&gt;The &lt;strong&gt;Scrum Master&lt;/strong&gt; facilitates the team and helps them work better (mostly through the practice of agile principles).&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;backlog&quot;&gt;Backlog&lt;/h3&gt;

&lt;p&gt;The backlog is an outline of all the work there is to be done. For each item, consider adding a priority level, work estimate, and value added metric. The product owner is typically responsible for keeping the backlog updated and sorted.&lt;/p&gt;

&lt;p class=&quot;message&quot;&gt;
Descriptions of each item are usually presented as a &quot;user story&quot;. This is an effective way to define tasks because it describes the &quot;what&quot; without stipulating the &quot;how&quot;. This gives the development team ownership of the task, and ensures they keep vision of the goal, and not get bogged down by following a set of instructions. In systems engineering terms, this would be like using the validation field of a requirement in place of the requirement itself.  
&lt;/p&gt;

&lt;p&gt;To judge an effective user story description, consider if it is:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Independent - completion of this story is not dependent on another one&lt;/li&gt;
  &lt;li&gt;Negotiable - leave room for change&lt;/li&gt;
  &lt;li&gt;Valuable - should clearly explain the value delivered&lt;/li&gt;
  &lt;li&gt;Estimable - should have a clear definition of done so it is estimable&lt;/li&gt;
  &lt;li&gt;Small - should be completable within a single sprint&lt;/li&gt;
  &lt;li&gt;Testable - is specific enough to verify&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;User stories often follow the structure of:&lt;/p&gt;

&lt;p&gt;As a &lt;strong&gt;user&lt;/strong&gt;, I want to &lt;strong&gt;action&lt;/strong&gt; so that I can &lt;strong&gt;value&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&quot;sprints&quot;&gt;Sprints&lt;/h3&gt;

&lt;p&gt;In scrum, the workflow is broken up into periods called sprints. At the start of every sprint, we set an objective (based on past velocity) about what we will accomplish. We work towards that goal, and then at the end we review our product and process. The review is an especially important piece of the sprint since that’s what allows us to make improvements.&lt;/p&gt;

&lt;h3 id=&quot;pitfalls&quot;&gt;Pitfalls&lt;/h3&gt;

&lt;p&gt;Here are a few pitfalls, which can derail the original design intent of some agile practices (and remember, following a process without knowing the reason is step number one towards bad design and delays).&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Velocity measures the average sprint pace. This assumes that in each sprint we are completing the tests needed to deliver a completed story. If we’re pushing the testing out, then it’s likely that our velocity eventually plateaus.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Velocity is NOT a measure of total team performance, and it shouldn’t be. Ultimately what matters is the value delivered. Not to mention that this practice can create some really bad work cultures.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Scrum makes use of user stories because they keep the team focused on the end product, and allow room for innovative solutions. Unless you’re on a service team, you should focus on the “why” of your goals, and not the “how”.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;devops&quot;&gt;DevOps&lt;/h3&gt;

&lt;p&gt;DevOps is an approach to software engineering that brings together the development team with the operations support team. The goal of this collaboration is to build a more direct path between the two.&lt;/p&gt;

&lt;h3 id=&quot;scaling-agile&quot;&gt;Scaling Agile&lt;/h3&gt;

&lt;p&gt;Since scrum teams work best for groups of 5 to 10 people, larger product teams need an adapted agile system. Common big-group agile structures include:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Scaled Agile Framework (SAFe)&lt;/li&gt;
  &lt;li&gt;Scrum of Scrums&lt;/li&gt;
  &lt;li&gt;Large Scale Scrum (LeSS)&lt;/li&gt;
  &lt;li&gt;Disciplined Agile Delivery (DAD)&lt;/li&gt;
  &lt;li&gt;Spotify Model (of Squads, Tribes, Chapters, and Guilds)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;But in general, it’s important to remember that Agile is all about being flexible to deliver value. These frameworks are NOT meant to be definitive instruction manuals or a process to be followed. Instead, seek a balance of strategies and values that work best for your particular situation.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Music and AI - Part 2</title>
   <link href="https://ludavid15.github.io//musicAI2/"/>
   <updated>2022-05-04T00:00:00-07:00</updated>
   <id>https://ludavid15.github.io//musicAI2</id>
   <content type="html">&lt;p&gt;This post goes over a few different approaches to music generation with deep learning.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;part-1---single-step-feedforward-learning&quot;&gt;Part 1 - Single Step Feedforward Learning&lt;/h2&gt;

&lt;p&gt;These architectures do not ingest music one step at a time, but rather ingest a chunk all at once. While straightforward, a major limitation of this method is that it’s difficult to produce musical phrases of variable length. It’d be like deciding ahead of time how many words are allowed in each sentence.&lt;/p&gt;

&lt;h3 id=&quot;11---introduction-with-bach&quot;&gt;1.1 - Introduction with Bach&lt;/h3&gt;

&lt;p&gt;For the first example, we’ll walk through a very simple and intuitive deep learning setup. Here are the parameters:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Music Structure&lt;/strong&gt; - 4 measures of SATB in 4/4 time&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;ML Architecture&lt;/strong&gt; - Feedforward neural network with 1 hidden layer&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Input&lt;/strong&gt; - (One hot encoding for pitch at each time step) x number of input voices&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Output&lt;/strong&gt; - (One hot encoding for pitch at each time step) x number of output voices&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Training Data&lt;/strong&gt; - Bach chorales, with each voice extracted and transposed into all keys.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Even before we consider the musical merit of any generated output, we can notice that there will be intrinsic limitations to this method. First, it is deterministic. For each unique input there will only ever be 1 output. Maybe this ok for something like this, but what if our input was a chord progression and our desired ouput was a melody? Many different melodies are possible for the same progression. Here we run into our first challenge - how can we generate a wide variety of content from limited inputs? (&lt;em&gt;creatio ex-nihilo&lt;/em&gt; and content variability)&lt;/p&gt;

&lt;p&gt;The next two examples are ways around this issue.&lt;/p&gt;

&lt;h3 id=&quot;12---encoderdecoder&quot;&gt;1.2 - Encoder/Decoder&lt;/h3&gt;

&lt;p&gt;The basic idea here is to first train an autoencoder, which if you remember, learns the important “features” in its hidden layer. To generate unique outputs, we simply turn this around - the hidden layer becomes the input (i.e. a seed). The seed is fed-forward through the decoder, and we get a unique output. Of course this is still deterministic, but it overcomes the &lt;em&gt;creatio ex-nihilo&lt;/em&gt; issue. (Technically we’re not starting from &lt;em&gt;true nothing&lt;/em&gt;, but then what does? Most randomly generated content, like a minecraft world, starts from a seed anyway).&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The DeepHear system by Sun uses this approach to generate ragtime music. They use Scott Joplin songs as the training data, and a stacked autoencoder with a hidden layer size of 16. Due to the small size of this hidden layer, there is a high amount of plagiarism (around 60%).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;part-2---sequential-models&quot;&gt;Part 2 - Sequential Models&lt;/h2&gt;

&lt;p&gt;These architectures treat the data sequentially. Once advantage of structuring a model this way is that you can produce music of variable length. Most are implemented with some kind of RNN.&lt;/p&gt;

&lt;h3 id=&quot;21---a-basic-rnn-with-lstm&quot;&gt;2.1 - A Basic RNN with LSTM&lt;/h3&gt;

&lt;p&gt;An example of this sequential approach was implemented by Eck and Schmidhuber in their 12 bar blues program. The input and output layer both have 25 nodes (13 for notes and 12 for chords) with a hidden layer of eight LSTM blocks. The hidden layer connections are as follows:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Chord block is fully connected to everything in the input and the chord output.&lt;/li&gt;
  &lt;li&gt;Melody block is fully connected to everything in the input, and melody output.&lt;/li&gt;
  &lt;li&gt;Chord block is recursive with itself and melody.&lt;/li&gt;
  &lt;li&gt;Melody block is recursive only with itself.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The asymmetric architecture is used to control the dependency of chords and melody. In this case, the chords are dependent on the melody, but not vice-versa.&lt;/p&gt;

&lt;h3 id=&quot;22---bi-directional-lstm-for-accompaniment&quot;&gt;2.2 - Bi-Directional LSTM for Accompaniment&lt;/h3&gt;

&lt;p&gt;A Bi-directional RNN uses data from both before and after the target timestep to make predictions. This makes sense when generating music, since motifs or themes are often repeated.&lt;/p&gt;

&lt;p&gt;One such way to use a BLSTM is to generate a progression of chords as an accompaniment to a melody.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Input encoding: one-hot for each of 12 pitches&lt;/li&gt;
  &lt;li&gt;Output encoding: one-hot for each minor and major triad of 12 pitches (24 total)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;23---rnnrbm-polyphany-generation&quot;&gt;2.3 - RNN/RBM Polyphany Generation&lt;/h3&gt;

&lt;p&gt;Ok, we’ve introduced a few architectures, but we haven’t really factored in anything about music yet. Music theory offers many ideas through which we can understand the structure and shape of songs, so why not incoporate them into our architecture?&lt;/p&gt;

&lt;p&gt;To begin, let’s start with the basic differentiation of melody and harmony. From a music theory perspective, there are two dimensions to a song: the vertical and the horizontal. Vertical is the pairing of melody with harmony, while horizontal is the change from one time step to the next.&lt;/p&gt;

&lt;p&gt;The idea of a coupled RNN-RBM is to cover both of these aspects:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;The RNN generates content in the horizontal dimension&lt;/li&gt;
  &lt;li&gt;The RBM models the probability distribution of melody/chord pairs in the vertical dimension.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This strategy designs an archictecture based on an understanding of music theory (i.e. that melody and harmony support each other). In this way, it is unique to some of the other strategies that have been outlined, which begin from other perspectives.&lt;/p&gt;

&lt;p class=&quot;message&quot;&gt;

Question for you: if music has two dimensions, that makes it just like an image right? Why can&apos;t we just apply existing image-based AI algorithms to a piano roll?

The surprisingly intuitive answer is that in music (and unlike in images), the vertical and horizontal dimensions are not equivalent. In a picture, both dimensions are length, but in a piano roll, one dimension is pitch and the other is time. 

That being said, Convolutional Neural Networks - which have been very effective for image processing - are not useless for music generation... we just have to find creative ways to apply it.

&lt;/p&gt;

&lt;h3 id=&quot;24---rnnrnn-polyphany-generation&quot;&gt;2.4 - RNN/RNN Polyphany Generation&lt;/h3&gt;

&lt;p&gt;This is nearly identical to the architecture in example 7, but the vertical dimension is modeled by another RNN, instead of an RBM.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;For an example of this implementation, see the Bi-Axial LSTM archicture proposed by Daniel Johnson “Generating Polyphonic music using tied parallel networks” (2017).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;part-3---hybrid-approaches&quot;&gt;Part 3 - Hybrid Approaches&lt;/h2&gt;

&lt;p&gt;Although RNN’s are great for sequential data, music actually tends to have a bit more structure than language. Songs are not one monolithic piece from start to finish, but rather are organized into sections, often with recurring motifs (e.g. AABA, Sonata, Etude, etc.).&lt;/p&gt;

&lt;p&gt;This kind of repeating structure is actually really well captured by things like convolutional neural networks or encoders. So can we get the best of both worlds by using both a sequential and single-step architecture?&lt;/p&gt;

&lt;h3 id=&quot;31---variational-recurrent-autoencoder&quot;&gt;3.1 - Variational Recurrent Autoencoder&lt;/h3&gt;

&lt;p&gt;Often, structure is intentionally withheld from music writing AI’s because it’s very difficult to learn high level structures simultaneously with low-level harmony and melodic style.&lt;/p&gt;

&lt;p&gt;MusicVAE is a variational recurrent autoencoder with a 2-level heirarchical RNN within the decoder. The introduction of an additional level improves the algorithm’s ability to learn structure. This allows it to generate longer sequences of music with better overall cohesion.&lt;/p&gt;

&lt;p&gt;The first level within the hierarchy deals with low level concepts, like a musical phrase, while the second (higher) level deals with musical structure. (Technically, there is nothing that forces this association, but the hope is that by designing the archicture this way, the network will also learn this concept when it is trained).&lt;/p&gt;

&lt;h2 id=&quot;part-4---miscellaneous&quot;&gt;Part 4 - Miscellaneous&lt;/h2&gt;

&lt;h3 id=&quot;41---style-transfer&quot;&gt;4.1 - Style Transfer&lt;/h3&gt;

&lt;p&gt;Style transfer is an active field of image processing, but hasn’t been explored very much in music. Musicians do this all the time in real life, (e.g. rearranging a pop song into a waltz, copying a jazz pianists style, or remixing a song into lo-fi). Conceptually, we can think about two types of style transfer:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Composition structure (e.g. time signature, song structure)&lt;/li&gt;
  &lt;li&gt;Performance style (e.g. different style of harmony, embellishments. Think how different jazz pianists can approach the same standard in dramatically different ways)&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;And that’s it! A quick overview of different architectures that researchers have used to tackle music generation. In the next post, we’ll take a look at specific challenges and more practical considerations for if you wanted to deploy a production model.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Systems Engineering</title>
   <link href="https://ludavid15.github.io//systemsEngineering/"/>
   <updated>2022-05-04T00:00:00-07:00</updated>
   <id>https://ludavid15.github.io//systems</id>
   <content type="html">&lt;p&gt;If you’ve ever tried to manage a highly complex project, you know that a certain amount of organization is required. This kind of big-picture planning helps to reduce risk. However, it’s important to remember that this kind of oversight ultimately serves the product. There is such a thing as too much management.&lt;/p&gt;

&lt;p&gt;This is the balance to be struck in the world of systems engineering. Systems engineering is a set of practices for developing highly complex projects while minimizing risk. It is NOT a substitute for good communication or for responsible people (though it can help).&lt;/p&gt;

&lt;!--more--&gt;

&lt;h3 id=&quot;requirements&quot;&gt;Requirements&lt;/h3&gt;

&lt;p&gt;Requirements have been the backbone of aerospace systems engineering for a few decades now. The basic idea is that we write down a complete list of everything our project needs to do, and then break them down piece by piece. The idea is sound, but the execution gets messy very quickly, and is more art than science.&lt;/p&gt;

&lt;p&gt;Let’s consider an example. Say we are trying to design a rocketship to Mars. We might define a few high level requirements that read:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The rocket shall carry 4 astronauts&lt;/li&gt;
  &lt;li&gt;The rocket shall be able to complete the mission in 2 years.&lt;/li&gt;
  &lt;li&gt;The rocket shall use electric propulsion systems.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Taking the first requirement, we can break it down logically into necessary components. This process then gets repeated over and over until we reach a good level of detail, or more likely, until we can’t be bothered to keep going.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The rocket shall include a life support system to recycle oxygen.&lt;/li&gt;
  &lt;li&gt;The rocket shall include 5000 cubic feet of living space for the astronauts.&lt;/li&gt;
  &lt;li&gt;The rocket shall carry 3000 lbs of food and living equipment.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Once all the requirements have been written, design work begins. The engineers build the rocketship exactly to spec, ahead of schedule and under budget, and then we fly to Mars. Err, ok maybe not. Before we launch we need to validate and verify that everything is good to go.&lt;/p&gt;

&lt;h3 id=&quot;validation-and-verification&quot;&gt;Validation and Verification&lt;/h3&gt;

&lt;p&gt;The process of ensuring the design meets the expectation is known as the validation and verification step. &lt;strong&gt;Verification&lt;/strong&gt; checks to see that the design satisfies the exact wording of the requirement. For example, we can measure the interior space of our rocket, and if we find that there is indeed 5000 cubic feet, we have verified that requirement. &lt;strong&gt;Validation&lt;/strong&gt; checks that we’re meeting the spirit of the requirement. In this case, the intent of this requirement is to provide astronauts with enough living space, but is 5000 really enough? What if the 5000 cubic feet is in the form of a 1 ft x 1 ft x 5000 ft narrow tube? Such a design would not meet the intent of the requirement, even though technically it satisfied the exact wording.&lt;/p&gt;

&lt;p&gt;There aren’t really any rules on how a requirement should be written, but usually requirements do one of three things:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Define some desired function/feature (ex: shall send telemetry)&lt;/li&gt;
  &lt;li&gt;Define how well something has to be done (ex: shall be operational up to 100 deg)&lt;/li&gt;
  &lt;li&gt;Define an aspect of the design (ex: shall operate at 30V)&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;why-requirements&quot;&gt;Why Requirements?&lt;/h4&gt;

&lt;p&gt;My personal opinion of requirements is that they exist as a document of wants, agreed upon by the stakeholders. If I want or need A, I’ll go to you, we can talk it over, and we write this down into our requirements document.&lt;/p&gt;

&lt;p&gt;This may be a good way to track our needs, (potentially comparable to “user stories” from agile), but I think we shouldn’t imagine requirements to necessarily be a good model of your design. In other words, it’s important for your model to meet the requirements, but the requirements are not for organizing your design.&lt;/p&gt;

&lt;h3 id=&quot;requirements-in-practice&quot;&gt;Requirements in Practice&lt;/h3&gt;

&lt;p&gt;In real life, we often do not build things up from scratch. Instead a project is often an addition to, or a modification of something that already exists. Even though this is meant to simplify the process, it also creates a lot of additional work (as anyone who has tried to read someone else’s code can testify). For this situation, there are often requirements which outline a specific design (i.e. shall use ABC hardware).&lt;/p&gt;

&lt;h3 id=&quot;requirement-pitfalls&quot;&gt;Requirement Pitfalls&lt;/h3&gt;

&lt;p&gt;Just a few other things to watch out for when writing requirements.&lt;/p&gt;

&lt;h4 id=&quot;1-negatives&quot;&gt;1. Negatives&lt;/h4&gt;

&lt;p&gt;Requirements that specify what &lt;em&gt;not&lt;/em&gt; to do can be difficult to verify. For instance, “shall not fail under xxx circumstances” requires a lot of definition about what exactly these circumstances are.&lt;/p&gt;

&lt;h4 id=&quot;2-subjective-goals&quot;&gt;2. Subjective Goals&lt;/h4&gt;

&lt;p&gt;This is intuitive, but requirements should not be subjective. “Shall be satisfactory” is vague. Good according to who? Again, being verifiable is important.&lt;/p&gt;

&lt;h4 id=&quot;3-not-including-rationale&quot;&gt;3. Not Including Rationale&lt;/h4&gt;

&lt;p&gt;Even a perfectly good requirement can be challenging if there’s confusion about why it exists. I promise that no matter how good your memory is, if you come back to a requirement many months later you’ll be glad to have a rationale section. For instance, maybe a requirement was derived from a user study, but 2 years later, that study was proven to be unreliable. For situations like this, a rationale blurb would let you know quickly if a requirement is still relevant.&lt;/p&gt;

&lt;h4 id=&quot;4-requirements-that-are-constraints&quot;&gt;4. Requirements that are Constraints&lt;/h4&gt;

&lt;p&gt;Another deceptively complex situation is to have a requirement that defines a constraint. For instance, “the satellite shall operate normally under xxx constraints”. Ok, seems easy. But what if another part of the design fails to keep us within these constraints? Technically, we’ve still met this first requirement. We’re just never operational, but that’s ok because we’re outside the limit. If you have a requirement like the first one, you’d better have a second requirement which defines availability, “the satellite shall be operational for 75% of the day”.&lt;/p&gt;

&lt;h3 id=&quot;design-reviews&quot;&gt;Design Reviews&lt;/h3&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Preliminary Design Review (PDR)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;PDR is the first major “design” checkpoint. This means that an idea for a part has matured into a design for that part. By PDR, you should be able to demonstrate that your design is going to meet all your requirements, at least in theory.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Critical Design Review (CDR)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;In short, your CDR is the last checkpoint before moving on to fabrication, integration, and testing. By CDR, your design should be baselined, and you should be fairly confident that what you’re building will work. This usually means plenty of analysis. You should also have a plan for how you are going to manufacture or acquire all your hardware.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;operations&quot;&gt;Operations&lt;/h3&gt;

&lt;p&gt;Also known as functions or activities, operations are used to explain &lt;em&gt;how&lt;/em&gt; something is done. This could be for the benefit of a designer, an operator, or even a computer. Depending on the user, this can also be detailed to different resolutions, ranging from the abstract, to the very specific (like individual command messages).&lt;/p&gt;

&lt;p&gt;Some Operations Documents:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Concept of Operations (CONOPS)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;A high level overview which outlines the overall goals and objectives. Usually includes context or rationale for why things are the way they are. This is frequently a user or customer facing document.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Mission Operations Document (MOD)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;A more detailed outline of your procedures than the CONOPS. A MOD can provide specific details about what your hardware (or an operator) needs to do. This is something you might hand to a responsible engineer to turn into code.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Recommended Operating Procedures (ROP)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;The most detailed document of the three, a ROP is as detailed as you can get before actually implementing a solution. For things like commanding or telemetry, a ROP can be as specific as the individual bits in a dataframe. In an OSI context, this means going down to the Data Link Layer (layer 2). Unlike a CONOPS document or MOD, a ROP can include fault management/anomaly response procedures.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

</content>
 </entry>
 
 <entry>
   <title>Linear Algrebra</title>
   <link href="https://ludavid15.github.io//linearAlgebra/"/>
   <updated>2022-03-30T00:00:00-07:00</updated>
   <id>https://ludavid15.github.io//linearAlgebra</id>
   <content type="html">&lt;p&gt;We’ve mentioned before that machine learning is really just glorified regression. But neural networks are just one way to do this. If we’re working with matrices, linear algrebra gives us many ways to extract patterns from our data as well.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h3 id=&quot;matrix-fundamentals&quot;&gt;Matrix Fundamentals&lt;/h3&gt;

&lt;p&gt;Before getting into the more interesting/complicated math, let’s start by defining a few terms.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Vector&lt;/strong&gt; - By default, vectors are columns. The transpose/Hermitian of a vector turns it into a row.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Range/Span&lt;/strong&gt; - The set of all linear combinations of each vector.&lt;/p&gt;

\[R\left(A\right)={\alpha_1A_1+a_2A_2\ldots+\alpha_kA_k,\ for\ any\ \alpha_i\in F}\]

&lt;p&gt;&lt;strong&gt;Nullspace/Kernel (of a matrix A)&lt;/strong&gt; - The set of all vectors \(\vec{x}\) such that Ax = 0&lt;/p&gt;

\[N\left(A\right)={x\in F^n,\ Ax=0}\]

&lt;p&gt;&lt;strong&gt;Ortho-complement (of a subspace)&lt;/strong&gt; -  The set of all vectors \(\vec{x}\) that are orthogonal to all vectors in the subspace V.&lt;/p&gt;

\[V^\bot={x,\ x\bot y\ for\ all\ y\in V}\]

&lt;p&gt;&lt;strong&gt;Linear Dependence&lt;/strong&gt; - A set of vectors are said to linearly dependent if there exist scalars \(\alpha\) not all zero such that:&lt;/p&gt;

\[\alpha_1V_1+a_2V_2\ldots+\alpha_kV_k=0\]

&lt;p&gt;&lt;strong&gt;Rank&lt;/strong&gt; - The rank of a matrix is the is the number of linearly independent rows or columns. It is equal to the dimension of the span of the matrix. The rank cannot be greater than min(m, n) given \(A\in F^{m\times n}\).&lt;/p&gt;

&lt;h3 id=&quot;normal-matrix&quot;&gt;Normal Matrix&lt;/h3&gt;

\[AA^H=A^HA\]

\[\|A\|^2=tr(A^HA)\]

\[A=Q\Lambda Q^H\]

\[AQ[:,i]=λiQ[:,i]\]

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;The Frobenius norm can by computed by the eigenvalues&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;[A] is normal if it commutes with its conjugate transpose&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;[A] is diagonalizable by a unitary matrix&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;There exists a set of eigenvectors of [A] which form an orthonormal basis for range([A])&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;[A] can be decomposed into the product of its unitary eigenvector matrices and a diagonal matrix of eigenvalues&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;unitaryorthogonal-matrix&quot;&gt;Unitary/Orthogonal Matrix&lt;/h3&gt;

\[AA^H=A^HA=I\]

\[\|x\|_2=\|Ax\|_2\]

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;[A] is unitary if it is normal and its product with its conjugate transpose equals the identity matrix&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;The product of a unitary matrix with a vector does not change the magnitude of the vector.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;symmetrichermitian-matrix&quot;&gt;Symmetric/Hermitian Matrix&lt;/h3&gt;

\[A=A^T\]

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;[A] is symmetric if it is equal to its conjugate transpose&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;All symmetric matrices are also normal matrices&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Rectangular matrices are never normal matrices&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;The eigenvalues of a symmetric (and thus normal) matrix are always real&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;diagonalizable-matrix&quot;&gt;Diagonalizable Matrix&lt;/h3&gt;

\[A=Q\Lambda Q^H\]

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;[A] is diagonalizable if it is similar to a diagonal matrix&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;singular-value-decomposition&quot;&gt;Singular Value Decomposition&lt;/h3&gt;

&lt;p&gt;The singular value decomposition of a matrix [A] yields the following expression, where  \(U\in F^{m\times m}\) is the matrix of left singular vector, \(V\in F^{n\times n}\) is the matrix of right singular vectors, and the strictly positive entries of \(\Sigma\in F^{m\times n}\) are referred to singular values. The number of nonzero singular values equals the rank of [A]. Both U and V are unitary matrixes.&lt;/p&gt;

\[A\in F^{m\times n}=U\Sigma V^H\]

&lt;p&gt;Realizing that in some cases, the rank of A is less than either m or n, leaving a few zero entries along the singular values. These send corresponding vectors in U and V to zero, and thus A can be reassembled with only the vectors of U, V and singular values through (r).&lt;/p&gt;

\[A=\ \sum_{i=1}^{r}{\sigma_iu_iv_i^H}\]

&lt;h3 id=&quot;additional-properties-of-the-svd&quot;&gt;Additional Properties of the SVD&lt;/h3&gt;

\[Av_j=\sigma_ju_j  \ \ \ \ \ \ if\ j\in\left(1,r\right)\]

\[Av_j=\sigma_ju_j=0\ \ \ \ \ \ if\ j\in(r+1,\ n)\]

\[A^Hu_j=\sigma_jv_j\ \ \ \ \ \ if\ j\in(1,\ r)\]

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;The right singular vectors of AH are the left singular vectors of A and vice-versa&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;The dimension of the range of A is equal to the rank of A&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;\(u_1,u_2,\ldots u_r\) are orthogonal basis vectors for the range of A&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;\(u_{r+1},u_{r+2},\ldots u_m\) are orthogonal basis vectors for the orthocomplement of the range of A&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;\(v_{r+1},v_{r+2},\ldots u_n\) are orthogonal basis vectors for the nullspace of A&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;\(v_1,v_2,\ldots v_r\) are orthogonal basis vectors for the orthocomplement of the nullspace of A&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;orthogonal-projection-matrix&quot;&gt;Orthogonal Projection Matrix&lt;/h3&gt;

&lt;p&gt;Consider a set of vectors \(v_1,\ v_2,\ \ldots v_k\) which form an orthonormal basis for the subspace of some range V. The orthogonal projection matrix of the subspace V as well as the orthocomplement of V is formed as:&lt;/p&gt;

\[P_v=Q_kQ_k^H\]

\[P_{v^\bot}={I-Q}_kQ_k^H\]

&lt;p&gt;The orthogonal projection matrix when multiplied by a vector finds the projection of that vector onto the subspace and is equal to subtraction of any orthogonal components from the original vector. That is:&lt;/p&gt;

\[P_{v^\bot}x=x-P_vx\]

&lt;h3 id=&quot;pseudo-inverse-moore-penrose-inverse&quot;&gt;Pseudo-Inverse (Moore-Penrose Inverse)&lt;/h3&gt;

&lt;p&gt;Note that a non-square matrix cannot be inverted in the traditional sense. However, it is still possible to achieve a partial inverse by using the SVD. We define the pseudo inverse as:&lt;/p&gt;

\[A^+=V\Sigma^+U^H\]

\[\Sigma^+=\left[\begin{matrix}\Sigma_{r\times r}&amp;amp;0_{r,\ n-r}\\0_{m\times r,\ r}&amp;amp;0_{m-r,\ n-r}\\\end{matrix}\right]\ \in F^{n\times m}\]

&lt;h3 id=&quot;least-squares-regressionordinary-least-squares&quot;&gt;Least Squares Regression/Ordinary Least Squares&lt;/h3&gt;

&lt;p&gt;Given a problem stated in the following format, it is possible to find an exact solution.&lt;/p&gt;

\[x_{LS}=argmin\|Ax-b\|_2^2\]

\[x_{LS}=A^+b\]

&lt;p&gt;Thus, we may be generally motivated to format our problems in the above format, such that a solution can be easily solved using the pseudo-inverse. Consider a dataset of inputs and corresponding outputs, denoted as t and b.&lt;/p&gt;

&lt;p&gt;Our approximation function we would like to take the form:&lt;/p&gt;

\[b_j=c_1+c_2t_j+c_3t_j^2+ \ldots α_1cos(t_j)+β_1sin(t_j)+α_2cos(t_j)+β_2sin(t_j)+ \ldots\]

&lt;p&gt;This can be represented in a linear format by defining the following sets of A and x matrices.&lt;/p&gt;

\[x=\ \left[c_1,\ c_2,c_3,\ldots,\ \alpha_1,\beta_1,\alpha_2,\beta_2,\ \ldots\right]^T\]

\[A_j=[1,\ t_j,\ t_j^2, \ldots,\cos(t_j),\sin(t_j),\cos(t_j),\sin(t_j)]\]

&lt;p&gt;Thus, the dot product of x with Aj should yield Equation 1. Repeating the above for every data point will yield a full matrix for A. The coefficients for our model equation which best fit the data can be found now using least squares regression.&lt;/p&gt;

&lt;h3 id=&quot;regularized-least-squares&quot;&gt;Regularized Least Squares&lt;/h3&gt;

&lt;p&gt;Consider for a moment, a constrained least squares problem:&lt;/p&gt;

\[x_{LS}=argmin\|Ax-b\|_2^2\]

\[\|Dx\|_2&amp;lt;τ\]

&lt;p&gt;As we did in optimization, we can include the constraint, as something that should be included in the weighting of the objective function.&lt;/p&gt;

\[x_{LS}=argmin\|Ax-b\|_2^2+λ^2\|Dx\|_2^2\]

&lt;p&gt;We can be reformed into our classic least squares problem format by defining the following sets of matrices:&lt;/p&gt;

\[\widetilde{A}=\left[\begin{matrix}A\\\lambda D\\\end{matrix}\right],\ \widetilde{b}=\left[\begin{matrix}b\\0\\\end{matrix}\right]\]

\[x_{LS}=argmin\|Ax-b\|_2^2\]

&lt;h3 id=&quot;first-difference-matrix&quot;&gt;First Difference Matrix&lt;/h3&gt;

&lt;p&gt;The first difference matrix when multiplied by a vector yields the elementwise gradients (taking the spacing/index to be the x displacement).&lt;/p&gt;

\[D=\ \left[\begin{matrix}-1&amp;amp;1&amp;amp;0&amp;amp;0&amp;amp;0\\0&amp;amp;-1&amp;amp;\cdots&amp;amp;0&amp;amp;0\\0&amp;amp;\vdots&amp;amp;\ddots&amp;amp;\vdots&amp;amp;0\\0&amp;amp;0&amp;amp;\cdots&amp;amp;-1&amp;amp;1\\1&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;-1\\\end{matrix}\right]\]

&lt;h3 id=&quot;trace-of-a-matrix&quot;&gt;Trace of a Matrix&lt;/h3&gt;

&lt;p&gt;The trace of a matrix is defined as the sum of values down the primary diagonal. The trace is invariant under cyclic permutation:&lt;/p&gt;

\[tr\left(AB\right)=tr\left(BA\right)\]

\[tr\left(A+B\right)=tr\left(A\right)+tr\left(B\right)\]

&lt;h3 id=&quot;frobenius-norm&quot;&gt;Frobenius Norm&lt;/h3&gt;

&lt;p&gt;The Frobenius norm of a matrix is the root of the sum of the square of all values. The frobenius norm is also equal to the square root of the trace, and the sum of square of singular values of A.&lt;/p&gt;

\[\|A\|_F = a_{ij}^2\]

\[\|A\|_F^2=tr(AA^H)=tr(A^HA)=σ_i^2\]

&lt;h3 id=&quot;principal-component-analysis&quot;&gt;Principal Component Analysis&lt;/h3&gt;

&lt;p&gt;Consider a matrix whose columns represent different items in a dataset, and whose rows represent different parameters for each data item (i.e. x, y, z, coordinates). Principal Component Analysis, or PCA, finds an orthonormal basis of directions which best fit the data. These lines minimize the average squared distance of each point to the line. This orthonormal basis are also the left singular vectors obtained through SVD.&lt;/p&gt;

&lt;p&gt;The first principal component of a matrix A, associated with the first eigenvector/left singular vector of the eigen decomposition and SVD, can be found as the vector which maximizes the second norm of the product of A with x.&lt;/p&gt;

\[u_1=\ argmax\|Ax\|^2)\]

&lt;p&gt;The next largest principal component can be found by projecting A into the null space formed from the previously found vectors and repeating the previous calculation. (We are finding the next line of best fit that is orthonormal to any previously found lines).&lt;/p&gt;

&lt;h3 id=&quot;independent-component-analysis&quot;&gt;Independent Component Analysis&lt;/h3&gt;

&lt;p&gt;ICA decomposes a signal into independent (non-correlated) non-Gaussian signals. When sources are statistically independent, ICA works very well in separating the two. ICA methods tend to breakdown when there is similarity in the signal, leading to correlation. To do this, ICA identifies directions that maximize absolute kurtosis. Mathematically, this is:&lt;/p&gt;

\[x=\ argmax(|k_4(x^TA)|)\]

&lt;p&gt;Where Kurtosis, or the fourth central cumulant, is defined as:&lt;/p&gt;

\[k_4(y^T)=\frac{1}{n}\sum y_i^4- 3(\frac{1}{n} \sum y_i^2)^2\]

&lt;p&gt;And in addition, subject to a spherical constraint on the x input (i.e., two norm of x is equal to 1).&lt;/p&gt;

\[\|x\|_2^2=1\]

&lt;h3 id=&quot;procrustes-analysis&quot;&gt;Procrustes Analysis&lt;/h3&gt;

&lt;p&gt;A method for statistical analysis of shape distributions. An orthogonal Procrustes problem is one that finds the optimal rotation, translation, and/or reflection which aligns two shapes.&lt;/p&gt;

&lt;h3 id=&quot;minimum-dimensions&quot;&gt;Minimum Dimensions&lt;/h3&gt;

&lt;p&gt;If I told you that there were 4 distinct points, and gave you the distance between every pair, you could determine the minimum dimensional space required to properly map these points. For instance, if all 6 distances are the same, there is no way to position these 4 points in a plane that makes this true. Instead, they must be arranged as a regular tetrahedron in 3D space. This is a useful concept for things like embedding vectors, used in sequence models, like natural language processing.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Music and AI - Part 1</title>
   <link href="https://ludavid15.github.io//musicAI1/"/>
   <updated>2022-03-19T00:00:00-07:00</updated>
   <id>https://ludavid15.github.io//musicAI1</id>
   <content type="html">&lt;p&gt;DallE-2 and ChatGPT have come and shown us how powerful AI can be when it comes to abstract and creative tasks. If AI can create images and sentences, why not music?&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;There are two ways in which artifical intelligence has been applied to music so far. The first is called music information retrieval, or MIR for short. These programs produce data from audio (e.g. song identification, transcribing audio into sheet music). The second is known as &lt;em&gt;generative&lt;/em&gt; AI. These programs try to produce new and original music, either fully autonomously or as a predictive aid to composers (i.e. like text predits on your phone!).&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;A third application which is not unique to music is song recommendation and classification. This includes apps like Spotify or Pandora which create custom playlists for you, and is very similar to how Netflix recommends you new movies and shows.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;projects-and-companies&quot;&gt;Projects and Companies&lt;/h3&gt;

&lt;p&gt;Just a few practical resources to look at if you are interested in seeing who is currently working on this subject.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://builtin.com/artificial-intelligence/ai-music-examples&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;AI Music: Companies and Applications to Know&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Magenta - an open source, Google-led project to explore creatives applications for ML.&lt;/li&gt;
  &lt;li&gt;BebopNet - an architecture that produces bebop style jazz solos.&lt;/li&gt;
  &lt;li&gt;deepJazz - a hackathon project that writes jazz for an ensemble.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;music-information-retrieval-mir&quot;&gt;Music Information Retrieval (MIR)&lt;/h3&gt;

&lt;p&gt;Chord recognition, song identification, etc. More information may follow, but this post primarily focuses on generative AI.&lt;/p&gt;

&lt;h1 id=&quot;generative-ai&quot;&gt;Generative AI&lt;/h1&gt;

&lt;p&gt;Stepping beyond recognition, generative AI tries to create new music. Algorithms in this category range from fully autonomous composers, to assistant bots which make recommendations.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;For a comprehensive review of this topic, I recommend reading “Deep Learning Techniques for Music Generation – A Survey”, by Jean-Pierre Briot, Gaetan Hadjeres, and Francois-David Pache.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;symbolic-vs-non-symbolic&quot;&gt;Symbolic vs Non-symbolic&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Symbolic - harmony, chords progressions&lt;/li&gt;
  &lt;li&gt;Non-symbolic - sound, timbre&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Algorithms working with symbolic music often needs rules, grammers and structured inputs, which reduces flexibility and increases overhead.&lt;/p&gt;

&lt;h4 id=&quot;markov-models&quot;&gt;Markov Models&lt;/h4&gt;

&lt;p&gt;Markov models predict one step at a time. This makes them easy to implement and understand, but it also means they are unable to think about long-term structure. Think of this like writing a book, but each word is written by finding the most statistically probable word to follow from the one before. You might still get complete sentences, but highly unlikely to get a coherent theme.&lt;/p&gt;

&lt;h3 id=&quot;attributes&quot;&gt;Attributes&lt;/h3&gt;

&lt;p&gt;These are a few attributes of different generative AI’s. Keep in mind that some of these might be related, (i.e. they may not be orthogonal, or independent of one another).&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Objective&lt;/strong&gt;: What aspect of music are you creating? A melody? A chord progression? An accompaniment?&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Representation&lt;/strong&gt;: How are you structuring your musical data? E.g. as a signal, MIDI, text, piano roll.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Architecture&lt;/strong&gt;: Recurrent NN, autoencoders, generative adversarial modeling, etc.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Challenge&lt;/strong&gt;: What qualities are you looking for in what you create? Variability, creativity, interactivity.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Strategy&lt;/strong&gt;: Strategy is how you’re going to convert the input into the output. Does it happen all at once? Note by note?&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;objectives&quot;&gt;Objectives&lt;/h3&gt;

&lt;p&gt;Let’s think about melody for a moment. What’s the context for the melody we’re writing? Is it a Bach style counterpoint to an existing melody? Is it the baritone part in a SATB choir? Is it an improvised melody over an existing chord progression (like on a lead sheet?).&lt;/p&gt;

&lt;p&gt;These are all valid ways to think about single-voice melodies, but are different enough that they may require unique approaches.&lt;/p&gt;

&lt;h3 id=&quot;representation&quot;&gt;Representation&lt;/h3&gt;

&lt;p&gt;Representation is how we choose to format our music. Is it the raw waveform? Maybe a spectrum if we first run a fourier analysis. Or what about symbolically? If so, what about enharmony? Is an Eb and the D# the same thing?&lt;/p&gt;

&lt;p&gt;Formats that deal with audio signals are often continuous, and fall into the realm of signal processing. In contrast, symbolic representation is discrete, and more often found in the field of knowledge representation. We’ll start by discussing different elements of music and how we might represent them, and then talk about existing representations.&lt;/p&gt;

&lt;h3 id=&quot;note-representations&quot;&gt;Note Representations&lt;/h3&gt;

&lt;p&gt;Every note has a pitch, duration, and dynamic. Pitch can be expressed as a frequency, position on a score, or a letter (A through G). Duration can be measured in absolute terms (seconds), or in the context of written music (quarter note, half note, etc.). The same absolute vs relevant distinction can be made for the note’s dynamic, (i.e. decibels vs pianissimo/forte).&lt;/p&gt;

&lt;h3 id=&quot;chord-representations&quot;&gt;Chord Representations&lt;/h3&gt;

&lt;p&gt;Chords can be represented either as a collection of notes, or by a root and type (e.g. C7, Gmin, etc.). The latter is more useful for harmonic analysis, and for some applications, like a jazz musician’s lead sheet, could be more useful.&lt;/p&gt;

&lt;h3 id=&quot;rhythm-representations&quot;&gt;Rhythm Representations&lt;/h3&gt;

&lt;p&gt;In some sense, the rhythm is already captured by the duration and dynamic of each note. But we can also think of rhythm as the “feel” of a piece. Repeating patterns in the duration and dynamic of each note create a combined rhythm effect. This collective sense of rhythm is distinct from the detailed implementation of &lt;em&gt;time&lt;/em&gt;.&lt;/p&gt;

&lt;h3 id=&quot;time-representations&quot;&gt;Time Representations&lt;/h3&gt;

&lt;p&gt;There are two approaches to how we create music with respect to time (and if you think about it, there can only be two). You can either model and optimize the entire score all together, or you can step through one unit at a time. This unit can be a beat, or a note. In the latter case, there is no going back to change work you’ve already done. The nuance here seems small, but it has a very big impact on what the input and output to our AI is.&lt;/p&gt;

&lt;p&gt;This type of modeling works if we choose to represent a relative duration (e.g. an 8th note, 16th note, etc.) or in absolute terms (in milliseconds). The latter is needed to capture the “artistic” interpretation that a human musician may add, but is not as useful if our goal is to create written sheet music.&lt;/p&gt;

&lt;h3 id=&quot;method-1---midi&quot;&gt;Method 1 - MIDI&lt;/h3&gt;

&lt;p&gt;MIDI (Musical Instrument Digital Interface) is a standard to represent musical information. MIDI works especially well for capturing single note melodies. An example line of MIDI input:&lt;/p&gt;

&lt;p&gt;[96, on, 0, 60, 90]
[184, off, 0, 60, 0]&lt;/p&gt;

&lt;p&gt;We can understand the above lines as saying:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;at time 96 and on channel 0, start playing the pitch 60 at a volume of 90.&lt;/li&gt;
  &lt;li&gt;at time 184 and on channel 0, stop playing the pitch 60 at a velocity of 0.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;When specifiying an off event, the very last number tells us how quickly to release a note.&lt;/p&gt;

&lt;p&gt;To create a chord, or any two notes played simultaneously, we just introduce a new channel. This is sufficient for capturing audio information, but in the realm of data science, this lack of unique language for chords is problematic. Algorithms which learn using a MIDI format often fail to “learn” harmonies.&lt;/p&gt;

&lt;h3 id=&quot;method-2---piano-roll&quot;&gt;Method 2 - Piano Roll&lt;/h3&gt;

&lt;p&gt;Unlike MIDI, a piano roll does capture chords in a more intuitive way. There are only two dimensions: pitch, and time. A third dimension can be added to collect volume and intensity information. As with the MIDI format, the piano roll doesn’t distinguish between melody and harmony.&lt;/p&gt;

&lt;h4 id=&quot;what-about-held-notes&quot;&gt;What About Held Notes?&lt;/h4&gt;

&lt;p&gt;One major downside of the piano roll is that (depending on how we encode time), it may be impossible distinguish a held note from a repeated note. For this, we’ll need to add a new word to our musical language. One way to do this is to introduce a new notation (something like a –), which represents a held note. Then when we need to encode this, we can treat the the hold symbol as just another “pitch”.&lt;/p&gt;

&lt;h3 id=&quot;metadata&quot;&gt;Metadata&lt;/h3&gt;

&lt;p&gt;What kind of metadata do we want to include? Key signature, meter (i.e. waltz, bossa nova, swing). Music annotating programs like musescore will often allow users to track these. Whether or not they are useful towards generation remains to be proven.&lt;/p&gt;

&lt;h3 id=&quot;encoding&quot;&gt;Encoding&lt;/h3&gt;

&lt;p&gt;Encoding is the step that connects the representation of music we’ve chosen, to the set of input notes or input variables for the nueral network. For example, consider the two definitions we have for chords:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Implicit (C, E, G, B)&lt;/li&gt;
  &lt;li&gt;Explicit (C major 7th)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;An implicit representation is typically encoded with many-hot, while an explicit representation can be encoded with a multi-one-hot (i.e. the first one-hot is the root, the second one-hot is the quality).&lt;/p&gt;

&lt;p&gt;And finally, a musical rest could be encoded like any other note - except in the case of MIDI which doesn’t need it.&lt;/p&gt;

&lt;h3 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;And that wraps up the introduction! Hopefully this article leaves you with a top level overview of the subject. We started with the different aspects of music (melody, harmony, rhythm, etc.) and discussed how they connect to machine learning. Before continuing on to &lt;a href=&quot;/notes/musicAI2&quot;&gt;part 2&lt;/a&gt;, I recommend checking out the &lt;a href=&quot;/notes/mlintroduction&quot;&gt;introduction to machine learning&lt;/a&gt; and &lt;a href=&quot;/notes/mlarchitectures&quot;&gt;machine learning&lt;/a&gt; posts.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Data Analytics</title>
   <link href="https://ludavid15.github.io//dataanalytics/"/>
   <updated>2022-02-14T00:00:00-08:00</updated>
   <id>https://ludavid15.github.io//dataAnalytics</id>
   <content type="html">&lt;p&gt;In contrast to data &lt;em&gt;science&lt;/em&gt;, which designs and explores the models and algorithms we have for analyzing data, data &lt;em&gt;analytics&lt;/em&gt; is about using data to solve problems. This includes additional steps like considering your stakeholders, communicating ideas, and working under a deadline.&lt;/p&gt;

&lt;p&gt;This post is a collection of notes and lessons from the Google Data Analytics Certificate.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h3 id=&quot;overview&quot;&gt;Overview&lt;/h3&gt;

&lt;p&gt;To begin, let’s be clear that data analytics is not machine learning. In the abstract, they might be the same (i.e. drawing patterns from your data), but machine learning is much more complex mathematically. In contrast, data analytics is limited to a few pretty straightforward computations.&lt;/p&gt;

&lt;h3 id=&quot;the-lifecyce-of-data&quot;&gt;The Lifecyce of Data.&lt;/h3&gt;

&lt;p&gt;Why do we discuss the lifestyle of data? Because data analytics is not just about obtaining results, it’s about collecting, managing, and then closing out a process.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Plan&lt;/li&gt;
  &lt;li&gt;Capture&lt;/li&gt;
  &lt;li&gt;Manage&lt;/li&gt;
  &lt;li&gt;Analyze&lt;/li&gt;
  &lt;li&gt;Archive&lt;/li&gt;
  &lt;li&gt;Destroy&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;setting-up-the-problem&quot;&gt;Setting up the Problem&lt;/h3&gt;

&lt;p&gt;The best results come from a well defined question. And one way to build good questions is to use the SMART system:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Specific&lt;/li&gt;
  &lt;li&gt;Measurable&lt;/li&gt;
  &lt;li&gt;Action-oriented&lt;/li&gt;
  &lt;li&gt;Relevant&lt;/li&gt;
  &lt;li&gt;Time constrained&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;And finally, it’s also worth considering the type of problem. Which of these are you trying to do?&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Predict&lt;/li&gt;
  &lt;li&gt;Categorize&lt;/li&gt;
  &lt;li&gt;Detect outliers&lt;/li&gt;
  &lt;li&gt;Identify themes&lt;/li&gt;
  &lt;li&gt;Discover connections&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Different objectives may lead to different problem setups and approaches. The better you understand what you are trying to do, the more tailored you can make your response.&lt;/p&gt;

&lt;h3 id=&quot;types-of-data&quot;&gt;Types of Data&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;Nominal vs Ordinal
    &lt;ol&gt;
      &lt;li&gt;Nominal - Choices/responses that don’t have a particular order (i.e. yes/no/maybe)&lt;/li&gt;
      &lt;li&gt;Ordinal - Data that has an associated order (i.e. a scale or ranking).&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;Internal vs External (i.e. who owns the data? Does it come from outside your organization?)&lt;/li&gt;
  &lt;li&gt;Continuous vs Discrete&lt;/li&gt;
  &lt;li&gt;Quantitative vs Qualitative&lt;/li&gt;
  &lt;li&gt;Structures vs Unstructured (i.e. survey responses, vs pictures)&lt;/li&gt;
  &lt;li&gt;Primary vs Secondary&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;types-of-data-modeling&quot;&gt;Types of Data Modeling&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Conceptual data modeling&lt;/strong&gt; gives a high-level view of the data structure, such as how data interacts across an organization. For example, a conceptual data model may be used to define the business requirements for a new database. A conceptual data model doesn’t contain technical details.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Logical data modeling&lt;/strong&gt; focuses on the technical details of a database such as relationships, attributes, and entities. For example, a logical data model defines how individual records are uniquely identified in a database. But it doesn’t spell out actual names of database tables. That’s the job of a physical data model.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Physical data modeling&lt;/strong&gt; depicts how a database operates. A physical data model defines all entities and attributes used; for example, it includes table names, column names, and data types for the database.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;data-integrity&quot;&gt;Data Integrity&lt;/h3&gt;

&lt;p&gt;Data integrity is something to keep in mind through the entire data analysis process. Data with integrity means that is accurate, complete, consistent, and trust-worthy.&lt;/p&gt;

&lt;p&gt;One common pitfall is to have biased data. This can occur if you’re using a survey to collect data and use leading or vague questions. Some examples:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Isn’t it true that A had a negative effect on B?&lt;/li&gt;
  &lt;li&gt;What’s going on with A?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Other common pitfalls of the data cleaning process:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Overlooking missing values&lt;/li&gt;
  &lt;li&gt;Only looking at a subset&lt;/li&gt;
  &lt;li&gt;Losing track of objectives&lt;/li&gt;
  &lt;li&gt;Not fixing the root of the issue&lt;/li&gt;
  &lt;li&gt;Not analyzing the system&lt;/li&gt;
  &lt;li&gt;Not backing up your data prior to cleaning&lt;/li&gt;
  &lt;li&gt;Not accounting for cleaning time in budgeting&lt;/li&gt;
  &lt;li&gt;Not checking for spelling errors&lt;/li&gt;
  &lt;li&gt;Forgetting to document errors&lt;/li&gt;
  &lt;li&gt;Not checking for misfielded values&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;data-analysis&quot;&gt;Data Analysis&lt;/h3&gt;

&lt;p&gt;This is a bit tough to describe, because the analysis you perform is going to be different depending on your application. But in general, you’ll have a few toolsets you can use. For smaller databases, excel is perfectly sufficient.&lt;/p&gt;

&lt;p&gt;For anything larger, you’ll want to look at SQL, R, or some other coding language such as Python. Personally, I like using Python with the Pandas library. Regardless of what tool you use, there are some common functions you’re likely to run into.&lt;/p&gt;

&lt;h4 id=&quot;filters-and-queries&quot;&gt;Filters and Queries&lt;/h4&gt;

&lt;p&gt;Basically equivalent to “get all results that satisfy some condition”.&lt;/p&gt;

&lt;h4 id=&quot;merges&quot;&gt;Merges&lt;/h4&gt;

&lt;p&gt;In a relational database, you data might be split across many different tables (usually to do with how it gets collected). Merges provide a way to combine results into one place.&lt;/p&gt;

&lt;h3 id=&quot;data-visualization&quot;&gt;Data Visualization&lt;/h3&gt;

&lt;p&gt;Principles of good data visualization:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Information&lt;/li&gt;
  &lt;li&gt;Story&lt;/li&gt;
  &lt;li&gt;Goal&lt;/li&gt;
  &lt;li&gt;Visual Form&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;You can also review your presentation with these questions:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;What is the practical question?&lt;/li&gt;
  &lt;li&gt;What does the data say?&lt;/li&gt;
  &lt;li&gt;What does the visual say?&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Finally, make sure to consider the use case. For instance, if we need to monitor new data as it comes in, an interactive dashboard with the proper backend support would be best (e.g. Tableau). However, if we wanted historical data, a dashboard could be too complex.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Writing Effectively</title>
   <link href="https://ludavid15.github.io//writingEffectively/"/>
   <updated>2021-08-25T00:00:00-07:00</updated>
   <id>https://ludavid15.github.io//writing</id>
   <content type="html">&lt;p&gt;A collection of writing tips. If you’re serious about writing, I’d recommend reading &lt;em&gt;On Writing Well&lt;/em&gt; by William Zinsser.&lt;/p&gt;

&lt;!--more--&gt;

&lt;p class=&quot;message&quot;&gt;
TLDR: Be concise &amp;amp; tell your story.
&lt;/p&gt;

&lt;h3 id=&quot;1-dumb-it-down&quot;&gt;1. Dumb it Down&lt;/h3&gt;

&lt;p&gt;Especially in scientific writing, using simple language is a must. Your words might make sense to you, but they likely don’t to most other people, and that’s not their fault.&lt;/p&gt;

&lt;h3 id=&quot;2-use-the-active-voice&quot;&gt;2. Use the Active Voice&lt;/h3&gt;

&lt;p&gt;I know this is the first rule you learn in school, but at some point we all forget or are told otherwise. For instance, have you ever heard that you’re not supposed to use pronouns in scientific writing? Something about keeping the focus on the data and not on the user. In my opinion, this is a pretty stupid rule, since the active voice keeps your writing energetic and engaging. If you have a cool scientific thing to discuss, don’t make it boring with passive voice.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;The satellite’s flight software had been developed at NASA. The requirements were met by their software.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;See how there’s no clear narrative with passive voice? We’re missing a clear actor and action. Instead, we can do something like this:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;NASA developed the satellite’s flight software, and it met their requirements.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;3-cut-the-clutter&quot;&gt;3. Cut the Clutter&lt;/h3&gt;

&lt;p&gt;Be careful to avoid “fluffy” language in your writing. For instance, don’t use big words where a smaller word would suffice. Also avoid those extra clauses, adverbs, or adjectives that don’t contribute to your primary point.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;These improved performance metrics presents a compelling argument for the adoption of our recently developed program to classify and label images regarding animals of the species C. familiaris.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This is a rather extreme example of “fluff”. There are many big and unnecessary words here, which don’t add any useful information. In general, use the shortest word you can, and take the shortest path to your point.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;Our classifier for dog images performed very well and should be used.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Adverbs are especially susceptible to redundancy.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Clenched tightly&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Finished completely&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Whispered quietly&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;4-use-verbs-not-nouns&quot;&gt;4. Use Verbs not Nouns&lt;/h3&gt;

&lt;p&gt;In the same spirit as tip #2 to use the active voice, you should avoid turning your verbs into nouns. This is usually done by adding “tion” or “ment” to the end of a verb. For instance, &lt;em&gt;create&lt;/em&gt; -&amp;gt; &lt;em&gt;creation&lt;/em&gt;, &lt;em&gt;establish&lt;/em&gt; -&amp;gt; &lt;em&gt;establishment&lt;/em&gt;.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;The establishment of a new cyber security team at the organization was a direct response to the recent breach.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This reads fine, but it’s not very exciting. It lacks a strong actor and action.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;The organization established a new cyber security team after the recent breach.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;5-only-one-hedge-word&quot;&gt;5. Only One Hedge Word&lt;/h3&gt;

&lt;p&gt;Hedge words are words which create ambiguity. These tend to dull the impact of a sentence. When using a hedge word, consider if you are actually uncertain, or if you’re just trying to avoid committment. If something is truly uncertain, one hedge word is enough.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;The data perhaps suggests a potential connection between the two effects.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;See how there are so many hedge words that hardly anything is being staked? The sentence also reads a lack of confidence. Let’s either get rid of all the hedge words, or keep a maximum of one to express genuine uncertainty.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;The data (shows/suggests) a connection between the two effects&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;6-take-ownership&quot;&gt;6. Take Ownership&lt;/h3&gt;

&lt;p&gt;Don’t be afraid to use “I” in your writing, and do take owernship of your opinions and thoughts. For the same reason you might dislike talking to an automated answering machine, I find that people are uninterested in writing that doesn’t demonstrate personality. Especially when writing about science/technology which can be very dense.&lt;/p&gt;

&lt;p&gt;Also, the use of “I” can help bring out your writing style. As William Zinsser stays, “writing is an act of ego, and you might as well admit it”.&lt;/p&gt;

&lt;h3 id=&quot;7-write-for-yourself&quot;&gt;7. Write for Yourself&lt;/h3&gt;

&lt;p&gt;On the topic of style, one way to develop yours is to write for yourself. Don’t feel overly burdened by what your readers might think. Use words/humor/pacing that feel right to you. To write is to be heard, so let the authentic version of yourself show through. However, this doesn’t mean you should ignore the rules of effective communication. Being able to communicate an idea clearly and expressing that idea with personality aren’t mutually exclusive.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Textbooks</title>
   <link href="https://ludavid15.github.io//textbooks/"/>
   <updated>2021-08-25T00:00:00-07:00</updated>
   <id>https://ludavid15.github.io//textbooks</id>
   <content type="html">&lt;p&gt;These are some textbooks that I found helpful, or that were recommended to me by friends and professors.&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;&lt;strong&gt;Thermodynamics: Foundations and Applications&lt;/strong&gt;
E.P Gyftopoulos, and G. P. Beretta&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The Dynamics and Thermodynamics of Compressible Fluid Flow&lt;/strong&gt;
A. H. Shapiro&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Elements of Gasdynamics&lt;/strong&gt;
H.W Liempann and A. Roshko&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Physics of Shock Waves and High Temperature Hydrodynamic Phenomena&lt;/strong&gt;
Y.B Zel’dovich and Y.P Raizer&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Viscous Flow&lt;/strong&gt;
F. M. White&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Fluid Mechanics&lt;/strong&gt;
L. D. Landau and E.M Lifshitz&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Boundary Layer Theory&lt;/strong&gt;
H. Schlichting&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Space Mission Analysis and Design&lt;/strong&gt;
J. Wertz&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Path Planning</title>
   <link href="https://ludavid15.github.io//pathPlanning/"/>
   <updated>2021-08-25T00:00:00-07:00</updated>
   <id>https://ludavid15.github.io//pathPlanning</id>
   <content type="html">&lt;p&gt;Across the vast field of robotics and controls, there is a common question of “how do we get from point A to point B?”. Without any constraints, the answer is pretty easy - go in a straight line - but this is not very useful. So how can we formulate a more useful question?&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;First, we’ll add a safety requirement - that we’d like to make this journey while avoiding obstacles. Then we’ll want to make sure we’re planning a feasible route - no sharp 180’s at supersonic speeds. And finally we’d like to find the best route. Maybe best means shortest, or fastest, or most efficient. With all of these requirements, the task of path planning becomes much more challenging, but most solutions fall into one of four methods.&lt;/p&gt;

&lt;h3 id=&quot;what-is-a-path&quot;&gt;What is a Path?&lt;/h3&gt;

&lt;p&gt;When we talk about path planning, what information actually makes up a “path”? To figure this out, imagine we are designing an autonomous driver that does everything you do.&lt;/p&gt;

&lt;p&gt;To start, we need (x,y,z) position coordinates. This is akin to choosing which street we take, or which lane on the freeway we use. But we as drivers make more decisions than just position - we also speed up and slow down. So a path might also have velocities (x’, y’, z’) at each position coordinate. To make these velocities happen, we apply accelerations. This quickly gets complicated, so instead of storing three velocities and three accelerations with each position, we could just index each position coordinate by time. This way, we can also calculate any order derivative!&lt;/p&gt;

&lt;h3 id=&quot;sampling-methods&quot;&gt;Sampling Methods&lt;/h3&gt;

&lt;p&gt;As the name implies, these search the free space for feasible paths. Active methods like Rapidly-Exploring Random Trees (RRT) expand outwards and only add new paths to existing paths (thus keeping everything connected). Meanwhile passive methods like Probabilistic Roadmaps (PRM) fill the feasible space and then must find a connected path. Sampling methods tend to be the most simple, but most do not guarantee a global optimum, nor do they typically consider things like dynamic feasibility, or visibility.&lt;/p&gt;

&lt;h3 id=&quot;node-or-heuristic-based-searches&quot;&gt;Node or Heuristic Based Searches&lt;/h3&gt;

&lt;p&gt;Node based algorithms implement a search to optimize some cost function. In this sense, they represent a form of dynamic programming. Dijkstra’s algorithm, A&lt;em&gt;, and D&lt;/em&gt; are the most well known algorithms of this group. As with sampling methods, the location of the drone and obstacles in the environment must be known ahead of time. Because there is optimization involved, a node based search finds some kind of optimal path, and not just a feasible path.&lt;/p&gt;

&lt;h3 id=&quot;mathematical-modeling&quot;&gt;Mathematical Modeling&lt;/h3&gt;

&lt;p&gt;Mathematical modeling is a more comprehensive, though computationally expensive strategy. With this approach, we write a cost function subject to kinodynamic constraints. This large optimization problem is then solved using a variety of either direct or indirect methods, i.e. through construction of the Hamiltonian, collocation, shooting methods, etc. See the section on &lt;a href=&quot;/notes/trajoptimization/&quot;&gt;trajectory optimization&lt;/a&gt; for more info.&lt;/p&gt;

&lt;h3 id=&quot;machine-learning-methods&quot;&gt;Machine Learning Methods&lt;/h3&gt;

&lt;p&gt;These methods use machine learning to discover an appropriate cost function. Rather than construct a model which tries to capture all the details, we provide data from real human drivers (i.e. throttle and steering wheel inputs). The algorithm then learns how to drive safely by mimicking the data. The final result is more of a controller - learning to track and avoid collisions as they come up - rather than a path planner.&lt;/p&gt;

&lt;h3 id=&quot;jerk-optimization&quot;&gt;Jerk Optimization&lt;/h3&gt;

&lt;p&gt;You’ve probably noticed that sampling methods and node searches don’t consider things like dynamic feasibility. They discretize space into grids, and plot a series of waypoints. To convert these waypoints into an actual path, we enforce each waypoint as a constraint, and then minimize the 4th derivative, or the “jerk”, of the trajectory. This makes a smooth path, though not necessarily a feasible path. To make it feasible we have to add more constraints, such as a maximum acceleration or velocity.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Scales</title>
   <link href="https://ludavid15.github.io//scales/"/>
   <updated>2021-08-16T00:00:00-07:00</updated>
   <id>https://ludavid15.github.io//scales</id>
   <content type="html">&lt;p&gt;Major Scale (Diatonic Scale, Ionian Mode)&lt;/p&gt;

&lt;p&gt;Ionian, Dorian, Phrygian, Lydian,&lt;/p&gt;

&lt;p&gt;More importantly, we need to know the style and color of a scale (major, minor, dom7, bright, dark, etc.)&lt;/p&gt;

&lt;p&gt;From brightest to darkest (notice that we are slowly dropping the pitch of notes, in the same order as we would along the circle of 5ths)&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Name&lt;/th&gt;
      &lt;th&gt;Sharps or Flats&lt;/th&gt;
      &lt;th&gt;Quality&lt;/th&gt;
      &lt;th&gt;Chords&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Lydian&lt;/td&gt;
      &lt;td&gt;# 4th&lt;/td&gt;
      &lt;td&gt;Major&lt;/td&gt;
      &lt;td&gt;Major chords&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ionian&lt;/td&gt;
      &lt;td&gt;None&lt;/td&gt;
      &lt;td&gt;Major&lt;/td&gt;
      &lt;td&gt;Major chords&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Mixolydian&lt;/td&gt;
      &lt;td&gt;b7&lt;/td&gt;
      &lt;td&gt;Dominant&lt;/td&gt;
      &lt;td&gt;Dominant 7th chords&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Dorian&lt;/td&gt;
      &lt;td&gt;add b3&lt;/td&gt;
      &lt;td&gt;Minor&lt;/td&gt;
      &lt;td&gt;Minor 7th chords&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Aeolian&lt;/td&gt;
      &lt;td&gt;add b6&lt;/td&gt;
      &lt;td&gt;Minor&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Phyrgian&lt;/td&gt;
      &lt;td&gt;add b2&lt;/td&gt;
      &lt;td&gt;Minor&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Locrian&lt;/td&gt;
      &lt;td&gt;add b5&lt;/td&gt;
      &lt;td&gt;Minor&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;dominant-7-harmony-scales&quot;&gt;Dominant 7 Harmony Scales&lt;/h3&gt;

&lt;p&gt;Lydian Flat 7
Altered Scale - flat 9, sharp 9, natural 3, sharp 11, flat 13, flat 7
Normally does not include the 5th, but the 5th is still usable in this scale.&lt;/p&gt;

&lt;p&gt;Symmetric Diminished - sounds like the diminished chord
b9, sharp 9, natural 3, sharp 11, natural 5, natural 6, flat 7&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Chord Progressions</title>
   <link href="https://ludavid15.github.io//progressions/"/>
   <updated>2021-08-14T00:00:00-07:00</updated>
   <id>https://ludavid15.github.io//progressions</id>
   <content type="html">&lt;p&gt;A collection of common chord progressions I’ve encountered. Though they come in all sorts of flavors and styles, many progressions are built on the idea of &lt;strong&gt;tension&lt;/strong&gt; and &lt;strong&gt;release&lt;/strong&gt;. We play dissonant chords to “push” the melody towards a nice resolution, which usually is the tonic chord (also known as the home chord).&lt;/p&gt;

&lt;!--more--&gt;

&lt;h3 id=&quot;the-2-5-1&quot;&gt;The 2-5-1&lt;/h3&gt;

&lt;p&gt;Starts with the minor 7th on the second, the major 7th on the 5th, and finishes on the root.&lt;/p&gt;

&lt;h4 id=&quot;minor-2-5-1&quot;&gt;Minor 2-5-1&lt;/h4&gt;

&lt;p&gt;It’s the same chord progression, but this is the minor version. The &lt;strong&gt;ii&lt;/strong&gt; which is normally a minor 7th, becomes a diminished&lt;/p&gt;

&lt;h4 id=&quot;extended-3-6-2-5-1&quot;&gt;Extended 3-6-2-5-1&lt;/h4&gt;

&lt;p&gt;Notice that we are adding chords according to their order along the circle of fifths. For instance, in the key of C, the 3rd (E) has 4 sharps, the 6th (A) has 3 sharps, the 2nd (D) has 2 sharps, and the 5th (G) has one sharp.&lt;/p&gt;

&lt;h3 id=&quot;tritone-substitutions&quot;&gt;Tritone Substitutions&lt;/h3&gt;

&lt;p&gt;This method is used on 2-5-1 progressions. We take the dominant fifth, and substitute a chord that is based on the note a tritone above. In the key of C, this means that the &lt;strong&gt;G7&lt;/strong&gt; might be replaced by a &lt;strong&gt;C#7&lt;/strong&gt;. This results in a chromatic sequence (&lt;strong&gt;D&lt;/strong&gt; - &lt;strong&gt;C#&lt;/strong&gt; - &lt;strong&gt;C&lt;/strong&gt;).&lt;/p&gt;

&lt;h3 id=&quot;diminished-sixths&quot;&gt;Diminished Sixths&lt;/h3&gt;

&lt;p&gt;Sometimes also known as the Barry Harris progression.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Trajectory Optimization</title>
   <link href="https://ludavid15.github.io//trajoptimization/"/>
   <updated>2021-08-11T00:00:00-07:00</updated>
   <id>https://ludavid15.github.io//trajectoryOptimization</id>
   <content type="html">&lt;p&gt;In this article, I talk about how to frame a trajectory problem as a mathematical optimization problem. Keep in mind that this is only one way to plan a trajectory. And when I say math, I really do mean &lt;em&gt;math&lt;/em&gt; (the difficult kind). You have been warned.&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;To begin, let’s connect the physical properties of a trajectory, to the inputs of any optimization problem.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Trajectories occur in 3D dimensional space, meaning that there should be x(t), y(t), and z(t).&lt;/li&gt;
  &lt;li&gt;The variables to be optimized are the control inputs as a function of time. That is, u(t).&lt;/li&gt;
  &lt;li&gt;Trajectories are continuous time problems. Problems can be solved as continuous time or can be discretized and solved as a finite dimensional optimization problem.&lt;/li&gt;
  &lt;li&gt;There are equations of motion which govern the effect of the control input u to the state variables x.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;problem-statement-for-generic-optimization&quot;&gt;Problem Statement for Generic Optimization&lt;/h3&gt;
&lt;p&gt;The problem statement in flight trajectory optimization is a specialized version of the problem statement for a generic optimization problem:&lt;/p&gt;

\[J=K\left(t_1,\ x_1\right)+\int_{t_0}^{t_1}L\left(t,x,u\right)dt\]

&lt;p&gt;Where K is known as the terminal cost, while L is known as an incremental cost. The one in the subscript indicates the value at the final time. The problem is subject to equations of motion, equality constraints, and inequality constraints.&lt;/p&gt;

\[\dot{x}=f\left(t,x,u\right)\]

\[g\left(t,x,u\right)=0\]

\[h\left(t,x,u\right)\le0\]

&lt;h3 id=&quot;solution-strategies&quot;&gt;Solution Strategies&lt;/h3&gt;
&lt;p&gt;There are three approaches for solving a continuous time trajectory optimization problem. These are:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Dynamic Programming* – using sufficient conditions to derive a control law (i.e. a function of the state and time).&lt;/li&gt;
  &lt;li&gt;Indirect Methods – apply Pontryagin Maximum Principle (which provide necessary conditions) and solve the resulting two-point boundary value problem.&lt;/li&gt;
  &lt;li&gt;Direct Methods – discretize the trajectory and solve as a constrained finite dimensional optimization problem. This is also known as transcription.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;*Note that dynamic programming can also be used to solve discrete (i.e. finite dimensional optimization problems). The principle of both is the same, just with slightly modified steps.&lt;/p&gt;

&lt;h3 id=&quot;discrete-time-optimal-control-problems&quot;&gt;Discrete Time Optimal Control Problems&lt;/h3&gt;

&lt;p&gt;In a discrete time optimal control problem, the trajectory is divided into a series of nodes, where at each node the vehicle has some state (i.e. position, velocity, angle, etc.) and control input. The problem statement can be rewritten in the following form:&lt;/p&gt;

\[J=K\left(x_N\right)+\sum_{k=0}^{N-1}{L(x_k,u_k,k})\]

\[x_{k+1}=f(x_k,u_k,k)\]

&lt;p&gt;The set of necessary conditions can be expressed as follows&lt;/p&gt;

\[p_k=\nabla_{x_k}H_k\]

\[\nabla_{u_k}H_k=0\]

\[p_N=\nabla_{x_N}K(x_N)\]

&lt;p&gt;If the Hamiltonian is convex in u, then the stationary condition becomes necessary and sufficient for the optimal control sequence to a pointwise minimizer of the Hamiltonian.&lt;/p&gt;

&lt;h3 id=&quot;collocation&quot;&gt;Collocation&lt;/h3&gt;

&lt;p&gt;This is a discretization method whereby the trajectory is divided into nodes, and both the state variables and controls are free (i.e. to be optimized by the optimizer). The state variables are chosen such that they equations of motions are satisfied. The total number of design variables is expressed below:&lt;/p&gt;

\[X=\left[\begin{matrix}x_o\\\vdots\\x_N\\u_o\\\vdots\\u_{N-1}\\\end{matrix}\right]\]

&lt;p&gt;In the above expression, u is the control vector at every node, while x is the state vector at every node. There can be multiple values within a single state vector or control vector (i.e. position and velocity in 3D space = 6 variables in each state vector). The equations of motion are applied as equality constraints on the components of the input vector.&lt;/p&gt;

&lt;h3 id=&quot;shooting-methods&quot;&gt;Shooting Methods&lt;/h3&gt;
&lt;p&gt;Whereas collocation methods approximate the trajectory curve, shooting methods are simulation based. There are two types of shooting methods: single shooting, and multiple shooting. Single shooting estimates the entire trajectory as one arc, while multiple shooting approximates the trajectory as a spline of multiple arcs, and then must satisfy continuity and constraint equations to join those arcs together.&lt;/p&gt;

&lt;p&gt;Classification of Optimal Control Problem Types
Problems formatted in one type can be transformed into another format fairly easily.&lt;/p&gt;

&lt;h4 id=&quot;mayers-problem&quot;&gt;Mayer’s Problem&lt;/h4&gt;
&lt;p&gt;A variation of optimal control problem where there is no incremental cost&lt;/p&gt;

\[J=K(x(t_1),\ t_1)\]

&lt;h4 id=&quot;lagranges-problem&quot;&gt;Lagrange’s Problem&lt;/h4&gt;
&lt;p&gt;A variation of optimal control problem where there is no terminal cost&lt;/p&gt;

\[J=\int_{t_0}^{t_1}L(t,x,u)dt\]

&lt;h4 id=&quot;bolzas-problem&quot;&gt;Bolza’s Problem&lt;/h4&gt;
&lt;p&gt;The optimal control problem where neither the terminal nor incremental cost are zero.&lt;/p&gt;

&lt;p&gt;\(J=K(t_1,\ x_1)+\int_{t_0}^{t_1}L(t,x,u)dt\)
 &lt;/p&gt;
&lt;h3 id=&quot;pontryagin-maximum-principle&quot;&gt;Pontryagin Maximum Principle&lt;/h3&gt;
&lt;p&gt;PMP provides a series of necessary conditions for continuous time optimal control problems. These principles bear a strong resemblance to the KKT necessary conditions. There are four components, outlined below:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Expression of the Hamiltonian – where L is the incremental cost expression&lt;/li&gt;
&lt;/ol&gt;

\[H=p_0 L(t,x,u)+ p^T f(t,x,u)\]

&lt;ol&gt;
  &lt;li&gt;Maximum Principle* – the control minimizer is a minimizer of the Hamiltonian&lt;/li&gt;
&lt;/ol&gt;

\[H\left(u^\ast,x,t\right)\le H(u,x,t)\]

&lt;ol&gt;
  &lt;li&gt;Adjoint Equations – time rate of change as it relates to the Hamiltonian&lt;/li&gt;
&lt;/ol&gt;

\[\dot{p}=-\nabla_xH(x,u,p,t)\]

&lt;ol&gt;
  &lt;li&gt;Transversality Conditions – constraints on the endpoints&lt;/li&gt;
&lt;/ol&gt;

\[p\left(t_1\right)-p_o\nabla_xK\left(x\left(t_1\right),t_1\right)=\ \sum_{i=1}^{j}{\alpha_i\nabla_x}g_i(x,u,t)\]

\[-H\left(x\left(t_1\right),u\left(t_1\right),p\left(t_1\right),t_1\right)-p_o\nabla_xK=\sum_{i=1}^{j}{\alpha_i\nabla_t}g_i(x,u,t)\]

&lt;ul&gt;
  &lt;li&gt;In the case of time varying control constraints, u must be a minimizer of the integral of the Hamiltonian over the duration of the time of flight.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If an optimization problem has some initial and end condition, the transversality conditions are expressed in terms of partials with respect to the terminal state and initial state.&lt;/p&gt;

\[p\left(t_1\right)-p_o\frac{\partial K}{\partial x_1}\left(x\left(t_0\right),x\left(t_1\right),\ t_0,t_1\right)=\ \sum_{i=1}^{j}\alpha_i\frac{\partial g_i}{\partial x_1}(x\left(t_0\right),x\left(t_1\right),\ t_0,t_1)\]

\[p\left(t_0\right)-p_o\frac{\partial K}{\partial x_0}\left(x\left(t_0\right),x\left(t_1\right),\ t_0,t_1\right)=\ \sum_{i=1}^{j}\alpha_i\frac{\partial g_i}{\partial x_0}(x\left(t_0\right),x\left(t_1\right),\ t_0,t_1)\]

&lt;p&gt;In general, the PMP statement of the necessary conditions assumes that the optimal control is a piecewise continuous function. Note that α is a vector of constant values. The following constraints must also apply:&lt;/p&gt;

\[p_0\in\left\{0,1\right\}\]

\[\left(p_0,\alpha\right)\neq0\]

&lt;p&gt;Application of the PMP necessary conditions results in a two-point boundary value problem to be solved.&lt;/p&gt;

&lt;h3 id=&quot;dynamic-programming-discrete-time&quot;&gt;Dynamic Programming (Discrete Time)&lt;/h3&gt;

&lt;p&gt;The central goal of dynamic programming is to determine a control policy, that is, the control u as a function of the state and time which will produce the optimal trajectory. This is achieved through construction of the cost-to-go function, otherwise known as the Bellman Function.&lt;/p&gt;

\[V_N=K(x)\]

\[V_k=\min_{u\in U}{L(k,\ x,u)+V_{i+1}(k,x,u)}\]

&lt;p&gt;The Bellman function must be computed backward in time from the terminal cost. The optimal control at a time instance k, is a function of the incremental cost at k, and the Bellman function at k+1.&lt;/p&gt;

\[u_k^\ast= \arg\min \ L\left(k,\ x,u\right)+V_{k+1}\left(k,x,u\right)\]

&lt;p&gt;To solve the dynamic programming problem, follow these steps and iterate backwards in time.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Start with \(V_N\)&lt;/li&gt;
  &lt;li&gt;Calculate \(Q_{N-1}=L_{N-1}+V_N\)&lt;/li&gt;
  &lt;li&gt;Find the optimal control as: \(u_{N-1}^\ast=argmin(Q_{N-1})\)&lt;/li&gt;
  &lt;li&gt;Use \(u_{N-1}^*\) to calculate \(V_{N-1}\)&lt;/li&gt;
  &lt;li&gt;Repeat&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Unfortunately, discrete dynamic programming scales very poorly. The number of operations increases exponentially with the number of states. Typically, DDP strategies are limited to problems with up to 5 states variables.&lt;/p&gt;

&lt;h3 id=&quot;dynamic-programming-continuous-time&quot;&gt;Dynamic Programming (Continuous Time)&lt;/h3&gt;
&lt;p&gt;In the continuous time case, we can show that the Bellman function must satisfy the following partial differential equation.&lt;/p&gt;

\[\min_{u\in U}{L\left(k,\ x,u\right)+\frac{\partial V(t,x)}{\partial t}+\frac{\partial V(t,x)}{\partial x}f(t,x,u)}\]

\[V\left(t_1,x\right)=K(x)\]

&lt;p&gt;This equation is known as the Hamilton-Jacobi-Bellman PDE. The solution can be found by finding the control which minimizes the Bellman PDE, in terms of the partials the Bellman function and x and t. Then plug this expression back into the PDE and solve for the Bellman function. Once the Bellman equation has been found, it can be plugged back into the expression for optimal control to obtain the optimal control. A continuously differential solution to the PDE has met sufficient conditions for optimality. Note that in system of multiple dimensions, the partial of V with respect to each state variable is a vector.&lt;/p&gt;

&lt;p&gt;The gradient of V with respect to all the state variables is in fact the adjoint variable vector used by PMP. In other words, the adjoint variable vector at time t, is exactly the sensitivity of the optimal cost to go changes in the state at the nominal optimal trajectory. This is similar to the idea of the price interpretation of Lagrange multipliers.&lt;/p&gt;

\[p\left(t\right)=\ \left(\frac{\partial V}{\partial x}\right)^T\]

&lt;h3 id=&quot;sufficient-conditions-for-existence-of-optimal-control-in-continuous-time-problems&quot;&gt;Sufficient Conditions for Existence of Optimal Control in Continuous Time Problems&lt;/h3&gt;

&lt;p&gt;If there exists an admissible control, i.e. u(t) exists within a set Ω where Ω is compact, that is a measurable function of time and it results in a state trajectory that satisfies the terminal condition, then there exists an optimal control. Assuming Lipshitz continuity holds for the equations of motion.&lt;/p&gt;

&lt;h3 id=&quot;singular-arcs--singular-control&quot;&gt;Singular Arcs &amp;amp; Singular Control&lt;/h3&gt;

&lt;p&gt;Singular arcs occur when minimization of the Hamiltonian with respect to the control does not provide any useful information about the control. This can occur for instance, if the adjoint variable in front of the control is equal to zero. Singular arcs must be defined over a real time interval and cannot simply occur at a time instance.&lt;/p&gt;

&lt;p&gt;Define a function of time, ρ(t), that is the coefficient in front of the control term. As an example, consider the following Hamiltonian.&lt;/p&gt;

\[H=p^T\left(f\left(x\right)+g\left(x\right)\ast u\right)\]

\[\rho\left(t\right)=p^T\left(t\right)\ast g\left(x\left(t\right)\right)\]

&lt;p&gt;Then the optimal control on a singular arc can be found by taking even derivatives of rho with respect to time.&lt;/p&gt;

\[\frac{\partial^{2q}\rho}{\partial t^{2q}}=h_1\left(p,x\right)+h_2\left(p,x\right)u=0\]

\[u^\ast(t)=\ -\frac{h_1(p^\ast(t),\ \ x^\ast(t))}{h_2(p^\ast(t),\ \ x^\ast(t))}\]

&lt;p&gt;Note that in a single input linear time invariant system, if the pair A, b and are controllable*, then singular arcs do not exist.&lt;/p&gt;

\[\dot{x}=Ax+Bu\]

&lt;h3 id=&quot;kelleys-necessary-conditions-for-optimality-of-singular-control&quot;&gt;Kelley’s Necessary Conditions for Optimality of Singular Control&lt;/h3&gt;
&lt;p&gt;Any candidate solution obtained via the previous method must be checked to obey the following condition. Kelley’s conditions must be satisfies to show the existence of singular arcs on an optimal control path.&lt;/p&gt;

\[\frac{\partial}{\partial u}\frac{d^k}{dt^k}\rho=0\ \ \ \ for\ k=0,\ \ldots2q-1\]

\[\left(-1\right)^{q+1}\frac{\partial}{\partial u}\frac{d^{2q}}{dt^{2q}}\rho\le0\]

&lt;h3 id=&quot;neighboring-extremal-optimal-control&quot;&gt;Neighboring Extremal Optimal Control&lt;/h3&gt;

&lt;p&gt;Assuming that the optimal control and trajectory have already been computed, this method provides a way to correct the optimal control without having to recompute it from scratch if the initial state is changed. It is a feedback law taking the following form:&lt;/p&gt;

\[u\left(t\right)=u^\ast\left(t\right)+\Gamma\left(T\right)\left(x\left(t\right)-x^\ast\left(t\right)\right)\]

&lt;p&gt;Where \(\Gamma\left(T\right)\) is a time varying gain \(T=t_1-t\). Neighboring extremal optimal control maintains the PMP necessary conditions approximately to the first order.&lt;/p&gt;

&lt;h3 id=&quot;linear-quadratic-optimal-control-problems&quot;&gt;Linear Quadratic Optimal Control Problems&lt;/h3&gt;
&lt;p&gt;This is a special format of optimal control problem where the equations of motion can be represented as a linear time invariant system, and the objective function is represented as a quadratic equation.&lt;/p&gt;

\[\dot{x}=Ax+Bu\]

\[J=\ \frac{1}{2}x^TSx+\frac{1}{2}\int{x^TQx+u^TRu\ dt}\]

&lt;p&gt;These systems can be analyzed in continuous time, discrete time, or through dynamic programming.&lt;/p&gt;

&lt;h3 id=&quot;continuous-time-lqr&quot;&gt;Continuous Time LQR&lt;/h3&gt;
&lt;p&gt;Begin by defining the Hamiltonian. It is also possible to show that \(p_0\) must take the value of one. Then apply PMP.&lt;/p&gt;

\[H=\ \frac{1}{2}p_0\left(x^TQx+u^TRu\ \right)+p^T(Ax+Bu)\]

\[u=\ -R^{-1}B^Tp\]

\[\dot{p}=-Qx-A^Tp\]

\[\dot{x}=Ax-BR^{-1}B^Tp\]

\[p\left(t_1\right)=S_fx(t_1)\]

&lt;p&gt;The adjoint equation and the equations of motion can be re-expressed in matrix form. Then the state transition matrices for linear systems are applied.&lt;/p&gt;

\[\left[\begin{matrix}\dot{x}\\\dot{p}\\\end{matrix}\right]=\left[\begin{matrix}A&amp;amp;-BR^{-1}B^T\\-Q&amp;amp;-A\\\end{matrix}\right]\left[\begin{matrix}x\\p\\\end{matrix}\right]=H\left[\begin{matrix}x\\p\\\end{matrix}\right]\]

\[\left[\begin{matrix}\Phi_{11}(t,t_1)&amp;amp;\Phi_{12}(t,t_1)\\\Phi_{21}(t,t_1)&amp;amp;\Phi_{22}(t,t_1)\\\end{matrix}\right]=\exp(H\left(t-t_1\right))\]

&lt;p&gt;We seek a solution to p(t) to the above necessary conditions in the form:&lt;/p&gt;

\[p\left(t\right)=P\left(t\right)x\left(t\right)\]

&lt;p&gt;Where P(t) is a time varying n x n matrix to be determined. Using this above format, it is plugged back into the adjoint equation expression to get the following result which must be satisfied by P(t).&lt;/p&gt;

\[\dot{P}\left(t\right)+PA-PBR^{-1}B^TP+Q+A^TP=0\]

&lt;p&gt;This is known as the &lt;strong&gt;Ricatti&lt;/strong&gt; equation. The following results are obtained&lt;/p&gt;

\[P\left(t_1\right)=\ S_f\]

\[P\left(t\right)=\left(\Phi_{21}+\Phi_{22}S_f\right)\left(\Phi_{11}+\Phi_{21}S_f\right)^{-1}\]

\[u^\ast(t)=\ -R^{-1}B^TP\left(t\right)x^\ast(t)\]

&lt;p&gt;Where \(x^\ast(t)\) is the solution to:&lt;/p&gt;

\[\dot{x}\left(t\right)=Ax\left(t\right)-BR^{-1}B^TP\left(t\right)x\left(t\right),\ \ \ \ x\left(t_0\right)=\ x_0\]

&lt;p&gt;Note that the above differential Ricatti equation must be solved backwards in time. A transformation of the P matrix can allow the problem to be solved forward in time.&lt;/p&gt;

\[\widetilde{P}\left(\tau\right)=P\left(t_1-\tau\right)\]

\[\widetilde{P}\left(0\right)=S_f\]

\[\frac{\partial\widetilde{P}(\tau)}{\partial\tau}=-\frac{\partial P\left(t_1-\tau\right)}{\partial t}=A^T\widetilde{P}+\widetilde{P}A+\widetilde{P}BR^{-1}B^T\widetilde{P}+Q\]

&lt;p&gt;In the infinite horizon case, if (A, B) is controllable and (A, C) is observable, then in the limit as t1 tends to infinity, P(t) will converge to a symmetric positive definite matrix P that satisfies the Algebraic Riccatti Equation.&lt;/p&gt;

\[PA-PBR^{-1}B^TP+Q+A^TP=0\]

&lt;p&gt;If (A, B) is stabilizable and (A, C) is observable/detectable, where Q = CTC, DARE has a unique positive definite/semi definite solution.&lt;/p&gt;

&lt;h3 id=&quot;discrete-time-lqr&quot;&gt;Discrete Time LQR&lt;/h3&gt;
&lt;p&gt;A set of continuous time equations of motion can be converted to a discrete time set of step update equations as follows:&lt;/p&gt;

\[\dot{x}=Ax+Bu\]

\[x_{k+1}=A_dx_k+B_du_k\]

\[A_d=e^{A\Delta T}\]

\[B_d=A^{-1}\left(e^{A\Delta T}-I\right)B\]

&lt;p&gt;In the following equations, the discrete time Ad is simply abbreviated as A. Given the initial conditions, x0, it is possible to express the state at any step as a function of the initial conditions and control input at each step (i.e. iterating forward in time through each step)&lt;/p&gt;

\[x_k=A^kx_0+\sum_{j=1}^{k-1}{A^{k-1-j}Bu_j}\]

&lt;p&gt;Apply the discrete time necessary conditions to this system.&lt;/p&gt;

\[H_k=\frac{1}{2}x_k^TQx_k+\frac{1}{2}u_k^TRu_k+p_{k+1}^T(Ax_k+Bx_k)\]

&lt;p&gt;The transversality conditions become:&lt;/p&gt;

\[p_N=\nabla_{x_N}K=\ S_fx_N\]

&lt;p&gt;Iterate backward in time to find the series of S and F at every time step.&lt;/p&gt;

\[S_N=S_f\]

\[F_{k-1}=-\left(R+B^TS_kB\right)^{-1}B^TS_kA\]

\[S_{k-1}=Q+A^TS_kA+A^TS_kBF_{k-1}\]

\[u_k^\ast=\ F_kx_k\]

&lt;p&gt;Which follows the form of a time varying state feedback control law. The adjoint variables at every step can be found similarly as:&lt;/p&gt;

\[p_k^\ast=\ S_kx_k\]

&lt;p&gt;The optimal control and trajectory can then be constructed forward in time beginning with xo and updating according to the optimal control at every point. As an aside, the cost to go comes out in this expression as follows:&lt;/p&gt;

\[J^\ast\left(x_k,k\right)=\ \frac{1}{2}x_k^TS_kx_k\]

&lt;p&gt;Note that the derivative of the cost to go is equal to the corresponding adjoint variables at k. This result implies that the adjoint variables are sensitivities of the cost to go with respect to changes in the state.&lt;/p&gt;

&lt;h3 id=&quot;steady-state-discrete-lqr&quot;&gt;Steady State Discrete LQR&lt;/h3&gt;
&lt;p&gt;As N tends to infinity, Sk may converge to a matrix S, where S satisfies the “steady state” version of the above equations.&lt;/p&gt;

\[S=Q+A^TSA+A^TSBF\]

\[F=\ -\left(R+B^TSB\right)^{-1}B^TSA\]

&lt;p&gt;The above can be written in as a function of only S, otherwise known as the discrete Riccati Algebraic Equation (DARE).&lt;/p&gt;

\[S=Q+A^TSA-A^TSB\left(R+B^TSB\right)^{-1}B^TSA\]

&lt;p&gt;The equivalent form of DARE for the infinite horizon LQR is&lt;/p&gt;

\[S=Q+A^TSA-A^TS\left(I+{BR^{-1}B}^TS\right)^{-1}A\]

&lt;h3 id=&quot;continuous-time-minimum-time-linear-time-invariant-optimal-control-problems&quot;&gt;Continuous Time, Minimum Time, Linear Time-Invariant Optimal Control Problems&lt;/h3&gt;

&lt;p&gt;Take a time invariant system, with given initial and terminal conditions. The objective is to minimize the transfer time.&lt;/p&gt;

\[\dot{x}=Ax+Bu\]

\[x\left(t_0\right)=x_0\]

\[x\left(t_1\right)=0\]

&lt;p&gt;The Hamiltonian is defined, and the adjoint equations are expressed as follows:&lt;/p&gt;

\[H=\ p_0+p^T\left(Ax+Bu\right)\]

\[\dot{p}\left(t\right)=\ -\left(\frac{\partial H}{\partial x}\right)^T=-A^Tp(t)\]

\[u_k^\ast=-sign(p^Tb_k)\]

&lt;p&gt;Where bk is an element in the B matrix. The optimal control assumes only the value of +1 and -1. The time instances at which the control switches from one to the other are called control switch points. Each component of the optimal control has a finite number of switch points. If all the eigenvalues of the matrix A are real-valued then the number of switch points of each component is at most n-1, where n is the dimension of A&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Eigen Values</title>
   <link href="https://ludavid15.github.io//eigen/"/>
   <updated>2021-08-10T00:00:00-07:00</updated>
   <id>https://ludavid15.github.io//eigen</id>
   <content type="html">&lt;p&gt;Eigenvalues are everywhere, from machine learning, to structural mechanics, to dynamics, to linear algebra. So just exactly what are these strange numbers?&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;Let’s take an N by N matrix and call it A. We’ll also define a length N vector v. Usually, multiplying a vector by a matrix (i.e. a rotation matrix) will change the direction of the original vector. However, if the product of matrix A and vector v is still in the same direction of v (but scaled by a factor λ) then we can say that v is an eigenvector of A, and that λ is the eigen value associated with that eigenvector. Mathematically:&lt;/p&gt;

\[Av=\ \lambda v\]

\[\left(A-\lambda I\right)v=0\]

\[determinant\left|A-\lambda I\right|=0\]

&lt;p&gt;Solving the above equation, we will find &lt;em&gt;up to&lt;/em&gt; N different eigenvalues, and &lt;em&gt;up to&lt;/em&gt; N different eigenvectors.&lt;/p&gt;

&lt;p&gt;This irrotational property of eigenvectors underlies their significance: eigenvectors carry information about the dimensional size (i.e. rank) and direction of matrices.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Machine Learning Introduction</title>
   <link href="https://ludavid15.github.io//mlintroduction/"/>
   <updated>2021-08-10T00:00:00-07:00</updated>
   <id>https://ludavid15.github.io//mlintroduction</id>
   <content type="html">&lt;p&gt;There is so much literature out there on machine learning that it can get pretty overwhelming. This post introduces machine learning one concept at a time, without getting into any math.&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;Before going further, it’s worth mentioning that many machine learning algorithms are built using optimization. There is almost always something to be optimized (an objective function - error, fitness, etc.), and different ways to run the optimization (genetic, linear, quadratic, etc.). Different algorithms may change the problem, but the name of the game remains the same (for example, the “learning rate” and “search step size” usually refer to the same thing!) Keep this in mind, because it helps simplify our perspective.&lt;/p&gt;

&lt;p&gt;For any machine learning algorithm, we should be able to identify three distinct aspects:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;The architecture&lt;/strong&gt;, or relationship between inputs and ouputs, which influences the&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Cost function&lt;/strong&gt;, which we minimize by using different&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Optimization techniques&lt;/strong&gt;.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;For a more mathematical discussion of machine learning algorithms, check out the &lt;a href=&quot;/notes/mlarchitectures&quot;&gt;original ML post&lt;/a&gt;!&lt;/p&gt;

&lt;h2 id=&quot;table-of-contents&quot;&gt;Table of Contents&lt;/h2&gt;

&lt;p&gt;In this post, we’ll talk about:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Supervised Learning&lt;/li&gt;
  &lt;li&gt;Unsupervised Learning&lt;/li&gt;
  &lt;li&gt;Representation Learning&lt;/li&gt;
  &lt;li&gt;Reinforcement Learning&lt;/li&gt;
  &lt;li&gt;Knowledge Based/Symbolic AI&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;supervised-learning&quot;&gt;Supervised Learning&lt;/h3&gt;

&lt;p&gt;When we know the type of output we want, but need to learn the function that will get us there, we use supervised learning. As the name implies, this method absolutely requires having a labeled dataset. If your problem doesn’t readily accept labels, this strategy will probably fall short. Try instead to identify if &lt;em&gt;parts&lt;/em&gt; of the solution involve identification.&lt;/p&gt;

&lt;p&gt;Supervised learning can be implemented with many architectures, and are usually associated with questions like:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;What is this?&lt;/li&gt;
  &lt;li&gt;What comes next?&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;unsupervised-learning&quot;&gt;Unsupervised Learning&lt;/h3&gt;

&lt;p&gt;In contrast to supervised learning, there is no “label” in supervised learning. This means that instead we are asking questions like:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;How are these alike?&lt;/li&gt;
  &lt;li&gt;What are the correlations?&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;One outcome of many unsupervised learning algorithms is that we can compress or generalize our data set. If you’ve ever compressed an image or a word document, you’ve made use of an unsupervised learning technique. Some algorithms include:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;K-means Clustering&lt;/li&gt;
  &lt;li&gt;Singular Value Decomposition&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/notes/machineLearning&quot;&gt;Independent Component Analysis&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Autoencoders&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A really cool outcome we get from unsupervised learning is the ability to generate new examples from the underlying patterns we discover, also known as generative modeling.&lt;/p&gt;

&lt;h3 id=&quot;representation-learning-or-feature-learning&quot;&gt;Representation Learning or Feature Learning&lt;/h3&gt;

&lt;p&gt;The goal of representation learning is to identify patterns in your data. This can be achieved both with supervised or unsupervised methods.&lt;/p&gt;

&lt;p&gt;Why? Because &lt;em&gt;patterns&lt;/em&gt; are useful for questions like:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;What is this? (Supervised learning)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;And questions like:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;How are these alike? (Unsupervised learning)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;It turns out that in many machine learning algorithms, we create tools to identify and track patterns anyway. Hence, representation learning can be both supervised or unsupervised learning.&lt;/p&gt;

&lt;p&gt;Here’s an example. We wish to write a program to classify flowers. Using a clustering approach, we might make measurements of the flower color or petal size and shape. K-means clustering would return the averages for each class. While we do find the averages, the properties were pre-defined.&lt;/p&gt;

&lt;p&gt;If we linearized the pixels of each image (n by m), we’d end up performing clustering in (\(n \times m\)) space, which is computationally expensive.&lt;/p&gt;

&lt;p&gt;So how can we get a machine to learn features? Well, when we perform supervised learning with something like a deep neural net, the last hidden layer before the output can actually be a set of features.&lt;/p&gt;

&lt;p&gt;Or in an unsupervised case, independent component analysis and autoencoders achieve this goal by looking for ways to represent the most original information in the fewest variables. The singular value decomposition and eigenvalues are two ways to do this.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Consider the example of rotations. A rotation matrix in 3D is a 3x3 matrix, for a total of nine variables. But it turns out that any rotation in 3D can be represented by only three Euler angles (Roll Pitch Yaw). If we have those three numbers, we can follow a specific set of rules to reconstruct the original object. In this way, the Euler angles can be thought of as “features” of the rotation matrix.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;reinforcement-learning&quot;&gt;Reinforcement Learning&lt;/h3&gt;

&lt;p&gt;Improvement through natural selection is the general idea of reinforcement learning. For some problems, success is measured by a distant goal, or by some cumulative performance. In these cases, it doesn’t make sense to define individual state variables. Here is where reinforcement learning comes in.&lt;/p&gt;

&lt;h3 id=&quot;knowledge-base-or-symbolic-ai&quot;&gt;Knowledge Base or Symbolic AI&lt;/h3&gt;

&lt;p&gt;Although other algorithms perform well enough (i.e. the output is good), they don’t gain any real “understanding” about what they’re doing, at least, not in the same capacity as you or me. And when something does goes wrong, it’s extremely difficult to identify the cause, especially when you’re dealing with NN’s that can have millions of weights.&lt;/p&gt;

&lt;p&gt;A knowledge base approach uses logic to make deductions. If I said that a cat is a type of mammal, and that all mammals are animals, then it could be deduced that a cat is a type of animal. These types of system are great for when we need to understand how the machine arrived at a decision. But because they operate on such an abstract level, building up the required database of statements is also a highly abstract task that relies on human input. Furthermore, many topics cannot be described with binary yes/no logic (things like the arts, personal opinions, relationships, etc.).&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Machine Vision and SLAM</title>
   <link href="https://ludavid15.github.io//vision/"/>
   <updated>2021-07-26T00:00:00-07:00</updated>
   <id>https://ludavid15.github.io//vision</id>
   <content type="html">&lt;p&gt;Machine vision refers broadly to any imaging analysis task performed by a computer. Meanwhile, simultaneous localization and mapping (SLAM) is a specific domain focused on obtaining an understanding of the environment and your position within it. These two often go hand in hand (but not always!).&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;The topic of perception and machine vision can be broken down into a few separate problems.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Odometry – where are you?*&lt;/li&gt;
  &lt;li&gt;Reconstruction/Mapping – where are things in the world?*&lt;/li&gt;
  &lt;li&gt;Semantics – what are things in the world?&lt;/li&gt;
  &lt;li&gt;Prediction – where will things in the world be?&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;em&gt;*The coordinate frame is very important! Positions are always defined with respect to something.&lt;/em&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Task&lt;/th&gt;
      &lt;th&gt;Implementation Stategy&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Odometry&lt;/td&gt;
      &lt;td&gt;Can be achieved with a number of things such as GPS, SLAM, internal IMU data, etc.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Reconstruction&lt;/td&gt;
      &lt;td&gt;Requires some sort of information about the environment. This can be achieved with cameras, LiDAR, radar, etc. There are also varying degrees to which we can process and store our internal model of the environment.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Semantics&lt;/td&gt;
      &lt;td&gt;Typically achieved through the use of machine learning, and some sort of image classification algorithm.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Prediction&lt;/td&gt;
      &lt;td&gt;Usually done with machine learning, or some kind of regression model.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;image-projections&quot;&gt;Image Projections&lt;/h3&gt;

&lt;p&gt;Consider a set of points in 3D space, defined by the camera frame. The projection of this point into the image plane can be expressed as:&lt;/p&gt;

\[u=f\frac{p_x^w}{p_z^w}\]

\[v=f\frac{p_y^w}{p_z^w}\]

&lt;p&gt;Where \(u\), \(v\) are the coordinates of point P expressed in the image plane, and f is the focal length of the camera. Note that \(u\), \(v\) are not pixel coordinates, but image plane coordinates defined from an origin.&lt;/p&gt;

&lt;p&gt;An important characteristic of 2D images is the lack information regarding depth. A machine cannot tell if we are looking at a large object very far away or a close object nearby. There are multiple ways around this problem, including but not limited to LiDAR, Radar, or triangulation.&lt;/p&gt;

&lt;h3 id=&quot;feature-identification&quot;&gt;Feature Identification&lt;/h3&gt;

&lt;p&gt;Although modern vision systems may incorporate object identification and tracking, a more rudimentary system may begin by tracking local features. This begs the question, what defines a good feature? Long story short, corners are good features, while edges and surfaces are not.&lt;/p&gt;

&lt;p&gt;Consider a rectangular window centered around some pixel \(\widetilde{x}\). This is a “good” feature if shifting the window in any direction produces a new window that is different from the original. Mathematically, let us define:&lt;/p&gt;

\[G=\sum_{W\left(x\right)}^{\ }{\nabla I\left(\widetilde{x}\right)\nabla I\left(\widetilde{x}\right)^\top}\]

&lt;p&gt;Where \(\nabla I\left(\widetilde{x}\right)\) is the gradient of the image. Two common ways of scoring the corner is with either the Harris score, or the Shi-Tomasi score. These are, respectively:&lt;/p&gt;

\[C\left(G\right)=det\left(G\right)-ktr\left(G\right)^2\]

\[S\left(G\right)=\lambda_{min}\left(G\right)\]

&lt;p&gt;Where \(\lambda_{min}\) is a function that returns the smallest eigenvalue of the matrix.&lt;/p&gt;

&lt;h3 id=&quot;outliers&quot;&gt;Outliers&lt;/h3&gt;

&lt;p&gt;When we use a quadratic loss function, the weights of outliers are exaggerated. Thus instead of fitting the correct data, we end up fitting to the incorrect ones. This is not an easy problem to overcome, because we do not know ahead of time which data points are the wrong ones, but a few outlier robust methods do exist.&lt;/p&gt;

&lt;h3 id=&quot;random-consensus-sampling-ransac&quot;&gt;Random Consensus Sampling (RANSAC)&lt;/h3&gt;

&lt;p&gt;From consecutive image frames, one can perform feature matching, and calculate the change in camera position between frames. However, given a set of matched features (typically called correspondences), there are bound to be a few mis-identified matches. RANSAC provides a method for dealing with these outliers.&lt;/p&gt;

&lt;p&gt;The basic idea is pretty simple. From the entire complete set of “matches”, we take a random set, and calculate the resulting change in position. We then repeat with another random set, and another, and check to see if there is agreement.&lt;/p&gt;

&lt;h3 id=&quot;image-segmentation&quot;&gt;Image Segmentation&lt;/h3&gt;

&lt;p&gt;Broadly, image segmentation is pixel classification. The ultimate goal is to find meaningful groupings. Note that this can be done independently, in combination with, or as step in object classification, which involves finding labels. Traditional image segmentation methods are also not necessarily feature tracking methods or SLAM methods. Here are a few, ordered approximately by increasing complexity:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Hard-coded thresholds&lt;/li&gt;
  &lt;li&gt;Hard-coded kernels, like a sobel filter (which is basically an edge detector)&lt;/li&gt;
  &lt;li&gt;Watershed algorithms&lt;/li&gt;
  &lt;li&gt;Otsu-multi-level thresholding, a.k.a. K-means clustering&lt;/li&gt;
  &lt;li&gt;Convolutional neural networks (e.g. YOLO)&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;simultaneous-localization-and-mapping-slam&quot;&gt;Simultaneous Localization and Mapping (SLAM)&lt;/h3&gt;

&lt;p&gt;SLAM is a process which covers the first two goals in computer vision - odometry and mapping. SLAM then can be further subdivided into two components, a &lt;strong&gt;front end&lt;/strong&gt; which identifies features in the environment, and a &lt;strong&gt;back-end&lt;/strong&gt; which builds an internal map of those features.&lt;/p&gt;

&lt;h3 id=&quot;misc-definitions&quot;&gt;Misc Definitions&lt;/h3&gt;

&lt;p&gt;Isomorphism – a form of transformation that preserves structure.&lt;/p&gt;

&lt;p&gt;Homography – an isomorphism between projected images.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Astrodynamics</title>
   <link href="https://ludavid15.github.io//astrodynamics/"/>
   <updated>2021-06-23T00:00:00-07:00</updated>
   <id>https://ludavid15.github.io//astrodynamics</id>
   <content type="html">&lt;p&gt;Astrodynamics is a lot like any other field of dynamics, except we now have an additional equation to consider: the law of universal gravitation. This leads to some strange and counterintuitive results - like slowing down to catch up!&lt;/p&gt;

&lt;!--more--&gt;

&lt;h3 id=&quot;keplers-laws-of-planetary-motion&quot;&gt;Kepler’s Laws of Planetary Motion&lt;/h3&gt;

&lt;p&gt;As good a place to start as any. These are more a set of observations than a theoretical explanation for celestial motion.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;All planets move in elliptical orbits, with the Sun at the focus.&lt;/li&gt;
  &lt;li&gt;A line that connects a planet to the Sun sweeps out equal areas in equal times.&lt;/li&gt;
  &lt;li&gt;The period of an orbit is proportional to the root of the cube of the semimajor axis.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;2d-orbits&quot;&gt;2D Orbits&lt;/h3&gt;

&lt;p&gt;The two-dimensional orbital frame is also known as the perifocal frame (i.e. periapsis and apoapsis vectors are in the plane). We also assume that one body is significantly larger than the other. Given θ as the true anomaly of your orbit, orbital radius from a focus point is:&lt;/p&gt;

\[r=\ \frac{h^2}{\mu}\frac{1}{1+e\cos(\theta)}\]

&lt;p&gt;Where µ is the gravitational parameter of the larger body being orbited. Standard values for objects in our solar system can be found &lt;a href=&quot;https://en.wikipedia.org/wiki/Standard_gravitational_parameter&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;For each orbit, we can also define the specific angular momentum \(\vec{h}\):&lt;/p&gt;

\[\vec{h}=\vec{r}\times\vec{v}\]

&lt;p&gt;Where \(\vec{r}\) and \(\vec{v}\) are the position vector and velocity vector at a point in time. The total angular momentum remains constant through the orbit. If the orbit is elliptical, we can define an apoapsis distance, periapsis distance, and semimajor axis distance.&lt;/p&gt;

\[2a=\ r_a+r_p\]

&lt;p&gt;The eccentricity (measure of how elliptical an orbit is) can also be calculated with:&lt;/p&gt;

\[e=\ \frac{r_a-r_p}{r_a+r_p}\]

&lt;p&gt;Through conservation of energy we arrive at the Vis-Viva equation. An orbit with a specific energy of zero is defined to be on a parabolic orbit. A positive specific energy means that it is on an escape trajectory, while a negative value means it is captured by the planet’s gravity (circular or elliptical).&lt;/p&gt;

&lt;h3 id=&quot;vis-viva-equation&quot;&gt;Vis Viva Equation&lt;/h3&gt;

&lt;p&gt;This equation relates the current velocity and radius of an object in orbit to the total energy, or semi-major axis of it’s orbit. This is very useful for computing Hohman transfers.&lt;/p&gt;

\[\frac{v^2}{2}-\frac{\mu}{r}=-\frac{\mu}{2a}=\varepsilon\]

&lt;h3 id=&quot;orbital-period&quot;&gt;Orbital Period&lt;/h3&gt;

&lt;p&gt;The orbital period is the total time is takes to complete a single revolution&lt;/p&gt;

\[\left(T\right)=2\pi\sqrt{\frac{a^3}{\mu}}\]

&lt;p&gt;Using the energy equation, we can show that for a circular orbit, where r = a, the circular orbit velocity is simply:&lt;/p&gt;

\[V=\ \sqrt{\frac{\mu}{r_1}}\]

&lt;h3 id=&quot;low-thrust-transfers&quot;&gt;Low Thrust Transfers&lt;/h3&gt;

&lt;p&gt;In general, there is no way to algebraically solve for a low thrust trajectory. Instead, for problems of this type we need to solve for x(t) and u(t) through trajectory optimization.&lt;/p&gt;

&lt;p&gt;An initial estimate for the delta V cost of a low thrust transfer orbit can be obtained by assuming that the resulting transfer path is made up of many circular orbits with gradually increasing radius. This applies when the initial and final orbits are circular and transfer time is long.&lt;/p&gt;

\[∆V= \sqrt{\frac{μ}{r_1}}-\sqrt{\frac{μ}{r_2}}\]

&lt;p&gt;Derivation:&lt;/p&gt;

&lt;p&gt;We start with Newton’s first law, relating forces to acceleration.&lt;/p&gt;

\[m\frac{d\vec{V}}{dt}=\vec{T}-\frac{\mu m}{r^3}\vec{r}\]

&lt;p&gt;We assume T is aligned with velocity. Both sides of the expression are dotted with V.&lt;/p&gt;

\[\vec{V}\bullet\left(m\frac{d\vec{V}}{dt}\right)=\vec{V}\bullet\left(T\ast\hat{V}-\frac{\mu m}{r^3}\vec{r}\right)\]

\[\frac{1}{2}\frac{d}{dt}V^2=\frac{T}{m}\vec{V}-\frac{1}{2}\frac{\mu}{r^2}\frac{d}{dt}r^2\]

&lt;p&gt;We re-write the thrust in terms of the mass flow rate and the exhaust velocity and integrate.&lt;/p&gt;

\[T=\ \dot{m}U_{ex}\]

\[\frac{d\vec{V}}{dt}=-\frac{d}{dt}\ln{\left(m\right)}U_{ex}-\frac{\mu}{r^2}\frac{dr}{dt}\frac{1}{V}\]

\[∆V=-U_{ex}ln\frac{m_f}{m_o}-\int_{t_o}^{t_f}\frac{μ}{r^2}\frac{dr}{dt}\frac{1}{V}dt\]

&lt;p&gt;With a circular approximation, we can substitute the magnitude of velocity in with the radius.&lt;/p&gt;

\[V=\sqrt{\frac{\mu}{r}}\]

&lt;p&gt;Integrating the “gravity drag” term from inner radius to outer radius yields the circular transfer approximation equation.&lt;/p&gt;

&lt;p&gt;For short transfers, low thrust trajectories result in a much higher time of flight, but as the transfer distance increases, EP transfer times become better than traditional impulsive options, due to a higher achieved maximum velocity from long periods of sustained thrust.&lt;/p&gt;

&lt;h3 id=&quot;lagrange-points&quot;&gt;Lagrange Points&lt;/h3&gt;

&lt;p&gt;A lagrange point is a stable orbit position where the gravitional pull and centrifugal force from two other bodies is at an equilibrium. In a three-body system, there are 5 lagrange points.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The James Webb Space Telescope is at the Earth-Sun Lagrange point L2!&lt;/p&gt;
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>Aircraft</title>
   <link href="https://ludavid15.github.io//aircraft/"/>
   <updated>2021-06-21T00:00:00-07:00</updated>
   <id>https://ludavid15.github.io//aircraft</id>
   <content type="html">&lt;p&gt;This post covers some principles of aircraft performance, design, and aerodynamics. It’s an assortment of notes collected from my undergraduate courses at UCLA, so it’s a little messy.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h3 id=&quot;basic-equations-of-flight&quot;&gt;Basic Equations of Flight:&lt;/h3&gt;

&lt;p&gt;These two equations summarize the aerodynamic forces acting on an airplane as if it were a rigid body.&lt;/p&gt;

\[L=\ \frac{1}{2}\rho U^2SC_L\]

\[D=\ \frac{1}{2}\rho U^2SC_D\]

&lt;p&gt;Where \(C_{D,min}\) is the contribution due to parasitic drag. We add on the contribution from induced drag (itself a function of the coefficient of lift) to find the total drag \(C_D\) during flight. Recall that \(\frac{1}{2}\rho U^2\) is defined as the dynamic pressure.&lt;/p&gt;

&lt;p&gt;We’ll also use a capital D and capital L to denote total coefficient of drag and lift for the wing, vs a lowercase d and lowercase l for local coefficient of drag and lift (which are functions of the local angle of attack).&lt;/p&gt;

&lt;h3 id=&quot;drag&quot;&gt;Drag&lt;/h3&gt;
&lt;p&gt;There are three main types of drag: parasitic, induced, and wave. The total drag coefficient is a function of parasitic and induced drag coefficient.&lt;/p&gt;

\[C_D=\ C_{D,min}+\frac{1}{\pi Ae}{C_L}^2\]

&lt;h3 id=&quot;aircraft-performance&quot;&gt;Aircraft Performance&lt;/h3&gt;
&lt;p&gt;In steady flight, the thrust is equal to drag (thus the airplane does not accelerate).&lt;/p&gt;

\[Power=Thrust\ast Velocity\]

&lt;h3 id=&quot;rate-of-descent&quot;&gt;Rate of Descent&lt;/h3&gt;

&lt;p&gt;First two equations for rate of descent are used for propeller driven/glider aircraft.&lt;/p&gt;

\[Rate\ of\ Descent\ =\ \sqrt{\frac{W}{S}\frac{2}{\rho}\frac{C_D^2}{C_L^3}}\]

\[V=\ \sqrt{\frac{2W}{\rho S C_L}}\]

&lt;h3 id=&quot;rate-of-climb&quot;&gt;Rate of Climb:&lt;/h3&gt;

&lt;p&gt;First equation is used for a jet (since thrust is constant at different velocities. Second equation is used for propeller aircraft (since power is constant at different velocities).&lt;/p&gt;

\[RC=\ \frac{\left(T_{av}-T_{req}\right)V}{W}\]

\[RC=\ \frac{\left(P_{av}-P_{req}\right)}{W}\]

&lt;p&gt;Climb gradient is calculated as the climb rate divided by the flight speed. Absolute ceiling is defined as the altitude at which RC = 0.&lt;/p&gt;

\[\gamma=\ \frac{RC}{V}\]

&lt;h3 id=&quot;summary-of-lift-coefficients-and-their-uses&quot;&gt;Summary of Lift Coefficients and Their Uses&lt;/h3&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;\(Max\ C_L\)&lt;/td&gt;
      &lt;td&gt;Stall speed&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;Lift constrained load factor&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;\(Max \ \frac{C_L^\frac{1}{2}}{C_D}\)&lt;/td&gt;
      &lt;td&gt;Max range for jets&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;\(Max\ \frac{C_L}{C_D}\)&lt;/td&gt;
      &lt;td&gt;Min drag Condition&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;Max Climb Rate for Jets&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;Max Range for Props &amp;amp; Gliders&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;Max Endurance for Jets&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;\(C_L=\sqrt{C_{D,0}\pi Ae}\)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;\(Max\ \frac{C_L^\frac{3}{2}}{C_D}\)&lt;/td&gt;
      &lt;td&gt;Min power condition&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;Min climb rate for propeller planes&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;Max Endurance for Props and Gliders&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;\(C_L=\sqrt{3C_{D,0}\pi Ae}\)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;cruise-performance&quot;&gt;Cruise Performance&lt;/h3&gt;

&lt;p&gt;Range &amp;amp; Endurance for a propeller aircraft.&lt;/p&gt;

\[R=\ \frac{\eta_{propulsive}}{c_p}\frac{C_L}{C_D}ln\left(\frac{W_i}{W_f}\right)\]

\[E=\ \frac{\eta_{propulsive}{C_L}^{3/2}}{c_PC_D}\sqrt{2\rho S}\left(\frac{1}{W_f^{1/2}}-\frac{1}{W_i^{1/2}}\right)\]

&lt;p&gt;Range &amp;amp; Endurance for a jet aircraft.&lt;/p&gt;

\[R=\ \frac{2}{c_t}\frac{C_L^{1/2}}{C_D}\sqrt{\frac{2}{\rho S}}\left({W_0}^{1/2}-{W_f}^{1/2}\right)\]

\[E=\ \frac{1}{c_t}\frac{C_L}{C_D}\ln(\frac{W_0}{W_1})\]

&lt;p&gt;Where \(c_p\) is (power/brake) specific fuel consumption (lbf/shp/hr) and \(\eta_{propulsive}\) is the propeller efficiency. Where \(c_T\) is the thrust specific fuel consumption. (Different from just the power specific fuel consumption).&lt;/p&gt;

&lt;p&gt;Range for a battery powered propeller aircraft&lt;/p&gt;

\[R=\ \left(\frac{C_L}{C_D}\right)\left(\frac{\eta}{W}\right)E\]

&lt;p&gt;In general, we can solve for range with the following equation:&lt;/p&gt;

\[R=\int_{W_f}^{W_i}{\frac{U\ast L}{c_t\ast D}\frac{dW}{W}}\]

&lt;p&gt;In a headwind, aircraft should fly faster to maximize range, while in a tailwind aircraft should fly flower to maximize range.&lt;/p&gt;

&lt;h3 id=&quot;carsons-speed&quot;&gt;Carson’s Speed&lt;/h3&gt;

&lt;p&gt;Highest speed to thrust ratio (also known as optimum cruise). Carson’s speed for a propeller aircraft is the same as velocity for max jet aircraft range. Turns out, endurance speed, range speed, and Carson’s speed are all related by \(3^{1/4}\).&lt;/p&gt;

&lt;h3 id=&quot;maneuvering&quot;&gt;Maneuvering:&lt;/h3&gt;

&lt;p&gt;We define the loading factor as the ratio of lift to weight. When we turn, our lift vector angles, and so total lift must increase to balance the weight. At low velocities, the max load factor is constrained by how much lift we can produce, while at higher velocities it is constrained by how much thrust we can produce (since there is less lift at low velocities, and more drag at higher velocities).&lt;/p&gt;

\[Turning\ Radius=\ \frac{U^2}{g\sqrt{\eta^2-1}}=\frac{mU^2}{Lsin\phi}\]

\[Turn\ Rate\ \left(w\right)=\ \frac{g\sqrt{\eta^2-1}}{V}\]

\[\eta=\ \frac{Lift}{Weight}\]

\[\eta_{Lift\ Constrained}=\frac{1}{2}\rho U^2\frac{C_{L,max}}{\frac{(W}{S)}}\]

\[\eta_{Thrust\ Constrained}=\frac{L}{D}\left(\frac{T_{Available}}{W}\right)_{Max}\]

&lt;p&gt;Note that when we bank, stall velocity increases (i.e. we need to fly faster when we bank to maintain steady flight). To minimize turn radius &amp;amp; maximize turn rate, decrease wing loading and decrease K (1/πAe).&lt;/p&gt;

&lt;p&gt;Symmetric Pull Up (When L &amp;gt; W) there is a centripetal force felt by the plane. Recall that rate of turn is equal to turn velocity over radius and is still applicable here.&lt;/p&gt;

\[R=\frac{U^2}{g\left(\eta-1\right)}\]

&lt;h3 id=&quot;takeoff-and-landing&quot;&gt;Takeoff and Landing:&lt;/h3&gt;

&lt;p&gt;The longer the runway, the higher our max refusal velocity is (speed above which we can no longer slow down to a stop). A “balanced field length” is one such that this max refusal speed is the same as the required takeoff velocity. Above this velocity, a pilot must take off. Below it, they must slow down.&lt;/p&gt;

&lt;p&gt;Ground roll distance and air distance. Assumes acceleration varies linearly with velocity squared. Equation below uses terms calculated at \(0.7V_{Liftoff}\).&lt;/p&gt;

\[S_G=\frac{(V_{Liftoff}-V_{headwind})^2}{2g\left[\left(\frac{T}{W}-\mu_g\right)-\frac{(C_{D,g}-\mu_gC_{L,g})\bar{q}}{\frac{W}{S}}\right]}\]

\[S_A=\frac{mg}{\left(T-D\right)_{avg}}\left[\frac{V_2^2-{V_{Liftoff}}^2}{2g}+h_{screen}\right]\]

\[S_{G,Landing}=\frac{V_{Touchown}^2}{2a_{0.7Vtouchdown}}+NV_{Touchdown}\]

&lt;h3 id=&quot;stability&quot;&gt;Stability:&lt;/h3&gt;
&lt;p&gt;Contribution from the wing to the moment about the center of gravity is expressed as:&lt;/p&gt;

\[C_{M,\ CG,Wing}=\ C_{M,\ AC,\ Wing}+C_{L,Wing}\ast(h_{cg}-h_{ac,Wing})\]

\[C_{L,Wing}=\ a_W\alpha\]

&lt;p&gt;Where \(h_{cg}\) and \(h_{ac,Wing}\) is the distance measured from the leading edge of the wing to the plane’s center of gravity and the wing’s aerodynamic center respectively, all normalized by the chord length.&lt;/p&gt;

&lt;p&gt;Similarly, the tail’s contribution to moment about the airplane’s center of gravity is:&lt;/p&gt;

\[C_{M,\ CG,Tail}=\ C_{M,\ AC,\ Tail}-C_{L,Tail}\ast\frac{l_{tail}}{C}\frac{S_{Tail}}{S_{Wing}}\]

\[C_{L,Tail}=\ a_T\alpha\left(1-\varepsilon\right)-a_Ti_t\]

\[Volume\ Coefficient\ \left(V_H\right)=\ \frac{l_{tail}}{C}\frac{S_{Tail}}{S_{Wing}}\]

&lt;p&gt;Due to downwash, the AoA observed by the tail is not the same as the AoA experienced by the wing. Furthermore, the tail is usually positioned at some different AoA anyway, represented here as an additional incidence angle.&lt;/p&gt;

&lt;p&gt;This leads to a net equation for complete Coefficient of Moment about the CG:&lt;/p&gt;

\[C_{M,\ CG}=\ C_{M,\ AC,\ Wing}+a_W\left[{(h}_{cg}-h_{ac,Wing})-V_H\frac{a_T}{a_W}(1-\varepsilon)\right]\alpha+C_{M,\ AC,\ Tail}+V_Ha_Ti_T\]

&lt;p&gt;If we replace \(h_{cg}\) with hnuetral point, we can take the derivative of the above expression with respect to angle of attack and set it equal to zero. This will allow us to find the neutral point position.&lt;/p&gt;

\[h_n=\ \frac{h_{ac,w}+h_{ac,t}\frac{S_T}{S_W}\frac{a_T}{a_W}(1-\varepsilon)}{1+\frac{S_T}{S_W}\frac{a_T}{a_W}(1-\varepsilon)}\]

&lt;p&gt;For static stability, CG must be located ahead of the neutral point. The difference between these two points is called the “static margin” and usually defined as a unitless value.&lt;/p&gt;

&lt;h3 id=&quot;trim-flight&quot;&gt;Trim flight:&lt;/h3&gt;
&lt;p&gt;For trim flight (that is, \(L=W\) and \(M_{cg} = 0\)), the moment must be zero at a positive AoA that will allow for lift to equal weight.&lt;/p&gt;

\[C_L=C_{L,\alpha}\ \alpha+C_{L,i}i_t\]

\[C_M=C_{M,AC}+C_{M,\alpha}\alpha+C_{M,i}i_t\]

\[C_{M,\alpha}=C_{L,\alpha}\ \left(h_{cg}-h_n\right)=a_w\left[\left(h_{cg}-h_{ac,wing}\right)-V_H\frac{a_T}{a_W}\left(1-\varepsilon\right)\right]\]

\[C_{L,\alpha}=\ a_W+a_T\frac{S_T}{S_W}\left(1-\varepsilon\right)\]

\[C_{L,i}=\ -a_T\frac{S_T}{S_W}\]

\[C_{M,i}=\ a_TV_H\]

\[i_t=\ -\frac{C_{M,AC}\ C_{L,\alpha}+C_{M,\alpha}C_L}{C_{L,\alpha}C_{M,i}-C_{M,\alpha}C_{L,i}}\]

&lt;p&gt;For actual planes with an elevator, we can deflect the elevator to achieve trim flight. This will introduce another term into our equation for moment coefficient and our term for lift coefficient. We’ll call the elevator deflection angle δ. Note that for the following equation we assume that the contribution to lift from \(C_{L,i}\ast i_t\) is small.&lt;/p&gt;

\[\delta_{elevator}=\ -\frac{C_{M,0}\ C_{L,\alpha}+C_{M,\alpha}C_L}{C_{L,\alpha}C_{M,\delta}-C_{M,\alpha}C_{L,\delta}}\]

\[C_{M,0}=C_{M,AC}+C_{M,i}i_t\]

&lt;p&gt;Note that \(C_L\) is the only term here that varies as a function of our flight characteristics. All other coefficients are constants.&lt;/p&gt;

&lt;h3 id=&quot;flapped-airfoils&quot;&gt;Flapped Airfoils&lt;/h3&gt;
&lt;p&gt;Flaps include ailerons, elevators, and rudders. For smaller angular deflections, we can model it as an equivalent change in the angle attack of the entire airfoil according to this equation:&lt;/p&gt;

\[i_{effective}=\ i_{airfoil}+\tau\delta_{flap}\]

&lt;p&gt;Where τ is a correction coefficient that should be looked up in a table.&lt;/p&gt;

&lt;h3 id=&quot;stick-free-neutral-point&quot;&gt;Stick Free Neutral Point:&lt;/h3&gt;
&lt;p&gt;When the pilot lets go of the stick, the elevator will fall into an equilibrium position where there is no moment on the hinge. This shifts the neutral point to the “stick free neutral point” (denoted here with an apostrophe).&lt;/p&gt;

\[h_n-{h^\prime}_n=(1-f)V_H\frac{a_T}{a_W}\left(1-\varepsilon\right)\]

\[{a\prime}_T=a_T\left(1-\frac{C_{L,T,\delta}}{\alpha_T}\frac{C_{h,\alpha,T}}{C_{h,\delta}}\right)=\ a_Tf\]

&lt;h3 id=&quot;speed-stability&quot;&gt;Speed Stability&lt;/h3&gt;
&lt;p&gt;An aircraft having speed stability is one that wants to return to constant speed when the speed changes. This is achieved when cg is in front of the stick free neutral point. (This is because stick force decreases with velocity. Say aircraft speeds up. Stick force will decrease, causing a pitch up, and speed decreases again.)&lt;/p&gt;

&lt;p&gt;Stability Derivatives&lt;/p&gt;

&lt;p&gt;Summary of Aircraft Coordinate Systems
|L	|Roll Moment	|X	    |Forward Acceleration
|M	|Pitch Moment	|Y	    |Lateral Acceleration
|N	|Yaw Moment	    |Z	    |Vertical Acceleration
|p	|Roll Rate	    |u	    |Forward Velocity
|q	|Pitch Rate	    |v	    |Lateral Velocity (Side Slip)
|r	|Yaw Rate	    |w	    |Vertical Velocity&lt;/p&gt;

&lt;p&gt;Some of the more important stability derivatives are presented below, along with a physical explanation.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th&gt;Damping Terms&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;\(L_p(-)\)&lt;/td&gt;
      &lt;td&gt;Roll moment due to roll rate&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;As we start to roll, one wing moves down while the other moves up. This changes angle of attack over each wing and creates a restoring force.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;\(N_r(-)\)&lt;/td&gt;
      &lt;td&gt;Yaw moment due to yaw rate&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;Side slips angle induces lift on the vertical stabilizer, which creates a restoring yaw moment&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;\(M_q(-)\)&lt;/td&gt;
      &lt;td&gt;Pitch moment due to pitch rate&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th&gt;Angle Dependent Moments&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;\(L_\beta(-)\)&lt;/td&gt;
      &lt;td&gt;Roll moment due to side slip angle&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;Without a dihedral, side slips angle creates no roll moment. With a dihedral, side slip angle introduces a horizontal component to the velocity vector, and thus changes AoA over each wing to create a restoring force.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;\(N_\beta(+)\)&lt;/td&gt;
      &lt;td&gt;Yaw moment due to side slip angle&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;Side slip angle induces lift on the tail, thus creating lift that tends to increase yaw moment.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th&gt;Rate Dependent Moments (But not damping terms)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;\(L_r(+)\)&lt;/td&gt;
      &lt;td&gt;Roll moment due to yaw rate&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;Positive yaw leads to left wing moving forward while right wing moves backwards, decreasing local velocity. Thus, lift increases over the left and decreases over the right, leading to a positive roll moment.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;\(N_p(-)\)&lt;/td&gt;
      &lt;td&gt;Yaw moment due to roll rate&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;Roll leads to change in AoA over each wing and change in spanwise drag, which leads to a positive yaw moment. At the same time, since AoA changes, lift vector over each wing also changes direction slightly (leans forward on downward wing due to higher AoA) which leads to a negative yaw moment.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;\(M_{\dot{\alpha}}(-)\)&lt;/td&gt;
      &lt;td&gt;Pitch moment due to AoA rate&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;When AoA of the wing changes, downwash changes as well, but lags before reaching the tail. Thus, for a moment the tail experiences the original downwash, resulting in a pitch moment.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;longitudinal-motion&quot;&gt;Longitudinal Motion&lt;/h3&gt;
&lt;p&gt;To increase equilibrium climb rate, increase engine power. To increase equilibrium speed, increase elevator deflection angle. Longitudinal motion can be represented with following matrix, known as the State Space, which relates the rates to the state vector and control vector.&lt;/p&gt;

&lt;h3 id=&quot;phugoid-mode&quot;&gt;Phugoid Mode&lt;/h3&gt;
&lt;p&gt;This is the low frequency mode which result from the slow trade between potential and kinetic energy. This is a very uncomfortable experience when occurring in passenger jets and should be mitigated. In this mode, we assume AoA remains constant.&lt;/p&gt;

\[\omega_{natural}=\ \sqrt2\frac{g}{u_0}\]

\[\zeta=\ \frac{1}{\sqrt2}\frac{1}{\frac{L}{D}}\]

&lt;h3 id=&quot;short-period&quot;&gt;Short Period&lt;/h3&gt;

&lt;p&gt;Associated with faster frequency oscillations due to change in AoA. Although it is faster, it is more highly damped.&lt;/p&gt;

\[\omega_{natural}=\ \sqrt{\frac{Z_\alpha M_q}{u_0}-M_\alpha}\]

\[\zeta=\ \frac{-\left(M_q+M_{\dot{\alpha}}+\frac{Z_\alpha}{u_0}\right)}{2\omega_n}\]

&lt;h3 id=&quot;lateral-motion&quot;&gt;Lateral Motion&lt;/h3&gt;
&lt;p&gt;Roll and Yaw are coupled, but distinct from pitch, hence the two are grouped together as lateral directional motion. As with longitudinal motion, lateral motion can be represented by the state space.&lt;/p&gt;

&lt;h3 id=&quot;roll-mode&quot;&gt;Roll Mode&lt;/h3&gt;
&lt;p&gt;Consists of pure rolling motion, where other dimensions are constrained. In this scenario roll moment is only affected by role rate and aileron deflection.&lt;/p&gt;

\[L_p=\ \frac{QSb^2C_{lp}}{2I_xu_0}\]

&lt;h3 id=&quot;dutch-roll&quot;&gt;Dutch Roll&lt;/h3&gt;

&lt;p&gt;Note that \(N_p(-)\) &amp;amp; \(L_r(+)\) will tend to drive each other to divergence, however both roll and yaw are also self-damping terms. Thus, this mode is driven primarily by side slipping and yawing motions. It results in higher frequency oscillations in which the wingtips trace out circles. Worsened by wing dihedral.&lt;/p&gt;

&lt;h3 id=&quot;spiral-mode&quot;&gt;Spiral Mode&lt;/h3&gt;

&lt;p&gt;Associated with a banking maneuver that diverges (roll and yaw). Spiral mode is brought about when the bank angle and heading angle (UNRELATED TO RATE!) pass a critical value, and yaw and roll both steadily increase.&lt;/p&gt;

&lt;p&gt;It can be unstable, but since it acts very slowly it is not a huge problem because the pilot can adjust by changing the ailerons. Can also be reduced by adding dihedral to the wings. 
 &lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Intro to Control Theory</title>
   <link href="https://ludavid15.github.io//controls/"/>
   <updated>2021-06-15T00:00:00-07:00</updated>
   <id>https://ludavid15.github.io//controls</id>
   <content type="html">&lt;p&gt;In previous posts, we explored the field of dynamics, which taught us how to calculate the position, velocity, and acceleration of an object given a set of driving forces. The topic of control theory flips this process around, and seeks an answer to the question: what type of force will produce the desired motion? In other words, if dynamics is the study of rules, controls is the study of how we use those rules to achieve results.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h3 id=&quot;the-goals-of-control-theory&quot;&gt;The Goals of Control Theory&lt;/h3&gt;

&lt;p&gt;Let’s explore the above statement further. In dynamics, we’re usually given a system of parts, a set of forces \(f(x, t)\), and are asked to calculate \(x(t)\), \(v(t)\), and \(a(t)\). Now we could just as easily reverse this around (given, \(a(t)\), \(v(t)\), \(x(t)\), find \(f(t)\), but this doesn’t seem very interesting, nor is this really what control theory is.&lt;/p&gt;

&lt;p&gt;The key idea that control theory introduces is of a &lt;em&gt;desired&lt;/em&gt; motion or state, which we’ll define with \(x&apos;(t)\), \(v&apos;(t)\), \(a&apos;(t)\) (not be confused with derivatives). Thus, a better problem statement would be: find f(t) that minimizes error between our desired state and actual state.&lt;/p&gt;

\[min | x(t) - x&apos;(t) | + | v(t) - v&apos;(t) | + | a(t) - a&apos;(t) |\]

&lt;p&gt;This is a bit more realistic because “close” is way easier than exactly equal. But as any engineer may point out, we are not only interested in the exact answer - the margins are just as important. Thus control theory seeks to understand how systems responds to inputs. Then, we can take these theories and design controllers to achieve particular goals.&lt;/p&gt;

&lt;p&gt;The design of a controller should strive to achieve the following:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Stable&lt;/li&gt;
  &lt;li&gt;Tracking – keeping y(t) close to command input&lt;/li&gt;
  &lt;li&gt;Regulation – keeping y(t) constant in the presence of disturbances&lt;/li&gt;
  &lt;li&gt;Control Effort – keeping u(t) to a minimum&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;modeling-systems-with-differential-equations&quot;&gt;Modeling Systems with Differential Equations&lt;/h3&gt;

&lt;p&gt;It goes without saying that highly complex systems are difficult to model, but that’s largely because of the number of interactions which exist. Depending on the system, a few common relationships are likely to be present:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;State relationships - The interest you make on your savings is related to how much money you have saved (the state).&lt;/li&gt;
  &lt;li&gt;Rate relationships - Aerodynamic drag increase with speed, making it a rate relationship.&lt;/li&gt;
  &lt;li&gt;Acceleration relationships - Damping mechanisms are acceleration relationships, often used to counteract sudden changes.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;These relationships can be linear, exponential, logarithmic, etc.&lt;/p&gt;

&lt;h3 id=&quot;linear-first-and-second-order-systems&quot;&gt;Linear First and Second Order Systems&lt;/h3&gt;

&lt;h4 id=&quot;first-order&quot;&gt;First order&lt;/h4&gt;

&lt;p&gt;Differential Equation&lt;/p&gt;

\[b\frac{\partial x}{\partial t}+kx=0\]

&lt;p&gt;Transfer Function&lt;/p&gt;

\[H(s)=\ \frac{a}{s+\sigma}\]

&lt;p&gt;Poles&lt;/p&gt;

\[-\sigma\]

\[\sigma=\frac{k}{b}\]

&lt;p&gt;Impulse Response Curve&lt;/p&gt;

\[x\left(t\right)=ae^{-t/\tau}\]

&lt;p&gt;&lt;img src=&quot;../images/firstOrderImpulse.jpg&quot; alt=&quot;first order impulse response&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;dl&gt;
  &lt;dt&gt;Time Constant&lt;/dt&gt;
  &lt;dd&gt;A term defined only for first order systems, after τ seconds, only 37% of initial value remains&lt;/dd&gt;
&lt;/dl&gt;

\[\tau=\ 1/\sigma\]

&lt;p&gt;Step Response Curve&lt;/p&gt;

\[y\left(t\right)=\frac{a}{\sigma}\left(1-e^{-t/\tau}\right)\]

&lt;p&gt;&lt;img src=&quot;../images/firstOrderStep.png&quot; alt=&quot;first order step response&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;second-order-systems&quot;&gt;Second Order Systems&lt;/h4&gt;

&lt;p&gt;Differential Equation&lt;/p&gt;

\[m\frac{\partial^2x}{\partial t^2}+b\frac{\partial x}{\partial t}+kx=0\]

&lt;p&gt;Transfer Function&lt;/p&gt;

\[H(s)=\ \frac{\omega_n^2}{s^2+2\zeta\omega_ns+\omega_n^2}\]

\[H(s)=\ \frac{\sigma^2+\omega^2}{(s+\sigma)^2+\omega^2}\]

&lt;p&gt;Poles&lt;/p&gt;

\[-\sigma\pm j\omega\]

\[\sigma=\ \zeta\omega_n\]

\[\omega=\ \omega_n\sqrt{1-\zeta^2}\]

\[\omega_n=\sqrt{\frac{k}{m}}\]

\[\xi=\frac{b}{2\sqrt{km}}\]

&lt;p&gt;Impulse Response Curve&lt;/p&gt;

\[x\left(t\right)=\ \frac{\omega_n}{\sqrt{1-\zeta^2}}e^{\frac{-\zeta}{\sqrt{1-\zeta^2}}\omega t}\sin{\omega t}\]

&lt;p&gt;&lt;img src=&quot;../images/secondOrderImpulse.png&quot; alt=&quot;second order impulse response&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Step Response Curve&lt;/p&gt;

\[Mp=\ e^\frac{-\zeta\pi}{\sqrt{1-\zeta^2}}\]

\[Rise\ Time\ \tau_r\cong\ \frac{1.8}{\omega_n}\]

\[Settle\ Time\ \tau_s\cong\ \frac{4.6}{\sigma}\]

\[Peak\ Time\ \tau_p=\ \frac{\pi}{\omega}\]

&lt;p&gt;&lt;img src=&quot;../images/secondOrderStep.png&quot; alt=&quot;second order step response&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;laplace-transform&quot;&gt;Laplace Transform:&lt;/h3&gt;
&lt;p&gt;Most important take away is that in the Laplace domain, derivation is represented by multiplication, while integration is represented by division.&lt;/p&gt;

\[\mathcal{L}\left(\dot{x}(t)\right)=sX(s)+x(0_+)\]

\[\mathcal{L}\left[\int_{0}^{t}x\left(t\right)dt\right]=\frac{X(s)}{s}\]

&lt;h3 id=&quot;final-value-theorem--initial-value-theorem&quot;&gt;Final Value Theorem &amp;amp; Initial Value Theorem:&lt;/h3&gt;

&lt;p&gt;Where F(s) is the transfer function of the system defined by f(t).&lt;/p&gt;

\[f\left(\infty\right)=\ \lim_{s\rightarrow0}{sF(s)}\]

\[f\left(0\right)=\ \lim_{s\rightarrow\infty}{sF(s)}\]

&lt;h3 id=&quot;stability&quot;&gt;Stability:&lt;/h3&gt;

&lt;p&gt;A system can be stable, unstable, or marginally stable.&lt;/p&gt;

&lt;p&gt;Stable&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;All poles must be in the LHP&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Marginally Stable&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;There are no poles in the RHP&lt;/li&gt;
  &lt;li&gt;There are poles on the imaginary axis&lt;/li&gt;
  &lt;li&gt;Poles on the imaginary axis are non-repeated&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Unstable&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Any pole in the RHP makes a system unstable&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;Theorem: Given a system represented by a denominator in expanded form, it is not stable if any coefficients of sn are zero or negative.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;undershoot&quot;&gt;Undershoot&lt;/h3&gt;
&lt;p&gt;Typical in non-minimum phase systems (defined as having a zero in the RHP).&lt;/p&gt;

&lt;h3 id=&quot;poles--zeros&quot;&gt;Poles &amp;amp; Zeros&lt;/h3&gt;
&lt;p&gt;A pole is a value of s such that the denominator of the transfer function will be equal to zero. Meanwhile, a zero is defined as a value of s such that the numerator of the transfer function will be equal to zero.&lt;/p&gt;

&lt;h3 id=&quot;routh-stability-criterion&quot;&gt;Routh Stability Criterion&lt;/h3&gt;
&lt;p&gt;Number of sign changes is equal to the number of poles in the RHP.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;IMPORTANT: Unstable pole/zero cancellation is not a valid method for achieving stability&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Feedback Control Systems:&lt;/p&gt;

&lt;p&gt;CL Transfer Function Numerator&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;R&lt;/td&gt;
      &lt;td&gt;W&lt;/td&gt;
      &lt;td&gt;V&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Y&lt;/td&gt;
      &lt;td&gt;GD&lt;/td&gt;
      &lt;td&gt;G&lt;/td&gt;
      &lt;td&gt;-GD&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;E&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;-G&lt;/td&gt;
      &lt;td&gt;GD&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;U&lt;/td&gt;
      &lt;td&gt;D&lt;/td&gt;
      &lt;td&gt;-GD&lt;/td&gt;
      &lt;td&gt;-D&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Where the denominator is the same for all: 1+GD&lt;/p&gt;

&lt;h3 id=&quot;system-type&quot;&gt;System Type&lt;/h3&gt;
&lt;p&gt;A transfer function and the system it represents is said to be type k if a polynomial input of tk results in an output converging to a nonzero constant. In practice,&lt;/p&gt;

\[H\left(s\right)\ is\ type\ K\ \Leftrightarrow\ H\left(s\right)\ has\ K\ zeros\ @\ origin\]

&lt;p&gt;For inputs of magnitude lower than k, output will converge to zero. For inputs of magnitude greater than k, output will diverge.&lt;/p&gt;

&lt;h3 id=&quot;steady-state-error&quot;&gt;Steady State Error:&lt;/h3&gt;
&lt;p&gt;In most cases, steady state error can be found by multiplying the E/R by R to yield E and applying the final value theorem. The below equations are simply shortcuts, that can be used by identifying the system type.&lt;/p&gt;

\[Position\ Constant\ K_p=\ \lim_{s\longrightarrow0}{L(s)}\]

\[Velocity\ Constant\ K_v=\ \lim_{s\longrightarrow0}{sL\left(s\right)}\]

\[Acceleration\ Constant\ K_a=\ \lim_{s\longrightarrow0}{s^2L(s)}\]

&lt;h3 id=&quot;pid-control&quot;&gt;PID Control:&lt;/h3&gt;

&lt;p&gt;Classic and very fundamental method of controller. PID stands for proportional, integral, and derivative. Each serves a different purpose for maintaining stability.&lt;/p&gt;

\[D\left(s\right)=\ K_P+\frac{K_I}{s}+sK_D\]

\[H\left(s\right)=\ \frac{s}{as^3+\left(b+K_D\right)s^2+\left(c+K_P\right)s+K_I}\]

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Increase&lt;/th&gt;
      &lt;th&gt;Effect&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;\(K_P\)&lt;/td&gt;
      &lt;td&gt;Faster Convergence&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;More oscillations for convergence&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;No effect on settling time&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;\(K_D\)&lt;/td&gt;
      &lt;td&gt;Faster convergence&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;Less oscillation&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;\(K_I\)&lt;/td&gt;
      &lt;td&gt;More oscillations&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;No steady state error&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;lead-lag-compensator&quot;&gt;Lead-Lag Compensator&lt;/h3&gt;

&lt;p&gt;Lead compensators improve transient response and is a variety of PD control, while lag compensators improve steady state response, and is a variety of PI control.&lt;/p&gt;

\[Lead\ Compensator:\ D\left(s\right)=K\frac{\left(s-z\right)}{\left(s-p\right)}\ where\ z&amp;lt;p\]

\[Lag\ Compensator:\ D\left(s\right)=K\frac{\left(s-z\right)}{\left(s-p\right)}\ where\ p&amp;lt;z\]

\[\alpha=\ \frac{z}{p}\]

&lt;h3 id=&quot;root-locus&quot;&gt;Root Locus&lt;/h3&gt;
&lt;p&gt;A root locus plot is defined as the plot of the roots of 1+KL(s) on the complex plane as K tends from -∞ to +∞. When drawing a root locus, follow these rules:&lt;/p&gt;

&lt;p&gt;Define: m zeroes and n poles.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The root locus is symmetric about the real axis&lt;/li&gt;
  &lt;li&gt;The root locus starts from n poles of L(s). m branches approach m zeros of L(s). n-m branches go to infinity.&lt;/li&gt;
  &lt;li&gt;The portion of the real axis to the left of an odd number of poles and zeroes is part of the root locus. (Plot the poles/zeroes of L(s) that are on the real axis and label them A, B, C from right to left. Then the segments, AB, CD, … are part of the root locus.)&lt;/li&gt;
  &lt;li&gt;There are n-m branches of the root locus that approach the following asymptotes&lt;/li&gt;
&lt;/ol&gt;

\[s=\ \alpha+\sqrt[n-m]{K}e^{j\theta}\]

\[\alpha=\ \frac{\sum P-\sum Z}{n-m}\]

\[\theta=\ \frac{2l-1}{n-m}\pi\ \ \ \ \ \ l=arbitrary\ integer\]

&lt;ol&gt;
  &lt;li&gt;Departure angles measured from poles, arrival angles measured at zeros. q is the multiplicity of each pole/zero.&lt;/li&gt;
&lt;/ol&gt;

\[q\phi_K=\sum{\angle\left(p_k-z_i\right)-\sum{\angle\left(p_k-p_i\right)+\left(2l-1\right)\pi}}\]

\[q\psi_K=\sum{\angle\left(z_k-p_i\right)-\sum{\angle\left(z_k-z_i\right)+(2l-1)\pi}}\]

&lt;h3 id=&quot;bode-plots&quot;&gt;Bode Plots&lt;/h3&gt;

&lt;p&gt;Bode plots are simply plots of magnitude vs frequency and phase angle vs frequency.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/firstOrderBode.png&quot; alt=&quot;first order Bode plot&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/secondOrderBode.png&quot; alt=&quot;second order Bode plot&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;nyquist-plots&quot;&gt;Nyquist Plots&lt;/h3&gt;
&lt;p&gt;A Nyquist plot is L(jw) on the complex plane as frequency tends from minus infinity to positive infinity. Motivation for using Nyquist plots is that we can determine closed loop stability by examining the open loop (L(jw)). Can be sketched from the bode plots, or by mapping a plot of the range of frequencies.&lt;/p&gt;

\[Z=P-N\]

&lt;p&gt;Where Z is the number of unstable closed loop poles. P is the number of unstable open loop poles, and N is the number of counterclockwise encirclements of -1.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/nyquist.png&quot; alt=&quot;nyquist plot&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;stability-margins&quot;&gt;Stability Margins&lt;/h3&gt;

\[\left|L\left(j\omega_c\right)\right|=1\]

\[\angle L\left(j\omega_p\right)=\ -180\]

\[Gain\ Margin=\ \frac{1}{\left|L\left(j\omega_p\right)\right|}\]

\[Phase\ Margin=\ \angle L\left(j\omega_c\right)+180\cong100\zeta\]

\[\omega_{c\ }\cong\frac{\omega_n}{1+\zeta^2}\]

&lt;p&gt;Where \(\omega_c\) is defined as the gain crossover frequency and \(\omega_p\) is defined to be the phase crossover frequency. On a Nyquist plot, gain crossover frequency is when the graph crosses a circle of radius 1, and phase crossover is when the it crosses the negative real axis. Gain margin is the maximum factor which gain can be increased without making CLS unstable. Phase margin is the maximum angle by which phase can be decreased without making CLS unstable.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Structural Mechanics</title>
   <link href="https://ludavid15.github.io//structuralFundamentals/"/>
   <updated>2021-06-12T00:00:00-07:00</updated>
   <id>https://ludavid15.github.io//fundamentals</id>
   <content type="html">&lt;p&gt;In dynamics, we often make a “rigid body” assumption for all our working parts. All forces merely cause these objects to move or rotate. In reality, forces can cause pieces to deform or even break. Structural mechanics then, is the study of these deformations and failures.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h3 id=&quot;moments&quot;&gt;Moments&lt;/h3&gt;
&lt;p&gt;Description of the various types of “moments” and their relevant applications. Tabulated values for moments of common shapes are not included in this document.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Type&lt;/th&gt;
      &lt;th&gt;Mathematical Expression&lt;/th&gt;
      &lt;th&gt;Use/Meaning&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;1st Moment&lt;/td&gt;
      &lt;td&gt;\(\iint x d A\)&lt;/td&gt;
      &lt;td&gt;Centroid andCenter of Mass&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2nd Moment&lt;/td&gt;
      &lt;td&gt;\(I_y=\iint{x^2dA}\)&lt;/td&gt;
      &lt;td&gt;Second Moment of Inertia/Area or Area Moment of Inertia [m^4], This property is relevant for 2D objects! Beam bending uses this type of moment calculation.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;\(I_x=\iint{y^2dA}\)&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;\(I_{xy}=\iint x y dA\)&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;\(I=\ mr^2\)&lt;/td&gt;
      &lt;td&gt;(For a point mass)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Moment of Inertia [kg-m^2]&lt;/td&gt;
      &lt;td&gt;\(M = Iα\)&lt;/td&gt;
      &lt;td&gt;3D objects have can have moments in Yaw, Pitch and Roll&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Moment or Torque&lt;/td&gt;
      &lt;td&gt;\(T=\ f\ast d\)&lt;/td&gt;
      &lt;td&gt;Moment of Force/Torque [Nm] - Causes angular acceleration/torsion&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt; &lt;/p&gt;
&lt;h3 id=&quot;stress--strain-1d&quot;&gt;Stress &amp;amp; Strain (1D)&lt;/h3&gt;
&lt;p&gt;Where E is young’s modulus. E for Al 6061 is 68.9 GPa. We can also define Poisson’s ratio (v) as the ratio of transverse strain to axial strain. (v) for aluminum and steel is about 0.33, and about 0.5 for rubber.&lt;/p&gt;

\[\sigma=\ \frac{F}{A}\]

\[\varepsilon =\ \frac{\Delta L}{L}\]

\[\varepsilon =\ \frac{\sigma}{E}\]

&lt;h3 id=&quot;shear&quot;&gt;Shear&lt;/h3&gt;
&lt;p&gt;Shear strains (\(\gamma\)) can be induced by shear stresses (\(\tau\)). In the simplest case, they are related by the following equation, where G is the shear modulus, a material property. Shear strains change the shape/angle of the object and is generally defined as the change in angle.&lt;/p&gt;

\[\gamma=\frac{1}{G}\tau\]

&lt;h3 id=&quot;expanded-3d-stress--strain-matrix-for-3d-elements&quot;&gt;Expanded 3D Stress &amp;amp; Strain Matrix for 3D Elements&lt;/h3&gt;

&lt;p&gt;Normal and shear stresses are identified by two subscripts. The first denotes the plane in which the stress acts, and the second denotes the direction. For example, \(\sigma_{xy}\) refers to shear stress acting in the x-plane (i.e. normal to the x direction) and in the y-direction. By force balance, we can also show that \(\sigma_{xy}=\sigma_{yx}\).&lt;/p&gt;

&lt;p&gt;The fully expanded relationship between stress and the strain can be represented by the following matrix. For isotropic and/or orthotropic materials this simplifies significantly. Below, v is Poisson’s ratio, E is Young’s modulus, and G is the shear modulus. The other moduli (n and µ) are not relevant for most materials. When in the following format, the large matrix is known as the &lt;em&gt;compliance matrix&lt;/em&gt;. Its inverse is known as the stiffness matrix.&lt;/p&gt;

\[\left[\begin{matrix}\varepsilon_{xx}\\\varepsilon_{yy}\\\varepsilon_{zz}\\\gamma_{yz}\\\gamma_{xz}\\\gamma_{xy}\\\end{matrix}\right]=\left[\begin{matrix}\frac{1}{E_x}&amp;amp;-\frac{v_{yx}}{E_y}&amp;amp;-\frac{v_{zx}}{E_z}&amp;amp;\frac{n_{yz,x}}{G_{yz}}&amp;amp;\frac{n_{xz,x}}{G_{xz}}&amp;amp;\frac{n_{xy,x}}{G_{xy}}\\-\frac{v_{xy}}{E_x}&amp;amp;\frac{1}{E_y}&amp;amp;-\frac{v_{zy}}{E_z}&amp;amp;\frac{n_{yz,y}}{G_{yz}}&amp;amp;\frac{n_{xz,y}}{G_{xz}}&amp;amp;\frac{n_{xy,y}}{G_{xy}}\\-\frac{v_{xz}}{E_x}&amp;amp;-\frac{v_{yz}}{E_y}&amp;amp;\frac{1}{E_z}&amp;amp;\frac{n_{yz,z}}{G_{yz}}&amp;amp;\frac{n_{xz,z}}{G_{xz}}&amp;amp;\frac{n_{xy,z}}{G_{xy}}\\\frac{n_{x,yz}}{E_x}&amp;amp;\frac{n_{y,yz}}{E_y}&amp;amp;\frac{n_{z,yz}}{E_z}&amp;amp;\frac{1}{G_{yz}}&amp;amp;\frac{\mu_{xz,yz}}{G_{xz}}&amp;amp;\frac{\mu_{xy,yz}}{G_{xy}}\\\frac{n_{x,xz}}{E_x}&amp;amp;\frac{n_{y,xz}}{E_y}&amp;amp;\frac{n_{z,xz}}{E_z}&amp;amp;\frac{\mu_{yz,xz}}{G_{yz}}&amp;amp;\frac{1}{G_{xz}}&amp;amp;\frac{\mu_{xy,xz}}{G_{xy}}\\\frac{n_{x,xy}}{E_x}&amp;amp;\frac{n_{y,xy}}{E_y}&amp;amp;\frac{n_{z,xy}}{E_z}&amp;amp;\frac{\mu_{yz,xy}}{G_{yz}}&amp;amp;\frac{\mu_{xz,xy}}{G_{xz}}&amp;amp;\frac{1}{G_{xy}}\\\end{matrix}\right]\ast\left[\begin{matrix}\sigma_{xx}\\\sigma_{yy}\\\sigma_{zz}\\\tau_{yz}\\\tau_{xz}\\\tau_{xy}\\\end{matrix}\right]\]

&lt;p&gt; &lt;/p&gt;
&lt;h3 id=&quot;isotropic-materials-in-3d&quot;&gt;Isotropic Materials in 3D&lt;/h3&gt;

\[\left[\begin{matrix}\frac{vE}{\left(1+v\right)\left(1-2v\right)}+2G&amp;amp;&amp;amp;\\&amp;amp;\frac{vE}{\left(1+v\right)\left(1-2v\right)}+2G&amp;amp;\\&amp;amp;&amp;amp;\frac{vE}{\left(1+v\right)\left(1-2v\right)}+2G\\\end{matrix}\right]\]

&lt;h3 id=&quot;orthotropic-materials&quot;&gt;Orthotropic Materials&lt;/h3&gt;
&lt;p&gt;An orthotropic material (Properties vary in 3 directions) has three elastic moduli, three shear moduli, and three Poisson’s ratios.&lt;/p&gt;

&lt;h3 id=&quot;axial-stress-in-beams&quot;&gt;Axial Stress in Beams&lt;/h3&gt;
&lt;p&gt;For a symmetric beam, the axial stress is a function of the distance away from the centroid. Mathematically, that is:&lt;/p&gt;

\[\sigma_{yy}=\frac{zM_Z}{I_Z}\]

&lt;p&gt;When the beam is non-symmetric (for example, a section of webs and stringers), moments in the X and Z directions have a coupled effect on the axial stress. The resultant stress is then a function of the location (x, z) relative to the centroid, the applied moments, and the area moment of inertia.&lt;/p&gt;

&lt;p&gt;\(\sigma_{yy}=\left(x-x_c\right)\frac{I_XM_Z+I_{XZ}M_X}{I_XI_Z-I_{XZ}^2}+\left(z-z_c\right)\frac{I_Z M_X+I_{XZ}M_Z}{I_X I_Z-I_{XZ}^2}\)
 &lt;/p&gt;
&lt;h3 id=&quot;shear-in-beams&quot;&gt;Shear in Beams&lt;/h3&gt;

&lt;p&gt;For the beam pictured below, a force applied in the x-direction causes axial compression in the top of the I-beam (\sigma_{xx}) and tension in the bottom. By force balance, this also causes a shear force, \sigma_{xy} in the cross section of the beam. It is important to remember that changes in the axial stress cause changes in the shear stress.&lt;/p&gt;

&lt;p&gt;This shear stress at a location y along the cross section of the beam can be calculated with the equation below. Where c is the y location of the centroid of the beam. Note that we assume the applied shear force does not twist the section. This is true only if the force is applied through the shear center.&lt;/p&gt;

\[\sigma_{xy}=\frac{V_y}{I_zt}\int_{y1}^{c}ydA\]

&lt;p&gt;The above equation is useful for beams with thick walled sectioned. When the beam consists instead of stringers and thin webbed members, we can simplify the problem and avoid using integrals.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Solving problems with shear flows allow us to do away with stresses for a while and work directly with the forces, which makes our life a bit easier&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;shear-flow&quot;&gt;Shear Flow&lt;/h3&gt;

&lt;p&gt;Consider now if the cross section of the beam consists of stringers and thin webbed members. The stringers are going to carry all the axial stresses, while the webs take care of shear stresses. Since the webs are thin, the shear stress will be constant along these webs. 
This leads to an idea called “shear flow”. Note that this concept is not defined for thick walled sections. We define shear flow in terms of the shear stress in a web, and the thickness. It is in units of force per length. At each stringer, there is a change in shear flow equal to the bending moment carried by that stringer.&lt;/p&gt;

\[q=\tau_{xy}\ast thickness\]

\[F_y=\int_{0}^{y}qdy\]

\[F_x=\int_{0}^{x}qdx\]

&lt;p&gt;Integrating the shear flow (Force/Length) along the web yields the total shear force.&lt;/p&gt;

&lt;h3 id=&quot;shear-center&quot;&gt;Shear Center&lt;/h3&gt;
&lt;p&gt;The shear center is defined as the point where if a shear force is applied, no additional torsion is created. For symmetric sections, the shear center coincides with the centroid. For non-symmetric &amp;amp; open sections, the shear center can be found as follows:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Find the shear flows in each beam. Since the section is open, you have the boundary conditions needed to find them directly.&lt;/li&gt;
  &lt;li&gt;Select an arbitrary point in your section, and the find the torque around that point due to the shear flows. A is the area swept out by the web.&lt;/li&gt;
&lt;/ol&gt;

\[T=2Aq\]

&lt;ol&gt;
  &lt;li&gt;The shear center is the point where if the shear force is applied, it will cancel out the torque due to the shear flow around the point you’ve selected.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;process-to-solving-simple-1-box-problem-closed-section&quot;&gt;Process to Solving Simple 1 Box Problem (Closed Section)&lt;/h3&gt;
&lt;p&gt;When the section is closed, you do not have the boundary conditions necessary to immediately solve for the shear flows. Instead you’ll impose a torque balance condition at the end and then solve a system of equations.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Find the moment of inertia of the cross section.&lt;/li&gt;
  &lt;li&gt;Assume that the shear force is applied at the shear center. Find the bending moment (force/length) carried by each stringer with the following equation.&lt;/li&gt;
&lt;/ol&gt;

\[∆P= V_yI_zA\]

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;At each stringer, the change in shear flow (force/length) is equal to the bending moment carried by that stringer. Use this to relate all the shear flow variables.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Since we’ve assumed the shear force is initially applied at the shear center, we can find the location of the shear center by imposing that the torque due to the shear flows must be equal to the restoring torque caused by the shear force at the shear center.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

\[T=\sum2Aq=V_x\ast e\]

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Now find the additional shear flow caused by the shear force being applied away from the shear center. Assuming all walls are of the same thickness, the shear flow will be constant in every wall in this pure torsion case.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Add the two resultant shear flows together to get the total.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;shear-flow-in-multiple-cells&quot;&gt;Shear Flow in Multiple Cells&lt;/h3&gt;
&lt;p&gt;When multiple cells are adjacent to one another, you must apply a compatibility constraint, which states that the twist in both cells are equal.&lt;/p&gt;

\[\theta_1=\frac{q_1}{A_1}∆S_i t_i\]

&lt;p&gt;Where \(q_1\) is the shear flow due to pure torsion in the cell, \(A_1\) is the area of the cell, \(S_i\) is the length of the wall, and \(t_i\) is the thickness of the wall. When you have two cells that are adjacent, you must account for the shear flow in the shared wall due to the other cell. Setting the two twist equations equal and then writing the torque equation below provides you with two equations to solve for the two unknowns.&lt;/p&gt;

\[\theta_2=\theta_1=\frac{q_1}{A_1}∆S_it_i-q2A_1∆S_{shared}t_{shared}\]

&lt;p&gt;\(T=2 A_1 q_1+2 A_2 q_2\)
 &lt;/p&gt;
&lt;h3 id=&quot;principle-stress&quot;&gt;Principle Stress&lt;/h3&gt;

&lt;p&gt;The magnitude of axial stress and shear stress will change depending on the coordinate frame used, though the total “energy” remains constant. Thus in some frame, the shear stress will go to zero, and the axial stress will be maximized. These maximum axial stresses are also known as principle stresses.&lt;/p&gt;

&lt;p&gt;Mathematically, the principle stresses are the eigenvalues of the stress tensor, and the direction in which they act are the principle directions (the eigenvectors).&lt;/p&gt;

\[\left[\begin{matrix}\sigma_{xx}&amp;amp;\tau_{xy}&amp;amp;\tau_{xy}\\\tau_{xy}&amp;amp;\sigma_{yy}&amp;amp;\tau_{yz}\\\tau_{xz}&amp;amp;\tau_{yz}&amp;amp;\sigma_{zz}\\\end{matrix}\right]=0\]

&lt;h3 id=&quot;von-mises-stress-criteria&quot;&gt;Von Mises Stress Criteria&lt;/h3&gt;

&lt;p&gt;Coming soon?&lt;/p&gt;

&lt;h3 id=&quot;pressure-vessels&quot;&gt;Pressure Vessels&lt;/h3&gt;
&lt;p&gt;For a cylindrical pressure vessel of radius \(r\) and a (thin) wall of thickness \(t\), we can define the hoop stress and axial stress using the equations below:&lt;/p&gt;

\[\sigma_{Hoop}=\frac{Pr}{t}\]

\[\sigma_{Axial}=\frac{Pr}{2t}\]

&lt;h3 id=&quot;fastener-shear-failure-methods&quot;&gt;Fastener Shear Failure Methods&lt;/h3&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Tearout&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Bypass&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Fastener Shear&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Bearing&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

</content>
 </entry>
 
 <entry>
   <title>Finite Element Methods</title>
   <link href="https://ludavid15.github.io//fem/"/>
   <updated>2021-06-10T00:00:00-07:00</updated>
   <id>https://ludavid15.github.io//fem</id>
   <content type="html">&lt;p&gt;Finite element methods, or FEM, is a strategy for modeling complex shapes as a series of small blocks. The math of FEM is foundational for modern computational structural analysis.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h3 id=&quot;spring-model-of-elements&quot;&gt;Spring Model of Elements&lt;/h3&gt;

&lt;p&gt;All elements are modeled as a spring, that is, exterior force is equal to the stiffness matrix times the displacement at the ends of the spring.&lt;/p&gt;

\[F=Ku\]

&lt;h3 id=&quot;shape-functions&quot;&gt;Shape Functions&lt;/h3&gt;

&lt;p&gt;Shape functions transform the displacements at nodes to the displacement at a point in space. In the equation below, the shape functions are a function of position.&lt;/p&gt;

\[\left[\begin{matrix}\begin{matrix}u\\v\\w\\\end{matrix}\\\end{matrix}\right]=\left[\begin{matrix}\begin{matrix}N_1&amp;amp;0&amp;amp;0\\0&amp;amp;N_2&amp;amp;0\\0&amp;amp;0&amp;amp;N_3\\\end{matrix}&amp;amp;\begin{matrix}\ldots&amp;amp;N_1&amp;amp;0&amp;amp;0\\\ldots&amp;amp;0&amp;amp;N_2&amp;amp;0\\\ldots&amp;amp;0&amp;amp;0&amp;amp;N_3\\\end{matrix}\\\end{matrix}\right]\left[\begin{matrix}u_1\\v_1\\w_1\\\ldots\\u_n\\v_n\\w_n\\\end{matrix}\right]\]

&lt;h3 id=&quot;b-matrix&quot;&gt;B Matrix&lt;/h3&gt;
&lt;p&gt;The “B” Matrix relates the strains to the displacements at the nodes. This depends primarily on the strain equations of the specific case, and so there is not a universal B matrix.&lt;/p&gt;

&lt;h3 id=&quot;stress&quot;&gt;Stress&lt;/h3&gt;

&lt;p&gt;The stress can be found once the nodal displacements, B matrix, and D matrix are known.&lt;/p&gt;

\[\sigma=DBq\]

&lt;p&gt;\(\sigma=D\epsilon\)
 &lt;/p&gt;
&lt;h3 id=&quot;shape-functions-1&quot;&gt;Shape Functions&lt;/h3&gt;
&lt;p&gt;Shape functions transform values at the nodes into values in space. The shape function corresponding to a node should be equal to one if given the coordinate of that node. The sum of all node functions should be also equal to one. From the previous two requirements, we can also understand that at a node, one shape function will evaluate to one, and all others will be zero.&lt;/p&gt;

&lt;h4 id=&quot;1d&quot;&gt;1D&lt;/h4&gt;

&lt;p&gt;2 Node Shape Function&lt;/p&gt;

\[N_1=\frac{x_2-x}{x_2-x_1}\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ N_2=\frac{x-x_1}{x_2-x_1}\]

&lt;p&gt;3 Node Shape Functions&lt;/p&gt;

\[N_1=\frac{(x-x_2)(x-x_3)}{(x_1-x_2)(x_1-x_3)}\]

\[N_1=\frac{(x-x_1)(x-x_3)}{(x_2-x_1)(x_2-x_3)}\]

\[N_1=\frac{(x-x_1)(x-x_2)}{(x_3-x_1)(x_3-x_2)}\]

&lt;h4 id=&quot;2d&quot;&gt;2D&lt;/h4&gt;

&lt;p&gt;3 Node (Standard Triangle Elements)&lt;/p&gt;

\[N_1=\xi\ \ \ \ \ \ N_2=\eta\ \ \ {\ \ \ \ N}_3=1-\xi-\eta\]

&lt;p&gt;4 Node (Standard Quad Elements)&lt;/p&gt;

\[N_i=\frac{1}{4}\left(1+{\xi\xi}_i\right)\left(1+\eta\eta_i\right)\]

&lt;p&gt;8 Node (Standard Higher Order Quad Elements)&lt;/p&gt;

\[N_{i,corners}=\frac{1}{8}\xi\eta(\xi+\xi_i)(\eta+\eta_i)\]

\[N_{i,\xi=0}=\frac{1}{8}\eta(1-\xi^2)(\eta+\eta_i)\]

\[N_{i,\eta=0}=\frac{1}{8}\xi(1-\eta^2)(\xi+\xi_i)\]

&lt;h4 id=&quot;3d&quot;&gt;3D&lt;/h4&gt;

&lt;p&gt;4 Node (Standard Tetrahedral Element)&lt;/p&gt;

\[N_1=\xi\ \ \ \ \ \ {\ \ \ \ \ \ \ N}_2=\eta\ \ \ {\ \ \ \ \ \ \ \ N}_3=\chi\ \ \ \ \ \ \ N_4=1-\xi-\eta-\chi\]

&lt;p&gt;8 Node (Standard Brick Element)&lt;/p&gt;

\[N_i=\left(\frac{1}{4}\right)\left(1+{\xi\xi}_i\right)\left(1+\eta\eta_i\right)\left(1+{\chi\chi}_i\right)\]

&lt;h3 id=&quot;numerical-integration&quot;&gt;Numerical Integration&lt;/h3&gt;

&lt;p&gt;A definite integral from negative one to one can be approximated numerically by evaluating the function at different points between the range and multiplying by a “weight”. This is represented as:&lt;/p&gt;

\[I=\ \int_{-1}^{1}f\left(x\right)dx=w_1f\left(x_1\right)+w_2f\left(x_2\right)+\ldots\]

&lt;p&gt;Depending on the order of the polynomial that is the function f(x) numerical integration can yield exact results. The number of integration points this requires is related to the order of the polynomial by the following expression:&lt;/p&gt;

\[n=\ \frac{P+1}{2}\]

&lt;p&gt;Note that the bounds must range from negative one to positive one. It is possible to do this numerical approximation for higher dimensional problems. New integration points are the permutation of integration point values for the 1-dimensional case.&lt;/p&gt;

&lt;h3 id=&quot;stiffness-matrix&quot;&gt;Stiffness Matrix&lt;/h3&gt;

&lt;p&gt;The following matrix can be found using potential energy minimization or calculated directly through analytical means.&lt;/p&gt;

\[K=\ \int{B^TDBdV}\]

&lt;h3 id=&quot;force-vector&quot;&gt;Force Vector&lt;/h3&gt;
&lt;p&gt;There can be multiple things that add terms to the force vector. The final force vector used in the spring expression will be the sum of the following:&lt;/p&gt;

\[f_{body}=\ \int{N^TbdV}\]

\[f_{traction}=\ \int{N^TTdA}\]

\[f_{thermal}=\int{B^TD}\epsilon_{thermal}dV\]

&lt;p&gt;Where ɛthermal is the thermal strain and is typically equal to αΔT.&lt;/p&gt;

&lt;h3 id=&quot;mass-matrix&quot;&gt;Mass Matrix&lt;/h3&gt;

&lt;p&gt;The sum of all elements in a mass matrix should be equal to the mass of the element you are modeling.&lt;/p&gt;

\[M=\ \rho\int{N^TNdV}\]

&lt;h3 id=&quot;natural-frequency&quot;&gt;Natural Frequency&lt;/h3&gt;

&lt;p&gt;Eigenvalues of the Mass Matrix and Stiffness matrix when the forcing term is set to zero.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Optimization Fundamentals</title>
   <link href="https://ludavid15.github.io//optimization/"/>
   <updated>2021-06-10T00:00:00-07:00</updated>
   <id>https://ludavid15.github.io//optimization</id>
   <content type="html">&lt;p&gt;The underlying principle of an optimization is pretty straightfoward - find the best way to do something. Best can mean fastest, safest, most efficient, shortest or thousands of other things, but the common denominator is that we are looking for the most (or least) of something. Mathematically then, this is pretty simple: we’re solving for a maximum.&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;Finding this maximum or minumum is pretty straightforward. However, optimization attempts often fail not because we couldn’t find the correct min/max, but because our question was posed poorly in the first place.&lt;/p&gt;

&lt;p&gt;For example, if you wanted to get from point A to point B, the fastest way to do this is probably not the cheapest way. In fact, these things likely trade off with one another. When you frame this mathematically, how do you weigh each objective? Lacking a common unit or denomination, it’s like comparing apples to oranges.&lt;/p&gt;

&lt;h3 id=&quot;mathematics&quot;&gt;Mathematics&lt;/h3&gt;

&lt;p&gt;An optimization problem is generally stated as follows:&lt;/p&gt;

\[f\left(x\right)\rightarrow min,\ \ \ \ x\in R^n\]

&lt;p&gt;Subject to equality constraints and inequality constraints&lt;/p&gt;

\[g\left(x\right)=0\]

\[h\left(x\right)\le0\]

&lt;h3 id=&quot;np-completeness&quot;&gt;NP Completeness&lt;/h3&gt;
&lt;p&gt;The NP completeness of a problem is a measure of its computational complexity.&lt;/p&gt;

&lt;h3 id=&quot;the-lagrangian&quot;&gt;The Lagrangian&lt;/h3&gt;
&lt;p&gt;A useful equation in constrained optimization problems. The unconstrained minimizer of the Lagrangian is equal to the constrained minimizer.&lt;/p&gt;

\[\mathcal{L}=q_0f\left(x\right)+p^Tg\left(x\right)+q^Th(x)\]

&lt;p&gt;Lagrange multipliers have a price interpretation, that is, the Lagrange multiplier leading an inequality function is the sensitivity of the final objective cost to slackness in that inequality.&lt;/p&gt;

\[h\left(x\right)+b \le 0\]

\[q=\frac{\partial f^\ast}{\partial b}\]

&lt;h3 id=&quot;derivatives-of-multivariable-functions&quot;&gt;Derivatives of Multivariable Functions&lt;/h3&gt;
&lt;p&gt;Rather than having a singular gradient/slope/derivative, a multivariable function will have a gradient with respect to each variable. This together is represented as a vector of values.&lt;/p&gt;

&lt;p&gt;If we are on a slopped region (in whatever dimension), lines of constant height will always be perpindicular to the local gradient at that point. Thus if we are running something like a steepest descent line search, the direction of steepest descent will be given by the negative of the gradient vector.&lt;/p&gt;

&lt;h3 id=&quot;the-hamiltonian&quot;&gt;The Hamiltonian&lt;/h3&gt;
&lt;p&gt;If the Hamiltonian does not explicitly depend on time, then the Hamiltonian remains constant along the optimal trajectory. Furthermore, if the terminal conditions and cost also do not depend on time, then the Hamiltonian is equal to zero for all time along the trajectory. The vector p contains what are known as adjoint variables.&lt;/p&gt;

\[H=\ p_0L(t,x,u)+p^Tf(t,x,u)\]

&lt;h3 id=&quot;fritz-john-necessary-conditions&quot;&gt;Fritz-John Necessary Conditions&lt;/h3&gt;
&lt;p&gt;The following necessary conditions must hold at any local or global minimizer. The first condition is known as stationarity, the second is dual feasibility, and the third is complementary slackness.&lt;/p&gt;

\[\nabla_xL\left(x^\ast,\ p,\ q_0,\ q\right)=0\]

\[q\geq0\]

\[q^Th\left(x^\ast\right)=0\]

&lt;p&gt;In addition to the above, all constraints must be met, the Lagrange multipliers cannot all be zero, and qo is either 0 or 1. In the case where all constraints are linearly independent, we can know that qo takes the value of one. This unique scenario leads to the KKT conditions.&lt;/p&gt;

&lt;h3 id=&quot;karush-khan-tucker-kkt-necessary-conditions&quot;&gt;Karush Khan Tucker (KKT) Necessary Conditions&lt;/h3&gt;
&lt;p&gt;Identical to the FJ necessary conditions, with the exception that \(q_o\) is taken to be equal to 1. This is most often the case. Note that for KKT to apply, the constraints must be linearly independent of one another (LICQ – Linear Independence of Constraints Qualification). The conditions become:&lt;/p&gt;

\[\nabla f\left(x\right)+\sum_{i=1}^{m}{p_i\nabla g_i\left(x\right)}+\sum_{i=1}^{l}{q_i\nabla h_i\left(x\right)}=0\]

\[q\geq0\]

\[q^Th\left(x^\ast\right)=0\]

&lt;p&gt;From a conceptual standpoint, the set of constraints define a feasible region of the design space. If the minimizer exists on one of these boundaries, then the inequality constraint must be equal to zero. Thus, complementary slackness is met. Consider however, there may be other inequality constraints which are not limiting the minimizer. These constraints are not “active” at the minimum, and their Lagrange multipliers must have the value of 0 to satisfy complementary slackness. The set of all nonzero Lagrange multipliers is known as the “active” set. In other words, this is a list of all the inequality constraints which are equal to zero at the minimizer.&lt;/p&gt;

&lt;h3 id=&quot;hessian&quot;&gt;Hessian&lt;/h3&gt;

&lt;p&gt;The hessian of a function is the second order derivative. It takes the form of an n x n matrix for a problem with n design variables. Typically abbreviated as just Hf.&lt;/p&gt;

\[\nabla^2f=\left[\begin{matrix}\frac{\partial^2f}{\partial x_{11}^2}&amp;amp;\cdots&amp;amp;\frac{\partial^2f}{\partial x_{1n}^2}\\\vdots&amp;amp;\ddots&amp;amp;\vdots\\\frac{\partial^2f}{\partial x_{n1}^2}&amp;amp;\cdots&amp;amp;\frac{\partial^2f}{\partial x_{nn}^2}\\\end{matrix}\right]\]

&lt;h2 id=&quot;finite-dimension-optimization-algorithms&quot;&gt;Finite Dimension Optimization Algorithms&lt;/h2&gt;
&lt;h3 id=&quot;line-search&quot;&gt;Line Search&lt;/h3&gt;

&lt;p&gt;Line search algorithms look for the minimum function value for a given search direction. Once a minimum is found, a new search direction is selected, and the line search is repeated. The first direction is typically the steepest descent direction, or the negative of the gradient.&lt;/p&gt;

\[-\nabla f=steepest\ descent\]

&lt;p&gt;It is not always required to find the exact minimum in the search direction. In fact, doing so is often more computationally expensive than it is worth. Instead of requiring the Strong Wolfe conditions, another option is to use sufficient decrease, where if the objective function is found to have decreased enough, it is accepted as the new position.&lt;/p&gt;

&lt;h3 id=&quot;armijo-rule&quot;&gt;Armijo Rule&lt;/h3&gt;
&lt;p&gt;Conditions for accepting a new point in a line search.&lt;/p&gt;

\[f\left(x+ap\right)\le f\left(x\right)+c_1ap^T\nabla f(x)\]

&lt;p&gt;Where a is the step length, p is the search direction, and c_1 is some scaling term that is less than 1. c_1 is usually selected to be very small.&lt;/p&gt;

&lt;h3 id=&quot;strong-wolfe-condition&quot;&gt;Strong Wolfe Condition&lt;/h3&gt;
&lt;p&gt;In addition to Armijo rule, the strong Wolfe conditions add another requirement on the local curvature. c_2 is usually selected to be much larger than c_1, but still less than 1.&lt;/p&gt;

\[\left|p^T\nabla f(x+ap)\right|\le\ c_2\left|p^T\nabla f(x)\right|\]

&lt;h3 id=&quot;conjugate-gradient&quot;&gt;Conjugate Gradient&lt;/h3&gt;
&lt;p&gt;Conjugate gradient improves line search convergence by providing a better alternative for the search direction than steepest descent. It retains information about the previous descent direction in the direction update for the next search.&lt;/p&gt;

\[p_k=-\nabla f_k+\beta_kp_{k-1}\]

\[\beta_k=\frac{\nabla f_k^T\nabla f_k}{\nabla f_{k-1}^T\nabla f_k}\]

&lt;p&gt;Where p is the search direction. Conjugate gradient avoids the zig-zagging behavior that can occur when using steepest descent.&lt;/p&gt;

&lt;h3 id=&quot;newtons-method&quot;&gt;Newton’s Method&lt;/h3&gt;

&lt;p&gt;Newton’s method makes a local quadratic approximation of the function and goes to the minimum. Requires second order differentiable functions in order to work but has the fastest convergence. The step (i.e. the next point is calculated as x + s) in every iteration is calculated as:&lt;/p&gt;

\[s_k=-H_k^{-1}\nabla f_k\]

&lt;p&gt;Where H is the hessian of the function calculated at that location. For a quadratic function, a minimum is found in a single step. However, because an exact hessian may not be available, the Hessian is typically approximated using the local gradients. This is known as a “Quasi-Newton Method”. BFGS is one such method for approximating the local hessian. It is also possible that the hessian is not positive definite, in which case the search direction is not a descent direction, and it is possible to end at a maximum or saddle point. As with SQP, a line search is frequently performed on top of the search direction once it has been calculated to ensure we are not blindly accepting the update.&lt;/p&gt;

&lt;h3 id=&quot;trust-regions&quot;&gt;Trust Regions&lt;/h3&gt;
&lt;p&gt;This is an alternative to the line search method and helps account for non-positive definite hessian matrices. Effectively, the trust region sets a maximum range on how far a Newton step can take the minimizer point. Then, using this fixed step distance, the search direction is picked which minimizes the function (in contrast to a line search, which fixes the search direction and searches for the step distance).&lt;/p&gt;

&lt;h3 id=&quot;penalty-methods&quot;&gt;Penalty Methods&lt;/h3&gt;
&lt;p&gt;Penalty methods provide a way to use unconstrained optimization techniques for constrained optimization problems. While straightforward, penalty methods have poor numerical performance and are generally not used anymore. Sequential quadratic programming is a better way to solve constrained optimization problems.&lt;/p&gt;

&lt;h3 id=&quot;sequential-quadratic-programming&quot;&gt;Sequential Quadratic Programming&lt;/h3&gt;
&lt;p&gt;SQP is the current state of the art method for solving constrained continuously differentiable optimization problems. The general problem that it solves is:&lt;/p&gt;

&lt;p&gt;Minimize:&lt;/p&gt;

\[\mathcal{L}=f\left(x,u,t\right)+\lambda h\left(x,u,t\right)+\mu g(x,u,t)\]

&lt;p&gt;Subject to:&lt;/p&gt;

\[h\left(x,u,t\right)=0\]

\[g\left(x,u,t\right)\le0\]

&lt;p&gt;It is effectively a Newton’s method application to solving the unconstrained Lagrangian equation and can be derived by application of KKT to any generic problem. It makes local quadratic approximations of the design variables and Lagrange multipliers, then repeats. At every step, the system to be solved:&lt;/p&gt;

\[\left[\begin{matrix}\nabla_{xx}^2\mathcal{L}&amp;amp;\left[\nabla h\right]^T\\\nabla h&amp;amp;0\\\end{matrix}\right]\bullet\delta X=\left[\begin{matrix}-\nabla_x\mathcal{L}\\-h\\\end{matrix}\right]\]

&lt;p&gt;Where \(\delta X\) is a stack up of all the design variables and the Lagrange multipliers, and represents the update (i.e. it should be added to the previous set of X values). It is possible and sometimes necessary to perform a line search in this direction to enable better convergence.&lt;/p&gt;

&lt;h3 id=&quot;gradient-calculation&quot;&gt;Gradient Calculation&lt;/h3&gt;

&lt;p&gt;The method of gradient calculation can have a large impact the accuracy, and hence convergence speed and robustness of the solver. Finite difference is the most straightforward and makes a local linear approximation. Accuracy increases with decreasing step size, up through numerical precision limits, typically on the order of 10e-6. FD also requires at least two function evaluations per term in the gradient.&lt;/p&gt;

\[df\cong\frac{f\left(x+h\right)-f(x)}{h}\]

&lt;p&gt;Complex step eliminates the subtraction step and provides a better approach with more accuracy, but still requires one function evaluations per term in the gradient.&lt;/p&gt;

\[df\cong Im[fx+ih]h\]

&lt;p&gt;Algorithmic differentiation, or sometimes known as automatic differentiation is similar to taking an analytical gradient but is performed line by line on the code of the objective function. AD derivates are exact and require zero function evaluations but are limited in regard to where they can be applied. Developers intending to use AD later on should understand ahead of time the types of code that cannot be passed through an AD tool and write their objective function accordingly. For python, the module Autograd provides an easy and useful tool for applying AD to obtain the first order gradient or second order Hessian.&lt;/p&gt;

&lt;h3 id=&quot;gradient-free-methods&quot;&gt;Gradient Free Methods&lt;/h3&gt;
&lt;p&gt;These methods avoid the calculation of a gradient. For this reason, they are more robust to non-continuous objective functions and constraints. Unfortunately, this also means that gradient free methods scale very poorly for problems of very many variables. There are a multitude of different gradient free algorithms, but two of the most popular are the genetic algorithm and Nelder-mead methods.&lt;/p&gt;

&lt;p&gt;Nelder-mead is a simplex method, where a simplex is defined as an N dimensional polyhedron formed form triangles. In 2D, it is a triangle, in 3D it is a tetrahedron, etc.&lt;/p&gt;

&lt;h3 id=&quot;metaheuristics&quot;&gt;Metaheuristics&lt;/h3&gt;
&lt;p&gt;Refers generally to a class of optimization methods that are designed to perform “well enough”. These typically can provide good solutions, but in a limited capacity and does not guarantee a perfect solution.&lt;/p&gt;

&lt;p&gt;These strategies make relatively few assumptions about the problem nature and aim to be generally applicable. A common metaheuristic strategy is to implement a form of stochastic optimization. Some examples of metaheuristic optimization include:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Ant colony optimization&lt;/li&gt;
  &lt;li&gt;Genetic and evolutionary algorithms&lt;/li&gt;
  &lt;li&gt;Iterated local searches&lt;/li&gt;
  &lt;li&gt;Simulated annealing&lt;/li&gt;
  &lt;li&gt;Tabu search&lt;/li&gt;
&lt;/ol&gt;

</content>
 </entry>
 
 <entry>
   <title>Twelve Tone Equal Temperatment</title>
   <link href="https://ludavid15.github.io//twelveTone/"/>
   <updated>2021-06-05T00:00:00-07:00</updated>
   <id>https://ludavid15.github.io//twelveTone</id>
   <content type="html">&lt;p&gt;If you’ve taken any kind of music lesson before, chances are you were introduced to the western classical system of notation, otherwise known as twelve-tone equal temperament. In this system, each octave is subdivided into 12 notes, labeled A through G.&lt;/p&gt;

&lt;p&gt;So much of music theory is based on this system that it’s easy to forget what it is - a constructed language that approximates something physical.&lt;/p&gt;

&lt;p&gt;That physical thing in question being acoustic waves traveling through the air. These waves (like all waves) carry a frequency, amplitude, and waveform. What we call pitch is the first of these - the frequency.&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;To build a bridge between music theory and physics, let us begin with intervals. If we define the note &lt;strong&gt;A&lt;/strong&gt; at 1 hz and then double the frequency to 2 hz, the resulting note is defined in our musical langauge as being 1 octave higher.&lt;/p&gt;

&lt;p class=&quot;message&quot;&gt;
In western music, two notes that are an octave apart are considered the same &quot;note&quot;. For this reason, they recieve the same label, although a number is sometimes used to indicate how high the note is. However, not all musical languages may recognize the concept of an octave, and after all, why should they? Even though we say two notes an octave apart are the same, they clearly are not - one is much higher in pitch than the other. Be careful to remember that the language we have shapes our perspective of the world. 
&lt;/p&gt;

&lt;p&gt;We could continue to double each frequency (1, 2, 4, …) and find a series of notes spaced 1 octave apart, but this musical scale is pretty limiting. So how do we define other intervals? Well, let’s take other ratios along the set of positive integers.&lt;/p&gt;

\[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, ...\]

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;2/1&lt;/td&gt;
      &lt;td&gt;3/2&lt;/td&gt;
      &lt;td&gt;4/3&lt;/td&gt;
      &lt;td&gt;5/4&lt;/td&gt;
      &lt;td&gt;6/5&lt;/td&gt;
      &lt;td&gt;7/6&lt;/td&gt;
      &lt;td&gt;8/7&lt;/td&gt;
      &lt;td&gt;9/8&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;octave&lt;/td&gt;
      &lt;td&gt;fifth&lt;/td&gt;
      &lt;td&gt;fourth&lt;/td&gt;
      &lt;td&gt;major third&lt;/td&gt;
      &lt;td&gt;minor third&lt;/td&gt;
      &lt;td&gt;??&lt;/td&gt;
      &lt;td&gt;??&lt;/td&gt;
      &lt;td&gt;whole step&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Notice that each subsequent ratio gets closer and closer to 1. In this way we achieve smaller and smaller intervals. There’s also nothing wrong with 7/6 or 8/7, those particular intervals just aren’t defined in our musical theory language.&lt;/p&gt;

&lt;p&gt;But are these intervals any good? Like many things, the answer is: it depends. They certainly &lt;em&gt;sound&lt;/em&gt; nice, but these all lack an important feature: they don’t return to the same point.&lt;/p&gt;

&lt;p&gt;Let’s take a whole step: 9/8. If we start on a note and travel up 7 whole steps, we get to:&lt;/p&gt;

\[(9/8)^6 = 2.0272\]

&lt;p&gt;Which is NOT an octave. Almost, but not quite. Whole steps are also unable to build any to any of the other intervals.&lt;/p&gt;

\[(9/8)^3 = 1.42\]

&lt;p&gt;Which is neither equal to 3/2 or 4/3. In fact, this basic problem extends for any interval defined with the ratio of positive integers. This is where 12-tone equal temperament comes in. The frequency ratio for a half step is set to be the twelfth root of two.&lt;/p&gt;

\[^{12} \sqrt{2}\]

&lt;p&gt;This way, any pair of notes 12 half steps apart form a perfect octave. This allows us to freely move about the piano and play in any key, at the cost of perfect intervals ratios. The approximations of each perfect ratio in this system become:&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Exact ratio&lt;/td&gt;
      &lt;td&gt;2/1&lt;/td&gt;
      &lt;td&gt;3/2&lt;/td&gt;
      &lt;td&gt;4/3&lt;/td&gt;
      &lt;td&gt;5/4&lt;/td&gt;
      &lt;td&gt;6/5&lt;/td&gt;
      &lt;td&gt;9/8&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;As decimal&lt;/td&gt;
      &lt;td&gt;2.0&lt;/td&gt;
      &lt;td&gt;1.5&lt;/td&gt;
      &lt;td&gt;1.333&lt;/td&gt;
      &lt;td&gt;1.25&lt;/td&gt;
      &lt;td&gt;1.2&lt;/td&gt;
      &lt;td&gt;1.125&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;12-tone approx.&lt;/td&gt;
      &lt;td&gt;2.0&lt;/td&gt;
      &lt;td&gt;1.498&lt;/td&gt;
      &lt;td&gt;1.335&lt;/td&gt;
      &lt;td&gt;1.26&lt;/td&gt;
      &lt;td&gt;1.19&lt;/td&gt;
      &lt;td&gt;1.123&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;As you can see, except for an octave which remains perfect, each 12-tone interval is very slightly off from the corresponding “just intonation” interval. In most cases, the variation is small enough that it very nearly sounds the same.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Fundamentals of Propulsion</title>
   <link href="https://ludavid15.github.io//fundamentalsProp/"/>
   <updated>2021-05-18T00:00:00-07:00</updated>
   <id>https://ludavid15.github.io//fundamentalsPropulsion</id>
   <content type="html">&lt;p&gt;When it comes to propulsion, it can be difficult to keep track of all the different classifications floating around out there. Props, turboprops, turbojets, ramjets, chemical rockets, nuclear rockets, Hall thrusters, and ion thrusters, just to name a few. If anything, it’s a testament to our joint creativity that we’ve come up with so many ways to &lt;em&gt;move&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;To help clear up some confusion, this section presents a roadmap - a heirarchy of propulsion systems to help you navigate this broad topic.&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;To begin, all propulsion systems must achieve the same goal: generate forward momentum. And the only way to do this (that we know of … ) is to make use of Newton’s third law.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;For every action, there is an equal and opposite reaction.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;So that’s it. We have to push something back (or push against something), and the action of doing so pushes us forward. Naturally the next question becomes, well how do we push mass back? The three answers we have achieved are:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Mechanically, by interacting with the environment.&lt;/li&gt;
  &lt;li&gt;Converting a fluid’s internal energy into kinetic energy with a nozzle.&lt;/li&gt;
  &lt;li&gt;If we have access to mass that is charged/magnetized, we can accelerate it with an electromagnetic field.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Other ideas that we have come up with, but cannot achieve yet:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Artificial gravity&lt;/li&gt;
  &lt;li&gt;Wormholes (i.e. spacetime warping)&lt;/li&gt;
  &lt;li&gt;Teleporters (technically &lt;em&gt;not&lt;/em&gt; a form of propulsion, since we’re not moving mass from one location to another, but rather assembling a copy somewhere else)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Although not explicitly stated, all relevant propulsion systems work with &lt;strong&gt;fluids&lt;/strong&gt;.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;What is a good measure for efficiency?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p class=&quot;message&quot;&gt;
As with most things in life, very little is free. Since the goal is to produce thrust, a common measure of effiency is how much thrust gets produced per unit weight of expendable mass. Naturally, this is not so good a quantifier for something like a battery powered quadcopter, but for anything that must carry fuel or propellent, thrust per mass flow is usually what is meant by &quot;efficiency&quot;. 
&lt;/p&gt;

&lt;h2 id=&quot;mechanical-propulsion&quot;&gt;Mechanical Propulsion&lt;/h2&gt;

&lt;p&gt;This group covers any type of system that captures momentum from the environment, and includes sails and propellers.&lt;/p&gt;

&lt;p&gt;Sails (whether on the ocean or in space) have large surface areas so that when a particle collides with the surface, the particle’s momentum is transferred to the sail.&lt;/p&gt;

&lt;p&gt;Propellers operate slightly differently. Power is required to turn the propeller, and as the propeller moves through the fluid, the fluid is accelerated in one direction, and the vehicle is moved in the opposite direction.&lt;/p&gt;

&lt;p&gt;From a force perspective, the fluid’s flow over each propeller blade creates a pressure gradient, which can be integrated to find a forward force.&lt;/p&gt;

&lt;h3 id=&quot;propeller-based-systems&quot;&gt;Propeller Based Systems&lt;/h3&gt;

&lt;p&gt;Propeller driven propulsion system are further classified by &lt;em&gt;how power is supplied&lt;/em&gt;.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Turboprop and Turbofan&lt;/strong&gt; - a jet engine’s turbine is used to turn the propeller. Although the jet engine also does produce thrust, the propeller is what’s mostly responsible.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Electric Propulsion&lt;/strong&gt; - some power source drives an electric motor which turns the propellor. Batteries have poor energy density, which is why you don’t often see electric airplanes.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Gas Engine&lt;/strong&gt; - relies on good old combustion with cylinders and pistons to turn the propeller.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;electromagnetic-propulsion&quot;&gt;Electromagnetic Propulsion&lt;/h2&gt;

&lt;p&gt;Along with gravity, the weak nuclear force, and strong nuclear force, electromagnetism is one of the four fundamental interactions of the universe. In other words, it doesn’t get more general than this. The concept is pretty simple - use electric and magnetic fields to accerate charged particles. Unfortunately, electromagnetism is weird, and this makes things complicated.&lt;/p&gt;

&lt;p&gt;Propulsion systems under this umbrella subdivide into two categories:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Electrostatic&lt;/strong&gt; thrusters create a static electric field and accelerate particles from high field potential to low field potential. Gridded ion thrusters and electrosprays use this method.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Electromagnetic&lt;/strong&gt; thrusters create a combined electromagnetic field. Hall thrusters use this method.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;nozzle-propulsion&quot;&gt;Nozzle Propulsion&lt;/h2&gt;

&lt;p&gt;If you’ve ever put your thumb over the end of a hose and observed the flow of water increasing in velocity, you’ve seen a nozzle. Nozzles work by constricting the area through which a fluid can pass.&lt;/p&gt;

&lt;p&gt;From a mass conservation perspective, the fluid velocity must increase so the mass flow rate remains the same (this applies for incompressible fluids).&lt;/p&gt;

\[\dot{m} = \rho AV\]

&lt;p&gt;When the velocity increases, the pressure decreases according to Bernoulli’s equation (assumptions: adiabatic, incompressible, inviscid, isentropic).&lt;/p&gt;

\[P+\frac{1}{2}\rho U^2+gz=constant\]

&lt;p&gt;This point is especially important. Nozzles convert the internal energy (pressure and/or temperature) of a fluid into kinetic energy. Thus to maximize kinetic energy, we would like to increase the internal energy of the fluid &lt;em&gt;before&lt;/em&gt; it enters the nozzle.&lt;/p&gt;

&lt;h3 id=&quot;increasing-the-internal-energy&quot;&gt;Increasing the Internal Energy&lt;/h3&gt;

&lt;p&gt;Things are heating up now as we subdivide nozzle based propulsion systems by the mechanism through which energy is added to a fluid.&lt;/p&gt;

&lt;h3 id=&quot;electricity&quot;&gt;Electricity&lt;/h3&gt;

&lt;p&gt;Thrusters of this variety convert power in the form of electricity into thermal energy by heating up the fluid. Your toaster oven at home does this. By passing current through a heating element, some of the electrical power is converted into heat, which radiates and convects to the air around it. This exact method is used in a resistojet.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;A &lt;strong&gt;resistojet&lt;/strong&gt; is a nozzle based propulsion system which adds heat to a fluid by means of a resistor.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Alternatively, if two conducting pieces are placed very close to one another and have a high potential difference between them, current can &lt;strong&gt;arc&lt;/strong&gt; through the fluid in between. This action heats up the fluid, and thus we have discovered another type of thruster: the arcjet.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;An &lt;strong&gt;arcjet&lt;/strong&gt; is a nozzle based propulsion system which adds heat to a fluid by an electric discharge.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;radiation-nuclear&quot;&gt;Radiation (Nuclear)&lt;/h3&gt;

&lt;p&gt;Though the word “radiation” may invoke images of nuclear power plants and dangerous x-rays, scientifically speaking radiation simply refers to the transfer of heat through a wave or particle. If you’ve studied heat transfer, you’ll know that radiation via electromagnetic waves is a fundamental mode of heat transfer. Radiation can also exist through particles, such as with the alpha and beta radiation you get when atoms experience radioactive decay.&lt;/p&gt;

&lt;p&gt;In the context of propulsion systems, this energy can be used to &lt;strong&gt;directly&lt;/strong&gt; heat up a fluid. Note the important distinction here. We’re not using nuclear power to generate electricity to power the engine - heat from the controlled fission reaction goes directly into the propellent. Thus we are firmly still in the word of &lt;em&gt;nozzle based&lt;/em&gt; propulsion systems.&lt;/p&gt;

&lt;p&gt;The main implementation of this idea takes the form of nuclear thermal rockets.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;A &lt;strong&gt;nuclear thermal rocket&lt;/strong&gt; passes fluid over a nuclear reactor core, which gets heated and then accelerated with a nozzle.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In rocket applications, nuclear thermal systems have an efficiency and thust in between chemical thrusters, and electromagnetic thrusters. While a few have been developed, this technology never caught on.&lt;/p&gt;

&lt;p&gt;In aircraft applications, nuclear systems have been proposed for high endurance applications, but this idea was never realized.&lt;/p&gt;

&lt;h3 id=&quot;combustion&quot;&gt;Combustion&lt;/h3&gt;

&lt;p&gt;And finally we’ve gotten to the biggest bucket of all - combustion based propulsion. That thing which powers our cars and cooks our food, turns out to be pretty reliable for adding heat to fluids.&lt;/p&gt;

&lt;p&gt;But did you know there are actually two modes of combustion? Deflagration is the one most people are familiar with. This is an open flame, or that thing which powers your car.&lt;/p&gt;

&lt;p&gt;The other mode of combustion is known as a detonation. In a detonation, a supersonic exothermic wave expands out, creating a shockwave. Detonations are much louder and less stable than deflagration combustion, but have the theoretical capacity to be more efficient.&lt;/p&gt;

&lt;h4 id=&quot;detonation-combustion-propulsion&quot;&gt;Detonation Combustion Propulsion&lt;/h4&gt;

&lt;p&gt;As of today, only two detonation engine designs have been designed and tested. These are the pulse detonation engine, and rotating detonation engine.&lt;/p&gt;

&lt;h4 id=&quot;deflagration-combustion-propulsion&quot;&gt;Deflagration Combustion Propulsion&lt;/h4&gt;

&lt;p&gt;Arguably, the bulk of today’s propulsion technology sits in this category. To further subdivide, we merely have to ask the question:&lt;/p&gt;

&lt;p&gt;Where do we get the oxygen required for our combustion reaction? If the answer is from the atmosphere, then we have a jet engine. But if do not have this option and must carry all our oxygen onboard, then we have a rocket engine. Due to this constraint, rocket engines are less efficient than jet engines, but that hasn’t stopped us from building them bigger!&lt;/p&gt;

&lt;h5 id=&quot;jet-engines&quot;&gt;Jet Engines&lt;/h5&gt;

&lt;p&gt;Jet engines have become the backbone of today’s aviation industry. Unlike their rocket counterparts, planes have the luxury of flying through the atmosphere, which is full of useful oxygen for combustion reactions. Thus, Jet engines are referred to as “air-breathing”.&lt;/p&gt;

&lt;p&gt;The basic jet engine consists of 5 stages.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Inlet - slows down incoming air and deals with shockwaves if there’s any&lt;/li&gt;
  &lt;li&gt;Compressor - draws in air and slows it down while raising the pressure.&lt;/li&gt;
  &lt;li&gt;Combustion - adds energy to incoming fluid&lt;/li&gt;
  &lt;li&gt;Turbine - collect some power from the flow to drive the compressor&lt;/li&gt;
  &lt;li&gt;Nozzle - converts thermal energy into kinetic energy&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Jet engines that follow this model which includes a turbine are known as &lt;strong&gt;Turbojets&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Turbojet&lt;/strong&gt; - a nozzle based propulsion system, that uses deflagration combustion, where oyxgen for the combustion reaction is pulled from the environment. In order to pressurize air, a compressor is used.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;At some point in our quest to move faster, we must cross over into supersonic speeds. In this realm of super fast fluid flow, shocks become an important problem. Luckily, we have a solution: ramjets and scramjets.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Ramjets&lt;/strong&gt; - these function like a turbojet, but rely on the incredibly fast forward speed of the vehicle to compress incoming air. Thus, ramjets do away with the compressor and turbine stages, but do not generate any thrust on their own unless the vehicle is already moving.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Scramjets&lt;/strong&gt; - short for supersonic combustion ramjet. Virtually identical in functionality to a ramjet but instead of slowing the flow down to supsonic speeds for combustion, scarmjets keep the flow supersonic. This makes combustion very complicated but at &lt;strong&gt;very&lt;/strong&gt; high speeds, slowing incoming air down all the way just isn’t very efficient.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h5 id=&quot;rocket-engines&quot;&gt;Rocket Engines&lt;/h5&gt;

&lt;p&gt;And last but not least, we have rockets. Rockets engines are a nozzle based propulsion system, that relies on a deflagration combustion reactions to add thermal energy to a fluid. Additionally, rockets carry their own oxidizer onboard.&lt;/p&gt;

&lt;p&gt;So how do we subdivide rocket engines? Well how about by the way in which propellent is stored? If both fuel and oxidizer and mixed together in a solid, that’s a solid rocket motor.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Solid rocket motor&lt;/strong&gt; - not all that different from an explosive, but simple, cheap, and reliable. These things are what you find in hobby rockets, but can be scaled up to power things like the space shuttle.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;If (fuel xor oxidizer == liquid), then we have a hybrid rocket engine&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Hybrid rocket motor&lt;/strong&gt; - these allow for more control than a solid rocket motor, but are a step up in complexity.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Lastly, if both the fuel and oxidizer are liquid, then we have a liquid rocket.&lt;/p&gt;

&lt;h6 id=&quot;liquid-rockets&quot;&gt;Liquid Rockets&lt;/h6&gt;

&lt;p&gt;If you’ve ever seen a big rocket launch, most likely it was a liquid rocket. The Falcon 9, Atlas, Delta, and Space Shuttle are all examples. The primary advantage of these systems is their control. A series of pumps and valves moderate the flow of both oxidizer and fuel into the combustion chamber, thus allowing for operators on the ground to control the thrust. This is a necessary component if you want to attempt manuevers like propulsively landing your rocket.&lt;/p&gt;

&lt;p&gt;Liquid rockets are further classified by the way in which propellent is fed into the combustion chamber.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Pumps&lt;/strong&gt; are a common way and provide a nice amount of control.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Pump-fed systems&lt;/strong&gt; are classified into open loop systems, and closed loop systems.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Pressure&lt;/strong&gt; can also be used to push propellent along the lines.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Pressure-fed systems&lt;/strong&gt; are classified based on the source of pressure. Some propellents automatically sublimate and create pressure. These systems are autogenous. Alternatively, a third gas (usually a non-reactive nobel gas) can be used.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;A short addendum to the rockets category is &lt;strong&gt;monopropellant&lt;/strong&gt; engines.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Monopropellant engine&lt;/strong&gt; - these do not technically use combustion, but instead rely on an incredibly exothermic chemical decomposition reaction. Hydrazine (NH4) is a popular choice.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;summary&quot;&gt;Summary&lt;/h3&gt;

&lt;p&gt;And there you have it! If you’ve followed along all this way, we’ve gone over about 20 different propulsion systems, ranging from tiny electrosprays to enormous liquid rocket engines. Hopefully you’ve gained a better understanding for the fundamental principles that drive propulsion technology.&lt;/p&gt;

&lt;p&gt;Personally, I think roadmaps like this are important for visualizing gaps (now there’s a loaded systems engineering word for ya) in our research and development. A question like “what propulsive technologies are we missing?” is much more difficult to answer comprehensively than something like “how can we add heat to a fluid?”.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Electric Propulsion</title>
   <link href="https://ludavid15.github.io//electric/"/>
   <updated>2021-05-17T00:00:00-07:00</updated>
   <id>https://ludavid15.github.io//electric</id>
   <content type="html">&lt;p&gt;Electric propulsion (EP) is, you guessed it, all about electric propulsion. This includes: ion thrusters, hall thrusters, resistojets, arcjets, and electrosprays.&lt;/p&gt;

&lt;p&gt;Technically speaking, anything battery powered is also frequently called &lt;em&gt;electric propulsion&lt;/em&gt;, but the underlying mechanism of thrust generation in these cases is often a propeller, and that’s certainly an aerodynamics problem.&lt;/p&gt;

&lt;p&gt;Also worth mentioning while we’re here: propulsion systems are never independent of the entire vehicle. It turns out, the power/fuel demand greatly impacts the design. Sizing appropriate solar arrays for an EP spacecraft, or sizing fuel tanks for a rocket are challenges in their own right, so we’ll limit out scope in this post to analyzing thruster performance only.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h3 id=&quot;thrust-to-power-ratio&quot;&gt;Thrust to Power Ratio&lt;/h3&gt;
&lt;p&gt;Applicable to all EP systems. Note that as Isp improves, the thrust per unit power decreases. In the limit of very high Isp, the system is very efficient with propellant, but there is also no thrust being generated.&lt;/p&gt;

\[\frac{T}{P}=\frac{2\eta}{U_{ex}}\]

&lt;h3 id=&quot;thrust&quot;&gt;Thrust&lt;/h3&gt;

&lt;p&gt;Derived from a simple statement of conservation of momentum.
\(T=\ \dot{m}U_{ex}\)&lt;/p&gt;

&lt;h3 id=&quot;specific-impulse&quot;&gt;Specific Impulse&lt;/h3&gt;

&lt;p&gt;The specific impulse is defined with the following equation. In practice, the Isp is found not by measuring exhaust velocity, but rather by measuring thrust and flow rate.&lt;/p&gt;

\[I_{sp}=\frac{T}{\dot{m}g_o}=\frac{U_{ex}}{g_o}\]

&lt;h3 id=&quot;time-of-flight&quot;&gt;Time of Flight&lt;/h3&gt;

&lt;p&gt;Recall that the rocket equation is expressed as:
\(∆V=U_{exhaust}\log{m_initial/m_final}\)&lt;/p&gt;

&lt;p&gt;Solving the above in terms of the mass of propellent (the difference between the final and initial mass) we get the following equation:&lt;/p&gt;

\[m_{propellent}=m_{final}\ (e∆VUex-1)\]

&lt;p&gt;The thrust time will be equal to the mass of propellent divided by the mass flow rate. The mass flow rate can be expressed in terms of the thrust and exhaust velocity.&lt;/p&gt;

\[\dot{m}U_{ex}=T\]

\[\Delta t=\ \frac{m_{initial}U_{ex}}{T}e∆VUex-1\]

&lt;p&gt;Note that for electric propulsion systems, thrust scales directly with the power input, according to the following equation:&lt;/p&gt;

\[\frac{T}{P}=\frac{2\eta}{U_{ex}}\]

&lt;p&gt;Thus, the time of flight equation becomes:&lt;/p&gt;

\[∆t= (mpayload+αP)Uex22ηPe∆VUex-1\]

&lt;p&gt;Where α is defined as the power density, in units of [weight/power]. We see that thrust time trades directly with power input. For a known thrust time and power, there is an optimum Isp which will minimize launch mass. This is because at low specific impulse, there is a large propellant penalty, but at high specific impulse, there is a large power system mass penalty.&lt;/p&gt;

\[m_{initial}=\frac{2\Delta t\eta m_{pl}e^{\Delta V/U}}{2\Delta t\eta+\alpha U^2\left(1-e^{\Delta V/U}\right)}\]

&lt;h2 id=&quot;resistojets&quot;&gt;Resistojets&lt;/h2&gt;

&lt;p&gt;As the name implies, this type of thruster uses a resistive heating element to add energy to a propellent, which is then expanded through a nozzle. Through an energy balance, we can find an expression for the thrust output. Note the efficiency terms.&lt;/p&gt;

\[\frac{1}{2}\frac{T}{\dot{m}}=\eta P_{in}\]

\[\frac{T^2}{P_{in}}=2\eta\dot{m}\]

\[\eta=\eta_f\eta_n\eta_h\eta_d\]

&lt;p&gt;The power going into the propellant directly goes into raising the enthalpy of the propellant. We note here that enthalpy is a function of the temperature, and in most scenarios, is just equal to the specific heat times the temperature.&lt;/p&gt;

\[\eta_hP_{in}=\dot{m}h\left(T_c\right)\]

\[h=c_pT\]

&lt;p&gt;Using all the above relationship, we can express the exhaust velocity as a function of the chamber temperature and specific heat of the gas.&lt;/p&gt;

\[U_{ex}=\sqrt{2c_pT_c\eta_f\eta_n\eta_d}\]

&lt;h3 id=&quot;frozen-flow-efficiency&quot;&gt;Frozen Flow Efficiency&lt;/h3&gt;

&lt;p&gt;This efficiency term is a measure of how well the internal energy of the gas is converted into directed potential energy. In an ideal case, he would be equal to zero, indicating that 100% of the internal energy has been converted into kinetic energy. In reality, not all the energy can be recovered. In EP systems particularly, dissociation of the propellant due to high temperatures can often lead to high frozen flow losses. (c) refers to the enthalpy in the chamber, and (e) refers to the enthalpy at the exit plane.&lt;/p&gt;

\[\eta_f=\frac{h_c-h_e}{h_c}\]

&lt;p&gt;To improve the frozen flow efficiency, one can:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Increase length of the nozzle (increased heat loss to the walls generally outweighs improved frozen flow efficiency.&lt;/li&gt;
  &lt;li&gt;Increase pressure (although this increases engine mass)&lt;/li&gt;
  &lt;li&gt;Gases with lower specific heat have better recombination, at the expense of lower enthalpy.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;heater-efficiency&quot;&gt;Heater Efficiency&lt;/h3&gt;

&lt;p&gt;A measure of how much power input to the heating chamber is actually used towards raising the temperature of the propellant.&lt;/p&gt;

\[\eta_h=\frac{heat\ added\ to\ propellant}{power\ supplied}\]

&lt;h3 id=&quot;divergence-efficiency&quot;&gt;Divergence Efficiency&lt;/h3&gt;
&lt;p&gt;Decreased effective thrust due to radial velocity component of exhaust plume.&lt;/p&gt;

\[\eta_D={cos}^2\theta=\left[\frac{\int{\cos(\theta)d\dot{m}}}{\int{d\dot{m}}}\right]^2\]

&lt;h3 id=&quot;nozzle-efficiency&quot;&gt;Nozzle Efficiency&lt;/h3&gt;
&lt;p&gt;Viscous and thermal losses of propellant internal energy to the nozzle and chamber walls. Q dot here is the rate of energy loss to the walls.&lt;/p&gt;

\[\eta_n=\frac{h_c-h_e-\frac{\dot{Q}}{\dot{m}}}{h_c-h_e}\]

&lt;h3 id=&quot;enthalpy&quot;&gt;Enthalpy&lt;/h3&gt;
&lt;p&gt;The specific enthalpy scales with relation to the available energy storage modes, including translational, vibrational, rotational, and dissociative modes. (m) is the molecule mass of a propellent molecule. We’ve assumed that no ionization occurs.&lt;/p&gt;

\[h=\ \frac{k_bT}{m}\left[\frac{5}{2}\left(2-\alpha_2\right)+\beta_r\alpha_2+\beta_r\alpha_2+\frac{(1-\alpha_2)\varepsilon_D}{k_bT}\right]\]

\[\alpha_2+\frac{1}{2}\alpha_1=1\]

\[\alpha_2=fraction\ of\ molecules\ not\ dissociated\]

\[\alpha_1=2 * fraction\ of\ molecules\ that\ have\ dissociated\]

\[\varepsilon_D=dissociation\ energy\]

\[k_b=boltzman\ constant\]

\[\beta_r=percent\ of\ molecules\ which\ have\ this\ energy\ mode\]

&lt;p&gt;Note that for monoatomic molecules, there cannot be rotational or vibrational modes of energy storage. Thus, the enthalpy for a monoatomic molecule reduces to:&lt;/p&gt;

\[h=\ \frac{k_bT}{m}\left[\frac{5}{2}\right]\]

&lt;p&gt;Important result is that dissociation increases entropy, but only if molecules can recombine. If the nozzle length is too short, some dissociated molecules do not recombine to release usable energy in time before they are expelled out the nozzle.&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;
&lt;h2 id=&quot;arcjets&quot;&gt;Arcjets&lt;/h2&gt;
&lt;p&gt;Similar in concept to resistojets, but the propellant acts like a resistor. A typical Arcjets layout is shown below:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/arcjet.png&quot; alt=&quot;arcjet&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The power absorbed by the gas is a function of its resistance and the current passed through it. The resistance can be found with the following equations:&lt;/p&gt;

\[R=\eta\left(\frac{L}{A}\right)=\frac{m_eV_c}{n_eq^2}\left(\frac{L}{A}\right)\]

\[V_c=\ V_{Te}n_n\sigma\]

\[V_{Te}=\sqrt{\frac{k_bT_e}{m_e}}\]

\[\lambda=\frac{1}{n_n\sigma}\]

&lt;p&gt;Term Definitions:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;L – length of the chamber&lt;/li&gt;
  &lt;li&gt;A – nozzle throat area&lt;/li&gt;
  &lt;li&gt;Vc – electron/neutral collision frequency&lt;/li&gt;
  &lt;li&gt;VTe – thermal velocity of electrons&lt;/li&gt;
  &lt;li&gt;me – mass of an electron&lt;/li&gt;
  &lt;li&gt;σ – cross section of molecule (πr2)&lt;/li&gt;
  &lt;li&gt;ne – electron density&lt;/li&gt;
  &lt;li&gt;nn – neutral density&lt;/li&gt;
  &lt;li&gt;q – fundamental charge&lt;/li&gt;
  &lt;li&gt;kb – Boltzmann constant&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Arcjets are still limited in efficiency by the material at the wall. There is however, a significant temperature drop-off from the centerline to the wall, which can be expressed with the following differential equation (where K is the thermal conductivity [W/Km]):&lt;/p&gt;

\[\left(\frac{I}{A}\right)^2\eta=-\frac{1}{r}\frac{\partial}{\partial r}\left[rK\frac{dT}{dr}\right]\]

&lt;p&gt;Convection, and radiation have been ignored in the above relationship. It has also assumed that the power into the propellant has been evenly distributed throughout the volume.&lt;/p&gt;

&lt;p&gt;Thus, the relationship of exhaust velocity to Pin for an arcjet can be expressed as:&lt;/p&gt;

\[\frac{1}{2}\dot{m}{U_{ex}}^2=\eta\int\rho\left(\vec{u}\bullet\hat{n}\right)h\left(T\right)dA&amp;lt;\eta h(T_c)\dot{m}\]

&lt;p&gt;Where \( T_c \) refers to the temperature long the centerline.&lt;/p&gt;

&lt;h3 id=&quot;derivation-of-gas-resistivity&quot;&gt;Derivation of Gas Resistivity&lt;/h3&gt;

&lt;p&gt;Begin by assuming some electric field, spanning some gap populated with neutral molecules. The acceleration of electrons in that field can be expressed as:&lt;/p&gt;

\[m_e\frac{dV}{dT}=-q\vec{E}\]

&lt;p&gt;In between collisions with the neutrals, the electron is accelerated by the electric field. The increase in velocity is found by integrating the above equation. In this case, Δt is the time in between collisions.&lt;/p&gt;

\[\vec{V_f}=-\frac{qE}{m_e}∆t+Vi\]

&lt;p&gt;We assume that velocity added by the electric field is negligible compared to the thermal velocity of electrons, which allows us to write:&lt;/p&gt;

\[∆t=1Vc≅λVTe\]

&lt;p&gt;The average velocity of electrons in the gap is then:&lt;/p&gt;

\[Average\ V_f=\frac{1}{N}\sum{-\frac{qE\Delta t}{m_e}}+\frac{1}{N}\sum V_i=-\frac{qE}{m_eV_c}\]

&lt;h2 id=&quot;gridded-ion-thruster&quot;&gt;Gridded Ion Thruster&lt;/h2&gt;

&lt;p&gt;These thrusters no longer rely on heating of a propellant. Instead, ions are directly accelerated through an electrostatic potential. Note that like a thermal system, kinetic energy of the propellant increase as the potential energy goes down. In this case, potential energy is in the form of an electrostatic potential.&lt;/p&gt;

\[\frac{1}{2}mU^2=q(V_{in}-V_{out})\]

\[U_{ex}=\sqrt{\frac{2q}{M}V_o}\]

\[T=\dot{m}U_{ex}=\frac{I_B}{q}M_{Xe}\sqrt{\frac{2q}{M_{Xe}}V_o}\]

&lt;p&gt;There are few important constraints that affect how we want to design the electric potential profile of the thruster.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;We want a large potential drop from the positive grid to the negative grid to accelerate our ions.&lt;/li&gt;
  &lt;li&gt;We want to attract positively charged ions to the positive grid while repelling electrons. This is achieved by keeping the chamber at a slightly higher potential than the positive grid.&lt;/li&gt;
  &lt;li&gt;We do not want electrons in the exhaust plume to be pulled back into the chamber, so we offset the entire thruster, (i.e. the negative grid is at a lower potential than the exhaust, thus repelling electrons).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In general, there are three important components to a gridded ion thruster&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Accelerator Grid (A positive and negative grid, sometimes a third one)&lt;/li&gt;
  &lt;li&gt;Ion Production chamber&lt;/li&gt;
  &lt;li&gt;Neutralizing Electron Gun&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;An electrical diagram is shown below, along with a map of the electric potential throughout the thruster. A minimum of 3 independent power supplies are required in order to achieve the desired mapping of potentials.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/git.png&quot; alt=&quot;Gridded Ion Thruster&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The efficiency of a gridded ion system can be calculated with an energy balance as follows:&lt;/p&gt;

\[\eta=\frac{T^2}{2\dot{m}P_{in}}\]

\[\eta=\frac{M}{\dot{m}}\frac{V_B}{q}\frac{I_B^2{cos}^2\theta}{P_D+V_BI_B}=\eta_D\eta_m\eta_e\]

\[\eta_D={cos}^2\theta\]

\[\eta_m=\frac{M}{\dot{m}}\frac{I_B}{q}\]

\[\eta_E=\frac{V_BI_B}{P_D+V_BI_B}\]

&lt;p&gt;Where, B refers to beam and D refers to the discharge. The three main types of efficiency are the discharge efficiency, mass utilization efficiency (how much of mass flowrate is successfully accelerated), and the electrical efficiency (power put into the ionization and constraining ions vs energy of successfully accelerated ions).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/gitPotential.png&quot; alt=&quot;GIT Potential&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;charge-exchange-event&quot;&gt;Charge Exchange Event&lt;/h3&gt;
&lt;p&gt;An event in which an accelerated ion impacts a neutral molecule in the exhaust plume. The decelerated ion is drawn back into to the potential well that was preventing electron backflow. This leads to sputtering and degrading of the negative grid.&lt;/p&gt;

&lt;p&gt;Solution is to install a third grid, which creates a positive electric potential which repels ions. It unfortunately does attract electrons, but electrons are stopped by the negative grid from passing further into the thruster.&lt;/p&gt;

&lt;h3 id=&quot;space-charge-limited-thrust-density&quot;&gt;Space Charge Limited Thrust Density&lt;/h3&gt;

&lt;p&gt;There is a limit to the amount of current which can be passed through the grids before the current itself cancels the electric field. This limit is defined with the Child-Langmuir Law.&lt;/p&gt;

\[J=\frac{4\varepsilon_o}{9}\sqrt{\frac{2q}{m_{Xe}}}\frac{V^{3/2}}{d^2}\]

&lt;p&gt;This is the primary limiter of thrust density for all Gridded Ion Thrusters.&lt;/p&gt;

&lt;h3 id=&quot;quasi-neutrality&quot;&gt;Quasi-Neutrality&lt;/h3&gt;

&lt;p&gt;Within the plasma chamber of a gridded ion thruster, quasi-neutrality is maintained (i.e. the electron density and ion density is the same). This is no longer true between the grids (by design since electrons are not allowed to enter). Quasi-neutrality is also maintained everywhere within a Hall thruster. This idea is important because space charge effects cannot apply to a quasi-neutral plasma.&lt;/p&gt;

&lt;h2 id=&quot;hall-thrusters&quot;&gt;Hall Thrusters&lt;/h2&gt;
&lt;p&gt;Hall thrusters are a form of electromagnetic propulsion which rely on the combination of an electric field and magnetic field. They have higher thrust densities than gridded ion thrusters, but lower efficiency and specific impulse.&lt;/p&gt;

&lt;p&gt;Propellent, typically Xenon, is injected into the chamber. They collide with electrons caught in the hall drift and are ionized. The ions are then accelerated out by the electric field.&lt;/p&gt;

&lt;p&gt;Although the device is an electrostatic accelerator, thrust is actually produced magnetically through the hall current. The hall current generates a magnetic field, which interacts with the current flowing in the solenoids (which generate the magnetic field that causes the hall current in the first place) to generate thrust. So, while the thruster can be analyzed with momentum conservation, the mechanism of force generation is not directly due to the acceleration of ions.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;\(I_D\) 	Discharge Current&lt;/li&gt;
  &lt;li&gt;\(I_B\)	Beam Current&lt;/li&gt;
  &lt;li&gt;\(I_{ec}\)	Cathode Discharge Current&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The discharge current represents the total current emitted from the cathode. A portion will go towards neutralizing the exhaust and is thus equal to the beam current. Another portion falls into the annulus of the thruster. Electrons which fall into the annulus become trapped in the Hall Effect, providing the source of ionization and thrust. Overtime, electrons will collide with neutrals, ionizing them. However, this leads to them slowly escaping the Hall Effect and eventually falling into the anode (along the electric potential line). The current of electrons escaping the hall current and reaching the anode (Iec) is a loss mechanism.&lt;/p&gt;

\[I_D=I_B+I_{ec}\]

&lt;p&gt;We can define a similar setup for the voltage.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;\(V_D\) 	Discharge Voltage&lt;/li&gt;
  &lt;li&gt;\(V_o\)	Beam Voltage&lt;/li&gt;
  &lt;li&gt;\(V_c\)	Cathode Offset Voltage&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As with the current, a portion of the total discharge voltage goes towards extracting electrons from the cathode, instead of accelerating ions in the beam. This value is typically small (20 V, compared to a 300 V discharge voltage).&lt;/p&gt;

\[V_D=V_o+V_c\]

&lt;h3 id=&quot;larmor-precession&quot;&gt;Larmor Precession&lt;/h3&gt;

&lt;p&gt;Charged particles subject to a magnetic field experience a phenomenon known as Larmor precession. This is a spiraling motion, azimuthally around the axis of the magnetic field. Recall that Maxwell’s equation states:&lt;/p&gt;

\[F=q(V\times B)\]

&lt;p&gt;The radius of this precession is known as the Larmor radius/Gryoradius, and the frequency is known as the Cyclotron frequency.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/LarmorProcession.jpg&quot; alt=&quot;larmorPrecesession&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

\[\omega_{cyclotron}=\frac{qB}{m}\]

\[r_{Larmor}=\frac{mv_\bot}{qB}\]

&lt;p&gt;Due to the mass difference, ions have a much larger Larmor radius than electrons. This means that electron motion is very tightly bound by the magnetic field lines, but ions are mostly free to follow the direction of electric potential.&lt;/p&gt;

&lt;h3 id=&quot;hall-effect&quot;&gt;Hall Effect&lt;/h3&gt;
&lt;p&gt;When subject to perpendicular E and B fields, charged particles will experience azimuthal drift in the direction perpendicular to both the E and B field. The drift velocity can be found as:&lt;/p&gt;

\[v_\theta=\frac{E\times B}{B^2}\]

&lt;p&gt;This leads the creation of the Hall Current, which is the current due to charged particles (in our case only electrons) drifting in the azimuthal direction within the thruster. Ions also experience drift, but due to their larger mass are not as affected.&lt;/p&gt;

\[J_{hall}=qn_ev_\theta\]

&lt;p&gt;The net equation of motion for a charged particle inside an E x B field is the combination of the E x B drift term (the Hall Effect), and the Larmor precession. The initial perpendicular velocity and phase can be given, but in our case, we are not as interested in the specific motion of a single electron as the general bulk motion giving rise to the hall current.&lt;/p&gt;

\[\vec{v}=-\frac{E_o}{B_o}\hat{y}+v_\bot[\cos{\left(\omega_{ce}t+\theta\right)}\hat{x}+\sin(\omega_{ce}t+\theta)\hat{y}]\]

\[J_{hall}=qn_e\frac{E_o}{B_o}\]

&lt;h3 id=&quot;hall-thruster-efficiency&quot;&gt;Hall Thruster Efficiency&lt;/h3&gt;

&lt;p&gt;Hall thruster efficiency decreases with thruster size. This is due to the ratio of surface area to volume (electrons colliding with the SA is a loss). Current systems can achieve about 75% efficiency, and this appears to be an empirical limit. We define the following efficiency terms:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Current utilization (losses due to differences between beam and discharge current). This is the dominate form of loss (~75%)&lt;/li&gt;
  &lt;li&gt;Charge utilization (losses due to non-singly charged ions) (~95-97%)&lt;/li&gt;
  &lt;li&gt;Divergence efficiency (~93-95%)&lt;/li&gt;
  &lt;li&gt;Mass utilization (~93-99%)&lt;/li&gt;
  &lt;li&gt;Voltage utilization (losses due to applied voltage potential not being equal to potential drop of ions as they are accelerated) (~95%)&lt;/li&gt;
  &lt;li&gt;Electrical efficiency (~99%)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These efficiencies can be calculated using the following expressions:&lt;/p&gt;

\[\eta_B=\frac{I_B}{I_D}\]

\[\eta_v=\frac{V_o}{V_D}\]

\[\eta_e=\frac{V_DI_D}{V_DI_D+P_{magnets}}\]

\[\eta_m=\frac{\dot{m}_{beam}} {\dot{m}_{injected}}\]

\[\eta_D={cos}^2(\theta)\]

&lt;p&gt;The total power efficiency is the product of the current and voltage utilization efficiency. As mentioned, the major loss mechanism in Hall thrusters is the flow of electrons flowing into the anode. This current is captured by the Iec term. This loss mechanism can be reduced by increasing the strength of the magnetic field (and hence electron confinement by the hall effect). See Hall Parameter.&lt;/p&gt;

&lt;h3 id=&quot;hall-parameter&quot;&gt;Hall Parameter&lt;/h3&gt;

&lt;p&gt;The hall parameter is the ratio of cyclotron frequency to collision frequency. At higher values, the rate of electron-neutral collisions is decreased, hall current increases, and efficiency improves (due to fewer losses to the anode). The hall parameter increases with increasing magnetic field.&lt;/p&gt;

\[\Omega=\frac{\omega_{cyclotron}}{v_c}\]

&lt;p&gt;In general, a higher hall parameter is desirable. However, at very large values, the magnetic field becomes sufficiently large that ions are also trapped by the Hall drift and thrust decreases to zero. Current empirical cap is around 150.&lt;/p&gt;

&lt;h3 id=&quot;hall-thruster-erosion&quot;&gt;Hall Thruster Erosion&lt;/h3&gt;

&lt;p&gt;This is an issue that has been largely overcome due to the technology of magnetic shielding. Magnetic field lines are configured such that charged particles following the field lines do not collide with the walls.&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;
&lt;h2 id=&quot;electrosprays&quot;&gt;Electrosprays&lt;/h2&gt;

&lt;p&gt;Electrosprays rely on the acceleration of charged ionic fluid with an electrostatic field. When exposed to an electrostatic potential, an ionic liquid will form into a Taylor Cone and droplets will be emitted from the tip of the cone.&lt;/p&gt;

&lt;p&gt;Electrosprays are further subdivided system which emit droplets (colloids) and system which emit ion (field emission thruster, or FEEP). Colloid thruster use ionic liquids, while some FEEP systems use liquid metals. Due to the high mass of droplets, colloid thrusters product greater thrust, at the loss of efficiency.&lt;/p&gt;

&lt;h3 id=&quot;colloid-thrusters&quot;&gt;Colloid Thrusters&lt;/h3&gt;

&lt;p&gt;Charged propellant droplets have some average charge to mass ratio that is a function of the volume flow rate.&lt;/p&gt;

\[\frac{q}{m}= \frac{f(\varepsilon)}{\rho} (\frac{\gamma K}{\varepsilon Q})^{\frac{1}{2}}\]

&lt;p&gt;Where f(ε) is an empirical scaling function that is equal to approximately 18 for values of (ε) greater than 40. K is the conductivity, Q is the volume flow rate, ε is the permittivity of the liquid, \gamma is the surface tension, and \rho is the density. The above can be used to solve for thrust as a function of the specific impulse and applied voltage.&lt;/p&gt;

\[T=\frac{f(\varepsilon )^2}{\rho (g_o Isp)^3}(\frac{\gamma K}{\varepsilon})4{V_o}^2\]

&lt;p&gt;Importantly, we find that that thrust scales with the square of voltage, but inversely with the cube of Isp. At high values of specific impulse, an extremely large voltage is required to produce even small amounts of thrust. Thus electrosprays must be built with multiple emission sites (typically on the order of 100-1000) to reach thrust levels comparable to gridded ion or hall thrusters.&lt;/p&gt;

&lt;p&gt;Luckily, this also means that we can just keep adding emission sites to increase the thrust (like increasing the number of thrusters). At this scale, doing so adds relatively little support equipment mass.&lt;/p&gt;

&lt;p&gt;If you’re interested, read all about electrospray scaling issues &lt;a href=&quot;https://docs.google.com/document/d/1sRX4AJxvLSF1PADZBpmdQWkueGrxS-LC/edit?usp=share_link&amp;amp;ouid=113710643301397614506&amp;amp;rtpof=true&amp;amp;sd=true&quot;&gt;here&lt;/a&gt;!&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Fundamentals of Dynamics</title>
   <link href="https://ludavid15.github.io//fundamentalsDynamics/"/>
   <updated>2021-05-13T00:00:00-07:00</updated>
   <id>https://ludavid15.github.io//dynamicsFundamentals</id>
   <content type="html">&lt;p&gt;In dynamics, the goal is to predict the position, velocity, and acceleration of rigid bodies as a function of time through using this equation: F=ma. While the basic principle is simple, the key challenge of dynamics involves defining reference frames, vectors, and their relationships.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Note that F = ma is not the only way to solve dynamics problems! In the late 1700’s, Joseph-Louis Lagrange introduced an energy conservation strategy, known today as the Euler-Lagrange Equations.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;!--more--&gt;

&lt;p&gt;The first idea to introduce is that of a reference frame. References frames are often attached to a rigid body, but this is not required. There are two properties to consider when relating two reference frames.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Position vector from the origin of one frame to another.&lt;/li&gt;
  &lt;li&gt;Rotation from one frame to another.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;At this point, one may be tempted to take the derivative of the two previous quantities. However, this must be done carefully. This is because there are very specific definitions of angular velocity and velocity. Taking the derivative is non-trivial! We are in the world of 3-dimensions now, so no more thinking in terms of scalars!&lt;/p&gt;

&lt;h3 id=&quot;kinematics&quot;&gt;Kinematics&lt;/h3&gt;

&lt;p&gt;A subset of dynamics, where forces are neglected, and we focus instead on the motion of points and rigid bodies over time.&lt;/p&gt;

&lt;h3 id=&quot;representation-of-rotations&quot;&gt;Representation of Rotations&lt;/h3&gt;

&lt;p&gt;As we will see, an angular velocity is one easy way to define the rotation of one frame with respect to another. The angular velocity is defined using a vector and an angle. However, there are other ways to define the rotation. These methods are:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;A Rotation Matrix&lt;/li&gt;
  &lt;li&gt;Euler Angle Rotations&lt;/li&gt;
  &lt;li&gt;Axis-angle&lt;/li&gt;
  &lt;li&gt;Quaternions&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Each method technically encapsulates all the information you need, and for obvious reasons, some are more useful than others.&lt;/p&gt;

&lt;h3 id=&quot;vectors&quot;&gt;Vectors&lt;/h3&gt;

&lt;p&gt;In the context of dynamics, a vector is defined as a construct of direction and magnitude, but do not have an associated location, unless otherwise specified to be a &lt;strong&gt;position vector&lt;/strong&gt;. Vectors are typically defined through the use of orthonormal basis vectors. A set of basis vectors is said to span some space/range. (see math section for a more detailed discussion of vectors spaces and linear algebra).&lt;/p&gt;

\[V=\sum V_i\alpha_i\]

&lt;p&gt;Where the values of \(\alpha_i\) are the basis vectors which are defined for a given problem and reference frame, and \(V_i\) are called the measure numbers (these are scalars).&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Fundamentals of Fluid Mechanics</title>
   <link href="https://ludavid15.github.io//fluidFundamentals/"/>
   <updated>2021-05-12T00:00:00-07:00</updated>
   <id>https://ludavid15.github.io//fluidFundamentals</id>
   <content type="html">&lt;p&gt;When we talk about fluid mechanics, we aren’t just talking about the second state of matter (liquid \(\subset\) fluid). Fluid mechanics is the study of &lt;em&gt;flow&lt;/em&gt;, which applies to both liquids and gases.&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;Also, we’re only dealing with &lt;strong&gt;Newtonion fluids&lt;/strong&gt;. Non-newtonian fluids are weird, and I haven’t studied them, so there won’t be anything about them here.&lt;/p&gt;

&lt;p&gt;Lastly, while we’re laying down the groundwork, it’s important to mention that classic fluid mechanics is treated as a subset of continuum mechanics. This is known as an engineering model - a set of assumptions we make to simplify real-life.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Continuums are characterized by the existence of shear, and by being continuous (duh).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;But watch out! When the density is really low, (such as in space) the continuum assumption falls apart, at which point we must switch over to molecular dynamics. This is an important rule to remember generally speaking - each equation we develop comes with it’s own set of assumptions that must be true or else our equation isn’t valid.&lt;/p&gt;

&lt;h3 id=&quot;newtonian-fluid&quot;&gt;Newtonian Fluid&lt;/h3&gt;

&lt;p&gt;A Newtonian fluid has a linear relationship between stress and strain rate. Non-newtonian fluids have non-linear relationships.&lt;/p&gt;

&lt;h2 id=&quot;fundamentals&quot;&gt;Fundamentals&lt;/h2&gt;

&lt;p&gt;In general, we want to find the following properties as a function of location and time:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Pressure&lt;/li&gt;
  &lt;li&gt;Temperature&lt;/li&gt;
  &lt;li&gt;Density&lt;/li&gt;
  &lt;li&gt;Velocity&lt;/li&gt;
  &lt;li&gt;Acceleration&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;With the above information, we can find things like lift, drag, work, &amp;amp; heat transfer (all very important for engineering applications). In a complete model, all 5 of these properties are closely related. Not surprisingly, it’s also difficult to solve for all 5 properties at once. Thus, the subject of fluid mechanics is further broken up into categories based on assumptions and simplifications. These assumptions allow us to make certain variables independent of other variables. The three most important “categories” are:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Incompressible vs Compressible&lt;/li&gt;
  &lt;li&gt;Inviscid vs Viscid&lt;/li&gt;
  &lt;li&gt;Laminar vs Turbulent&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Any combinations of the above labels are technically possible. Here are a few examples, and the respective sub-domains you get:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Compressible, Inviscid, Laminar = Shocks, expansion waves, acoustic waves&lt;/li&gt;
  &lt;li&gt;Compressible, Viscid, Turbulent = Turbulent boundary layers, supersonic wakes&lt;/li&gt;
  &lt;li&gt;Compressible, Viscid, Laminar = Hypersonic boundary layers&lt;/li&gt;
  &lt;li&gt;Incompressible, Inviscid, Laminar = Potential flow theory&lt;/li&gt;
  &lt;li&gt;Incompressible, Viscid, Laminar = Creeping flow, boundary layer theory&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;To solve problems in fluid mechanics, we can borrow laws and theories that traditionally fall under other disciplines. Some examples:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Thermodynamics&lt;/li&gt;
  &lt;li&gt;Conservation Equations&lt;/li&gt;
  &lt;li&gt;Gas Laws&lt;/li&gt;
  &lt;li&gt;Continuum Mechanics&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;And finally, we can make assumptions which are imposed as additional contraints. Common assumptions come from thermodynamics: isentropic, isobaric, isochoric, isothermal, steady, etc.&lt;/p&gt;

&lt;h3 id=&quot;viscosity&quot;&gt;Viscosity&lt;/h3&gt;

&lt;p&gt;The viscosity of a fluid $\mu$ defines the relationship between stress and strain. In most cases, we assume that the fluid is a Newtonian Fluid, meaning its stress and strain are related linearly. Here it is in two dimensions:&lt;/p&gt;

\[\tau=\mu\left(\frac{\partial u}{\partial y}+\frac{\partial v}{\partial x}\right)\]

\[Friction\ Force=\mu\nabla^2\vec{V}=\nabla\tau\]

&lt;p&gt;We can also define the second coefficient of viscosity as λ.&lt;/p&gt;

\[\xi=\lambda+\frac{2}{3}\mu\]
</content>
 </entry>
 
 <entry>
   <title>Kinematics</title>
   <link href="https://ludavid15.github.io//kinematics/"/>
   <updated>2021-05-12T00:00:00-07:00</updated>
   <id>https://ludavid15.github.io//kinematics</id>
   <content type="html">&lt;p&gt;A subset of dynamics, where forces are neglected, and we focus instead on the motion of points and rigid bodies over time. At the core of this topic are a series of rules about positions, velocities, accelerations, and how to find them amid a potentially messy system of reference frames and motion constraints.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;derivatives&quot;&gt;Derivatives&lt;/h2&gt;

&lt;p&gt;In the world of 3D dynamics, derivatives get complicated. This is largely due to reference frames. We’ll indicate a vector’s reference frame with a prescript.&lt;/p&gt;

&lt;p&gt;For example, \({}^A V \) indicates that the vector V is defined with respect to reference frame A.&lt;/p&gt;

&lt;h3 id=&quot;derivative-of-a-vector&quot;&gt;Derivative of a Vector&lt;/h3&gt;

&lt;p&gt;The derivative of a vector must always be defined with respect to some reference frame. Given a reference frame A, and basis vectors \(\alpha_i\), and measure numbers \(V_i\), the derivative of vector V in frame A is defined as:&lt;/p&gt;

\[{}^A\frac{dV}{dt}=\sum\frac{dV_i}{dx}\alpha_i\]

&lt;p&gt;Thus, one way to take the derivative of vector V is to express the vector in terms of the A basis vectors first, and then derive the measure numbers.&lt;/p&gt;

&lt;h3 id=&quot;angular-velocity&quot;&gt;Angular Velocity&lt;/h3&gt;

&lt;p&gt;The angular velocity is defined as a vector function such that the cross of it with any vector fixed in the frame yields the derivative of that vector in a new frame. Let’s break this down a little bit.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Define a world frame &lt;strong&gt;A&lt;/strong&gt;, and local frame &lt;strong&gt;B&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;Define a vector \(b_1\), that is fixed in &lt;strong&gt;B&lt;/strong&gt;, and defined in &lt;strong&gt;B&lt;/strong&gt; (understand the difference between fixed in &lt;strong&gt;B&lt;/strong&gt; vs defined in &lt;strong&gt;B&lt;/strong&gt;).&lt;/li&gt;
  &lt;li&gt;An angular velocity term relates the original vector defined in B, to it’s velocity defined in A.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;In other words, the angular velocity describes the rotation of one frame in another.&lt;/p&gt;

\[{}^A \omega^B \times V= {}^A \frac{dV}{dt}\]

&lt;p&gt;Where the the above notation indicates that \(\omega\) is the angular velocity of frame B defined in frame A.&lt;/p&gt;

\[{}^A \omega^B = b_1 (\dot{b_2} \bullet b_3 )+ b_2 (\dot{b_3} \bullet b_1 )+b_3 (\dot{b_1}\bullet b_2)\]

&lt;p&gt;This is a convenient tool for finding the derivative of a vector without first doing a complex change of reference frame calculation. Angular velocities can be added linearly. That is:&lt;/p&gt;

\[{}^A\omega^D=\ {}^A\omega^B + {}^B\omega^C + {}^C\omega^D\]

&lt;p&gt;Angular velocities can also be taken in inverse by applying a negative value in front:&lt;/p&gt;

\[{}^A\omega^B=\ - {}^B\omega^A\]

&lt;h3 id=&quot;rules-about-derivatives&quot;&gt;Rules about Derivatives&lt;/h3&gt;

&lt;p&gt;There are a few rules to keep in mind when taking derivatives of vectors. First, it is that the order of differentiation matters when taking a double differential. That is to say,&lt;/p&gt;

\[{}^B \frac{d}{dt}\left({}^A \frac{d}{dt}V\right)\neq {}^A\frac{d}{dt}\left({}^B\frac{d}{dt}V\right)\]

&lt;p&gt;Some other rules are shown below for differentiation of sums and products&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Derivatives of a sum are distributed&lt;/li&gt;
&lt;/ul&gt;

\[{}^A\frac{d}{dt}\left(V_1+V_2\right)=\ {}^A\frac{d}{dt}V_1+{}^A\frac{d}{dt}V_2\]

&lt;ul&gt;
  &lt;li&gt;You can pull out a scalar multiplier&lt;/li&gt;
&lt;/ul&gt;

\[{}^A\frac{d}{dt}\left({sV}_1\right)=\ {}^A\frac{ds}{dt}V_1+s{}^A\frac{d}{dt}V_1\]

&lt;ul&gt;
  &lt;li&gt;Use the product rule when dealing with vector dot products (also known as an inner product).&lt;/li&gt;
&lt;/ul&gt;

\[{}^A\frac{d}{dt}\left(V\bullet W\right)=\ {}^A\frac{dV}{dt}\bullet W+V\bullet{}^A\frac{dW}{dt}\]

&lt;ul&gt;
  &lt;li&gt;Also use the product rule with dealing with vector cross products (a.k.a. outer product), but note the change in operation order.&lt;/li&gt;
&lt;/ul&gt;

\[{}^A\frac{d}{dt}\left(V\times W\right)=\ {}^A\frac{dV}{dt}\times W+{}^A\frac{dW}{dt}\times V\]

&lt;h3 id=&quot;simple-angular-velocity&quot;&gt;Simple Angular Velocity&lt;/h3&gt;

&lt;p&gt;If there is a vector (k) fixed in both frame A and frame B over an interval of time, then B is said to have simple angular velocity in A during that time interval. This simplifies the expression of the angular velocity of B in A to:&lt;/p&gt;

\[{}^A\omega^B=\ \dot{\theta} k\]

&lt;p&gt;Where \( \theta \) is an angle defined around the common axis, and k is a unit vector in the direction of the axis defined in A. This is a more precise way of defining the case where an “axis” of rotation may exist, but note that generally speaking, an axis does not need to exist for us to be able to define an angular velocity.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Interestingly, Euler’s Rotation Theorem states that in three-dimensional space, any displacement of a rigid body such that a point on the rigid body remains fixed, is equivalent to a single rotation about some axis that runs through the fixed point. This leads to the idea of a “group” - a mathematical structure which all rotations must follow. This 3D rotation group is known as SO(3). In matrix representation, this is any orthogonal 3x3 matrix with determinant 1.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;derivative-in-two-reference-frames&quot;&gt;Derivative in Two Reference Frames&lt;/h3&gt;

&lt;p&gt;The derivative of the same vector with respect to two different reference frames A and B can be related by the angular velocity of B in A.&lt;/p&gt;

\[{}^A\frac{dV}{dt}=\ {}^B\frac{dV}{dt}+{}^A\omega^B\times V\]

&lt;p&gt;Where V does not have to be a vector fixed in B. Note that if V is fixed in B, the derivative of V with respect to B goes to zero, leaving just the cross product of the angular velocity and V yielding the derivative in A.&lt;/p&gt;

&lt;h3 id=&quot;angular-acceleration&quot;&gt;Angular Acceleration&lt;/h3&gt;

&lt;p&gt;The angular acceleration of a vector is defined as the derivative of an angular velocity vector function in &lt;em&gt;any frame&lt;/em&gt;. Note that the frame in which we take the derivative does not matter.&lt;/p&gt;

\[{}^A\alpha^B=\ {}^A\frac{d}{dt} {}^A\omega^B = {}^B\frac{d}{dt} {}^A\omega^B\]

&lt;p&gt;We can prove this second fact by applying the rule of differentiation in two reference frames, noting that a vector crossed by itself is always equal to zero.&lt;/p&gt;

\[{}^A\frac{d\omega}{dt}=\ {}^B\frac{d\omega}{dt}+{}^A\omega^B\times{}^A\omega^B\]

&lt;h3 id=&quot;general-velocity-and-general-acceleration&quot;&gt;General Velocity and General Acceleration&lt;/h3&gt;

&lt;p&gt;To define general velocity, we need to define a position vector. A position vector must start from a fixed point in the frame of differentiation. Any fixed point can be taken, as long as it is in the frame.&lt;/p&gt;

\[{}^AV^P=\ {}^A\frac{d}{dt}P^{P/N}\]

&lt;p&gt;The above is an expression for the velocity of point P in the reference frame A, where the vector P goes from point N fixed in A to a point P not fixed in A. The definition of acceleration of point P in frame A is then found by taking the second derivative of the velocity vector.&lt;/p&gt;

\[{}^Aa^P={}^A\frac{d}{dt}{}^AV^P\]

&lt;h3 id=&quot;v2pts-and-a2pts&quot;&gt;V2PTS and A2PTS&lt;/h3&gt;

&lt;p&gt;Consider two points (P and Q) fixed in a rigid body B, that has some angular velocity in frame A. We can relate the velocities of these two points in frame A as:&lt;/p&gt;

\[{}^AV^Q= {}^AV ^P+ {}^A \omega^B \times R^{Q/P}\]

&lt;p&gt;Where R is a vector that points to Q from P. Similarly, we can relate the acceleration of these points if we know the angular acceleration of body B in frame A.&lt;/p&gt;

\[{}^Aa^Q={}^A a^P+{}^A\omega ^B \times ( {}^A\omega ^B \times R^{Q/P})+{}^A \alpha^B \times R^{Q/P}\]

&lt;h3 id=&quot;v1pts-and-a1pts&quot;&gt;V1PTS and A1PTS&lt;/h3&gt;

&lt;p&gt;Consider a point P that has some velocity in frame B. Frame B itself moved with angular velocity in a reference frame A. The velocity and acceleration of point P in frame A is defined as:&lt;/p&gt;

\[{}^AV^P={}^AV^{B_p}+{}^BV^P\]

\[{}^Aa^P={}^Aa^{B_p}+{}^Ba^P+2{}^A\omega^B\times{}^BV^P\]

&lt;p&gt;Where \( B_p \) is defined as a point of B coincident with P at some time, t*. This is convenient because we can define \( B_p \) to be stationary in B.&lt;/p&gt;

&lt;h2 id=&quot;configuration-constraints&quot;&gt;Configuration Constraints&lt;/h2&gt;

&lt;p&gt;Consider a system of points, where each point is defined by position vector, where each vector has three measure numbers. A constraint configuration constraint is a function of these measure numbers that is equal to zero. Configuration constraints are also known as “holonomic constraints”.&lt;/p&gt;

\[P_1,P_2,\ldots,\ P_n\rightarrow vectors\]

\[f\left(P_{11},\ P_{12},\ P_{13},\ldots,\ P_{n1},\ P_{n2},P_{n3}\right)=0\]

&lt;p&gt;Next, we are going to define what are known as generalized coordinates and speeds. The main objective of this function is to simplify later when we have to define and solve the F = ma equation.&lt;/p&gt;

&lt;h3 id=&quot;generalized-coordinates&quot;&gt;Generalized Coordinates&lt;/h3&gt;

&lt;p&gt;Instead of using configuration constraints, we can define a set of (n) generalized coordinates. The total number of generalized coordinates is equal to:&lt;/p&gt;

\[n=3v+6\eta-m\]

&lt;p&gt;Where v is the number of points, \(\eta\) is the number of rigid bodies, and m is the number of configuration constraints we have defined in the original problem. Generalized coordinates are usually defined with the letter q.&lt;/p&gt;

\[q_1,q_2,q_3,\ldots q_n\]

&lt;h3 id=&quot;generalized-speeds&quot;&gt;Generalized Speeds&lt;/h3&gt;

&lt;p&gt;Generalized speeds are defined as linear combinations of the time derivative of the generalized coordinates. We define these both with the sum notation, and in matrix notation.&lt;/p&gt;

\[u_r= \sum_{s=1}^{n}{Y_{rs}{\dot{q}_s}+Z_r}\ \ \ \ \ \ r=(1,\ \ldots n)\]

\[u=Y\dot{q}+Z\]

&lt;p&gt;Thus, we can also invert the matrix expression to arrive at an expression for the kinematic differential equations as follows:&lt;/p&gt;

\[\dot{q}=Y^{-1}u-Y^{-1}Z\]

&lt;p&gt;Generalized speeds are useful because they give us the flexibility to simplify our expression for velocity. We define as many as are necessary to fully describe the problem.&lt;/p&gt;

&lt;h3 id=&quot;motion-constraints&quot;&gt;Motion Constraints&lt;/h3&gt;

&lt;p&gt;The motion constraints can be created by separating the generalized speeds into a series of dependent and independent generalized speeds. We denote the first 1 through p speeds as the independent speeds, and p+1 through n as the dependent speeds. The dependent speeds are linear combinations of the independent speeds. The number of independent speeds, p, is also referred to as the degrees of freedom.&lt;/p&gt;

\[u_1,u_2,\ldots,\ u_p,\ u_{p+1},\ldots,\ u_n\]

\[u_r=\ \sum_{s=1}^{P}{A_{rs}u_s+B_r}\ \ \ \ \ r=(p+1,\ \ldots,\ n)\]

&lt;p&gt;Motion constraints are referred to as “non-holonomic constraints”, but this is distinct from the “holonomic” constraints we used to define coordinate constraints (very confusing).&lt;/p&gt;

&lt;h3 id=&quot;partial-angular-velocities-and-partial-velocities&quot;&gt;Partial Angular Velocities and Partial Velocities&lt;/h3&gt;

&lt;p&gt;The partial angular velocities are defined as those that when multiplied by the generalized speeds produce the original angular velocity expression. Note that there is a remainder term at the end. There are (n) total partial angular velocities. When motion constraints are applied, there are only (p) partial angular velocities – one for every generalized speed.&lt;/p&gt;

\[{}^A\omega^B= [{}^A\omega_1 ^B,\ \ldots,\ {}^A\omega_n^B] \begin{bmatrix}u_1\\\ldots\\u_n\\\end{bmatrix}+w_t\]

\[{}^A\omega^B= [{}^A \tilde{\omega}_1^B,\ \ldots, {}^A \tilde{\omega}_p^B ]  \begin{bmatrix}u_1\\\ldots\\u_p\\\end{bmatrix} + \tilde{w}_t\]

&lt;p&gt;The partial velocities are defined in much the same way.&lt;/p&gt;

\[{}^A V^B= [{}^AV_1^B,\ \ldots,\ {}^AV_n^B ] \begin{bmatrix}u_1\\\ldots\\u_n\\\end{bmatrix} +V_t\]

\[{}^AV^B= [{}^A \widetilde{V}_1^B,\ \ldots,\ {}^A \widetilde{V}_p^B ] \begin{bmatrix}u_1\\\ldots\\u_p\\\end{bmatrix}+\widetilde{V}_t\]

&lt;p&gt;The partial angular velocities can be derived by using our previous definition of the angular velocity in terms of the basis vectors and their derivatives.&lt;/p&gt;

\[{}^A\omega^B=b_1(\dot{b_2}\bullet b_3)+b_2 (\dot{b_3}\bullet b_1 )+b_3 (\dot{b_1}\bullet b_2)\]

\[\frac{ ^AdV}{dt}= \begin{bmatrix}\frac{\partial V}{\partial q_1}&amp;amp;\ldots&amp;amp; \frac{\partial V}{\partial q_s}\\\end{bmatrix} \begin{bmatrix} \dot{q}_1\\\ldots\\\dot{q}_s\\\end{bmatrix} +\frac{^A\partial V}{\partial t}=\frac{\partial V}{\partial q}\dot{q}+\frac{^A\partial V}{\partial t}\]

\[\dot{q}=Wu+X\]

\[{}^A\omega^B=\left[b_1\frac{\partial b_2}{\partial q}\bullet b_3+b_2\frac{\partial b_3}{\partial q}\bullet b_1+b_3\frac{\partial b_1}{\partial q}\bullet b_2\right]\left(Wu+X\right)+\frac{^A\partial b_1}{\partial t}+\frac{^A\partial b_2}{\partial t}+\frac{^A\partial b_3}{\partial t}\]

\[{}^A\omega^B=\left[~\right]Wu+\left[~\right]X+\frac{^A\partial b_1}{\partial t}+\frac{^A\partial b_2}{\partial t}+\frac{^A\partial b_3}{\partial t}\]

&lt;p&gt;We now have an expression for the angular velocity which satisfies the format we’ve already defined for the partial angular velocities. Take care to notice everything that goes into the remainder term.&lt;/p&gt;

&lt;p&gt;But why define partial angular velocities at well? Well, in a full dynamics problem, we’ll frequently encounter a situation in which an applied force causes a resultant acceleration/velocity in one direction, but not in another. Partial velocities allow us to separate each F = ma statement by direction, greatly simplifying each equation.&lt;/p&gt;

&lt;h3 id=&quot;partial-acceleration-and-partial-velocities&quot;&gt;Partial Acceleration and Partial Velocities&lt;/h3&gt;

&lt;p&gt;This is basically the projection of accelerations into the partial velocities. Doing so, we’d see that it connects to the same result as in Lagrange’s Method. More info on this topic may come in the future.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Continuum Mechanics</title>
   <link href="https://ludavid15.github.io//continuumMechanics/"/>
   <updated>2021-05-11T00:00:00-07:00</updated>
   <id>https://ludavid15.github.io//continuumMechanics</id>
   <content type="html">&lt;p&gt;One of the common assumptions we make when working with fluids is that it forms a continuum. The individual atoms of a fluid are assumed to be tightly packed enough that we can approximate the collective molecular interactions. What are these collective molecular interactions? Well, pretty standard stuff actually. We assume that applying a force causes an object to move, or a body to deform. (Technically speaking, that stress is related to strain). And honestly well, that’s kinda it.&lt;/p&gt;

&lt;p&gt;The reason this assumption is so powerful is because it makes our model &lt;strong&gt;continuous&lt;/strong&gt;. This may seem pretty obvious at a glance, but working with stuff that is continuous is very different from working with stuff that is discrete! The reason as you may already have guessed: derivatives.&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;Alright, so what can we do with continuums? Well, how about mass, momentum, and energy conservation? Sounds easy enough. There are two ways to do this: with either a &lt;strong&gt;control mass&lt;/strong&gt; or &lt;strong&gt;control volume&lt;/strong&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Control Mass&lt;/strong&gt; We define a body/mass we are interested in and track how its momentum/energy changes over time. (Notice that by definition, the total mass remains constant)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Control Volume&lt;/strong&gt; We define a region of space, and take into account any mass/momentum/energy which flows in or out of this region.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;conservation-equations-for-1d-steady-inviscid-flow&quot;&gt;Conservation Equations for 1D Steady Inviscid Flow&lt;/h3&gt;

&lt;p&gt;Please note the assumptions required for these equations to be valid:&lt;/p&gt;

\[d(pu)=0\]

\[d(p+pu^2) = 0\]

\[d(h+\frac{1}{2}u^2)=0\]

&lt;h3 id=&quot;conservation-of-mass&quot;&gt;Conservation of Mass&lt;/h3&gt;

&lt;p&gt;Also known as continuity. Time rate of change of mass in the control volume (CV) is equal to the mass flux through the boundary. Or, in differential form, partial derivative of density plus mass flux is zero.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Integral&lt;/li&gt;
&lt;/ul&gt;

\[\frac{\partial}{\partial t}\iiint\rho dV=- \iint \rho u \bullet \hat{n} dA\]

&lt;ul&gt;
  &lt;li&gt;Conservative&lt;/li&gt;
&lt;/ul&gt;

\[\frac{\partial\rho}{\partial t}+\nabla\bullet\left(\rho u \right)=0\]

&lt;ul&gt;
  &lt;li&gt;Non-conservative&lt;/li&gt;
&lt;/ul&gt;

\[\frac{D\rho}{Dt}+\nabla\bullet\left(\rho u \right)=0\]

&lt;p&gt;For (quasi) 1-dimensional steady flow, the mass flow rate can be expressed as the following:&lt;/p&gt;

\[\dot{m}=\rho AV\]

&lt;p&gt;For 2D incompressible flow, we need to account for the velocity in two directions. Note that we assumed incompressibe, which results in the density term dropping out. In this case continuity is also just conservation of volume. It can be expressed as:&lt;/p&gt;

\[\frac{\partial u}{\partial x}+\frac{\partial v}{\partial y}=0\]

&lt;h3 id=&quot;conservation-of-momentum&quot;&gt;Conservation of Momentum&lt;/h3&gt;

&lt;p&gt;Time rate of change of momentum in the CV is equal to the advection term plus forces. Or in differential form, partial of momentum with respect to time plus advection term is equal to forces acting on the fluid element. Note that the right side of the equation is the substantial derivative. You may recognize these as the Navier-Stokes equations. Or another way of thinking about it, the Navier-Stokes equations are just a statement momentum conservation.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Integral&lt;/li&gt;
&lt;/ul&gt;

\[\frac{\partial}{\partial t}\iiint\rho udV=- \iint u \left(\rho u\bullet\hat{n}\right)dA-\iint\left(P\hat{n}\right)dA\]

&lt;ul&gt;
  &lt;li&gt;Conservative&lt;/li&gt;
&lt;/ul&gt;

\[\frac{\partial\rho u}{\partial t}+\left(\nabla\bullet\rho u  \right) u=-\nabla P+\rho g+\nabla\tau+F_{body}\]

&lt;ul&gt;
  &lt;li&gt;Non-conservative&lt;/li&gt;
&lt;/ul&gt;

\[\rho\frac{Du}{Dt}=-\nabla P+\rho g+\nabla\tau+F_{body}\]

&lt;h3 id=&quot;conservation-of-energy&quot;&gt;Conservation of Energy&lt;/h3&gt;

&lt;p&gt;Time rate of change is equal to advection term plus heat (both volumetrically and through the surface). Note that work done is encapsulated in the P/rho term in the advection integral. Or, the substantial derivative of total enthalpy is equal to time rate of change of pressure (work) and flux of heat. This is also a statement of the 1st law of thermodynamics. (Conservation of Energy).&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Integral&lt;/li&gt;
&lt;/ul&gt;

\[\frac{\partial}{\partial t}\iiint{\rho(e+\frac{1}{2}U^2)dV}=-\iint{\rho\left(e+\frac{P}{\rho}+\frac{1}{2}U^2\right)u\bullet\hat{n}dA}+\iiint{\rho\dot{q}dV}-\iint{\dot{q}^n\bullet\hat{n}dA}\]

&lt;ul&gt;
  &lt;li&gt;Conservative&lt;/li&gt;
&lt;/ul&gt;

\[\frac{\partial\rho e}{\partial t}+\nabla\bullet\left(u(\rho e+P)\right)=0\]

&lt;ul&gt;
  &lt;li&gt;Non-Conservative&lt;/li&gt;
&lt;/ul&gt;

\[\rho\frac{Dh_o}{Dt}=\frac{\partial P}{\partial t}+\rho\dot{q}\]

&lt;h3 id=&quot;conservative-vs-non-conservative-form&quot;&gt;Conservative vs Non-conservative Form&lt;/h3&gt;

&lt;p&gt;Conservative equations are valid over discontinuities in the fluid flow. These mathematical models directly stems from applying conservation of mathematical quantities within a control volume.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Is this related to the idea of a conservative vector field? I’m actually unsure, but I like the question.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Now consider the case where we take a derivative of a multivariable function. Mathematically, we can expand this derivative with the chain rule, but in doing so, we introduce terms that no longer describe a physical quantity. This is known as the non-conservative form. Most importantly, the non-conservative forms are not valid over discontinuities (i.e. shocks).&lt;/p&gt;

&lt;h3 id=&quot;euler-equations&quot;&gt;Euler Equations&lt;/h3&gt;

&lt;p&gt;The Euler equations represent conservation of momentum when viscous forces are neglected. This is also associated with the limit as Reynold’s number approaches infinity, and the regime of potential flow theory. In this regime, the no slip boundary condition cannot be applied, instead fluid flow at the wall is always tangential to the wall. The following equations have assumed incompressible flow:&lt;/p&gt;

&lt;h4 id=&quot;cartesian-coordinates&quot;&gt;Cartesian Coordinates&lt;/h4&gt;

\[x:\ \ \ \ \rho\left[\frac{\partial u}{\partial t}+u\frac{\partial u}{\partial x}+v\frac{\partial u}{\partial y}+w\frac{\partial u}{\partial z}\right]=-\frac{\partial P}{\partial x}+\rho g_x\]

\[y:\ \ \ \ \rho\left[\frac{\partial v}{\partial t}+u\frac{\partial v}{\partial x}+v\frac{\partial v}{\partial y}+w\frac{\partial v}{\partial z}\right]=-\frac{\partial P}{\partial x}+\rho g_y\]

\[z:\ \ \ \ \rho\left[\frac{\partial w}{\partial t}+u\frac{\partial w}{\partial x}+v\frac{\partial w}{\partial y}+w\frac{\partial w}{\partial z}\right]=-\frac{\partial P}{\partial x}+\rho g_z\]

&lt;h3 id=&quot;navier-stokes&quot;&gt;Navier-Stokes&lt;/h3&gt;
&lt;p&gt;Navier-Stokes is a general statement of conservation of momentum. The form presented here includes forces due to pressure, gravity, and viscous forces, but neglects other types of forces. This form has also assumed constant density and viscosity.&lt;/p&gt;

&lt;h4 id=&quot;cartesian-coordinates-1&quot;&gt;Cartesian Coordinates&lt;/h4&gt;

\[x:\ \ \ \ \rho\left[\frac{\partial u}{\partial t}+u\frac{\partial u}{\partial x}+v\frac{\partial u}{\partial y}+w\frac{\partial u}{\partial z}\right]=-\frac{\partial P}{\partial x}+\rho g_x+\mu\left[\frac{\partial^2u}{\partial x^2}+\frac{\partial^2u}{\partial y^2}+\frac{\partial^2u}{\partial z^2}\right]\]

\[y:\ \ \ \ \rho\left[\frac{\partial v}{\partial t}+u\frac{\partial v}{\partial x}+v\frac{\partial v}{\partial y}+w\frac{\partial v}{\partial z}\right]=-\frac{\partial P}{\partial x}+\rho g_y+\mu\left[\frac{\partial^2v}{\partial x^2}+\frac{\partial^2v}{\partial y^2}+\frac{\partial^2v}{\partial z^2}\right]\]

\[z:\ \ \ \ \rho\left[\frac{\partial w}{\partial t}+u\frac{\partial w}{\partial x}+v\frac{\partial w}{\partial y}+w\frac{\partial w}{\partial z}\right]=-\frac{\partial P}{\partial x}+\rho g_z+\mu\left[\frac{\partial^2w}{\partial x^2}+\frac{\partial^2w}{\partial y^2}+\frac{\partial^2w}{\partial z^2}\right]\]

&lt;h3 id=&quot;reynolds-transport-theorem&quot;&gt;Reynold’s Transport Theorem&lt;/h3&gt;

&lt;p&gt;States that the total time rate of change of an extensive property (B) for a system, depends on the rate of change of the intensive property in the control volume and the flux of that property through the control volume. (Extensive = mass dependent and Intensive = mass independent). In other works, it relates the control mass view of a fluid to the control volume view of a fluid.&lt;/p&gt;

\[\frac{DB_{sys}}{Dt}=\int_{cv}^{cv}\frac{\partial}{\partial t}(\rho b)dV+\int_{cs}^{cs}\rho b\left(\vec{v}\bullet\hat{n}\right)ds\]

&lt;h3 id=&quot;dimensional-analysis&quot;&gt;Dimensional Analysis&lt;/h3&gt;
&lt;p&gt;We can re-write an equation with normalized terms to see the relative magnitude of the different variables. For example, we can introduce a variable, keeping in mind to apply the chain rule when we take a derivative:&lt;/p&gt;

\[\widetilde{x}=\frac{x}{L}\]

\[\frac{\partial\widetilde{x}}{\partial t}=\frac{1}{L}\frac{\partial x}{\partial t}\]

&lt;p&gt;We can then make the following substitution into the original expression&lt;/p&gt;

\[\frac{\partial x}{\partial t}=L\ast\frac{\partial\widetilde{x}}{\partial t}\]

&lt;h3 id=&quot;bernoulli-equation&quot;&gt;Bernoulli Equation&lt;/h3&gt;

&lt;p&gt;Ah who doesn’t love Bernoullli’s equation. It’s so simple. We can derive Bernoulli’s equation from the conservation of energy equations (Euler equations already model adiabatic flow with no viscous forces). Assuming that the flow is also isentropic, steady, and irrotational, Euler’s equations simplify into:&lt;/p&gt;

\[P+\frac{1}{2}\rho U^2+gz=constant\]

&lt;p&gt;Ok, hold on, what are those assumptions again? Let’s just go over those one more time: isentropic, stready, irrotational, adiabatic, inviscid.&lt;/p&gt;

&lt;p&gt;Oh well.&lt;/p&gt;

&lt;p&gt;Unsteady Bernoulli’s (applicable for irrotational flow). Where the integral of ds is taken along a streamline.&lt;/p&gt;

\[\int\frac{\partial\left|v\right|}{\partial x}ds+\frac{1}{2}v^2+\int\frac{\partial P}{\rho}+gz=F(t)\]

&lt;h3 id=&quot;2d-potential-flow&quot;&gt;2D Potential Flow&lt;/h3&gt;
&lt;p&gt;Potential flow theory is the theory of inviscid fluid flow. This is also the limit where Reynold’s number tends to infinity. For two-dimensional inviscid flow, we can define the velocity components in terms of two other functions, the stream function and the potential function.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Irrotational Velocity Potential $\phi$ 	\(\nabla\times\vec{V}=0\)&lt;/li&gt;
  &lt;li&gt;Incompressible Stream Function $\psi$	\(\nabla\bullet\vec{V}=0\)&lt;/li&gt;
&lt;/ul&gt;

\[u=\ \frac{\partial\phi}{\partial x}= \frac{\partial\psi}{\partial y}\]

\[v=\ \frac{\partial\phi}{\partial y}=\ -\frac{\partial\psi}{\partial x}\]

\[u_r=\frac{\partial\phi}{\partial r}=\frac{1}{r}\frac{\partial\psi}{\partial\theta}\]

\[u_\theta=\frac{\partial\psi}{\partial r}=\frac{1}{r}\frac{\partial\phi}{\partial\theta}\]

&lt;p&gt;If either of the following is true, we can say that the fluid is both irrotational and incompressible.&lt;/p&gt;

\[\nabla^2\psi=0\]

\[\nabla^2\phi=0\]

&lt;p&gt;In assuming incompressibility, mass continuity reduces into a volume continuity equation, where density has dropped out:&lt;/p&gt;

\[Volume\ Continuity:\ \ \ \nabla\bullet V=\ \frac{\partial u}{\partial x}+\frac{\partial v}{\partial y}=0\]
</content>
 </entry>
 
 <entry>
   <title>Finally Getting to Dynamics</title>
   <link href="https://ludavid15.github.io//dynamicalEquations/"/>
   <updated>2021-05-11T00:00:00-07:00</updated>
   <id>https://ludavid15.github.io//dynamicEquations</id>
   <content type="html">&lt;p&gt;We’re almost ready to write down F = ma, but before that, we need to define what F is (a force), and what ma is (an inertial term).&lt;/p&gt;

&lt;!--more--&gt;

&lt;h3 id=&quot;resultant&quot;&gt;Resultant&lt;/h3&gt;
&lt;p&gt;The resultant is defined as the sum of force vectors. Useful for consolidating a number of forces into a singular equivalent one.&lt;/p&gt;

&lt;h3 id=&quot;bound-vector&quot;&gt;Bound Vector&lt;/h3&gt;
&lt;p&gt;A bound vector contains a direction, magnitude, or well-defined point. A bound vector may also exist on a line of action.&lt;/p&gt;

&lt;h3 id=&quot;moment-about-a-point&quot;&gt;Moment about a Point&lt;/h3&gt;
&lt;p&gt;The moment about a point due to a bound vector is defined as the cross product of any position vector from the point to the line of action with the force vector. Only defined for bound force vectors.&lt;/p&gt;

\[M^{F/P}=P^{O/P}\times F\]

&lt;p&gt;Where P is the point about which we’d like to take the moment, and O is a point on the line of action. The superscript on M denotes that this is the moment about point P due to a force F.&lt;/p&gt;

&lt;h3 id=&quot;shift-theorem&quot;&gt;Shift Theorem&lt;/h3&gt;
&lt;p&gt;If we know the moment about a point Q due to a set of forces S with resultant RS, and the position vector from Q to another point P, we can calculate the moment about the point P due to the set of forces RS as:&lt;/p&gt;

\[M^{S/P}=M^{S/Q}+P^{Q/P}\times R^S\]

&lt;h3 id=&quot;couples&quot;&gt;Couples&lt;/h3&gt;
&lt;p&gt;A couple is a set of vectors whose resultant is zero&lt;/p&gt;

&lt;h3 id=&quot;torque&quot;&gt;Torque&lt;/h3&gt;
&lt;p&gt;A torque is the moment of a couple. Torques are constant regardless of the point around which a moment is calculated, due to the nature of couples and how moments are defined. This can be proved via the shift theorem, by simply setting the resultant equal to zero.&lt;/p&gt;

&lt;h3 id=&quot;generalized-active-force&quot;&gt;Generalized Active Force&lt;/h3&gt;
&lt;p&gt;The set of generalized active forces are those which are important for determining the dynamics of the problem. The generalized active forces are the set of forces acting on a point dotted with the partial velocities of that point. Recall that there are non-holonomic and holonomic partial velocities, and thus there are likewise non-holonomic and holonomic active forces.&lt;/p&gt;

\[F_r=\sum_{i=1}^{v}{ ( ^A V)^P\bullet R^P}\ \ \ \ \ \ \left(r=1,\ \ldots,\ n\right)\]

\[\widetilde{F_r}=\sum_{i=1}^{v}({}^A \widetilde{V})^P\bullet R^P\ \ \ \ \ \ (r=1,\ \ldots,\ p)\]

&lt;p&gt;These two forces are also related using the definition of non-holonomic partial velocities.&lt;/p&gt;

\[\widetilde{F_r}=F_r+\sum_{s=p+1}^{n}{F_sA_{sr}}\ \ \ \ (r=1,\ \ldots,\ p)\]

&lt;p&gt;Similar to active forces, active torques and moments are defined by dotting with the partial angular velocity of that body.&lt;/p&gt;

\[(F_r)_B=R\bullet{_\ ^A V}^Q+T\bullet{ ^A\omega}_r^B\]

&lt;h3 id=&quot;non-contributing-forces&quot;&gt;Non-contributing Forces&lt;/h3&gt;

&lt;p&gt;These types of forces do not act as part of the set of active forces. There are 4 conditions which allow us to determine which forces are non-contributing.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Forces exerted on a system S across smooth surfaces of bodies in contact with S, where smooth implies no friction.&lt;/li&gt;
  &lt;li&gt;Internal forces between rigidly connected particles of S.&lt;/li&gt;
  &lt;li&gt;If B (of S) rolls without slipping on B’ (not a part of S), then all forces exerted by B’ on B are non-contributing&lt;/li&gt;
  &lt;li&gt;Forces exerted between B and B’ (both considered a part of S) are non-contributing.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;equivalent-replacement&quot;&gt;Equivalent Replacement&lt;/h3&gt;
&lt;p&gt;Given a set of forces acting on a rigid body, we define an equivalent replacement force and torque for the system, where the force is the resultant of all the force vectors and acts through point Q, and P is a position vector from Q to the original point of force application.&lt;/p&gt;

\[R=\sum F\]

\[T=\sum{P\times F}\]

&lt;h3 id=&quot;generalized-inertia-forces&quot;&gt;Generalized Inertia Forces&lt;/h3&gt;
&lt;p&gt;These are the equivalent term given to the idea of inertia (mass x acceleration). For particles, they are defined as the partial velocity dotted with the mass times acceleration.&lt;/p&gt;

\[F_R^\ast=\sum{V_r^P\bullet R_i^\ast}\]

\[R_i^\ast=-m_i{ ^A a}^P\]

&lt;p&gt;The equation is slightly different for rigid bodies, since we have to take into consideration the contributions due to angular acceleration.&lt;/p&gt;

\[F_R^\ast=V_r^P\bullet R_\ ^\ast+{^A\omega}_r^B\bullet T^\ast\]

\[R_i^\ast=-M_\ { ^A a}^B\]

\[T^\ast=-\sum{mr\times}{ ^A \alpha}_r^P\]

&lt;p&gt;Where r is the position vector from body B to point P.&lt;/p&gt;

&lt;h3 id=&quot;dynamical-equations&quot;&gt;Dynamical Equations&lt;/h3&gt;

&lt;p&gt;The dynamical equations are the equivalent of stating Newton’s second law, F = ma. These equations simply state that the generalized active forces plus the generalized inertia forces is equal to zero. These are generally integrated alongside the kinematic differential equations to find the state variables.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Viscous Flow</title>
   <link href="https://ludavid15.github.io//viscousFlow/"/>
   <updated>2021-05-10T00:00:00-07:00</updated>
   <id>https://ludavid15.github.io//viscous</id>
   <content type="html">&lt;p&gt;Unlike solids, fluids deform constantly under stress (in other words, a fluid &lt;strong&gt;flows&lt;/strong&gt;). How it flows is very much dependent on it’s &lt;strong&gt;viscosity&lt;/strong&gt;.&lt;/p&gt;

&lt;p class=&quot;message&quot;&gt;
Viscosity is to fluids what the modulus of elasticity is to solids. It relates the stress (amount of force) to strain (amount of deformation). Qualitatively, viscosity is a measure of a fluid&apos;s resistence to flowing. Things like honey have a very high viscosity, while air and water have comparatively lower viscosity. 
&lt;/p&gt;

&lt;p&gt;Viscous flow then, is the study of how a fluid’s viscosity affects its behavior. Viscous flow covers topics like boundary layers, low-speed flows, and small-scale flows. Coincidentally, the regimes in which viscous forces dominate is often incompressible, but this is not a hard and fast rule.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h3 id=&quot;viscosity&quot;&gt;Viscosity&lt;/h3&gt;

&lt;p&gt;The viscosity of a fluid $\mu$ defines the relationship between stress and strain. In most cases, we assume that the fluid is a Newtonian Fluid, meaning its stress and strain are related linearly. Here it is in two dimensions:&lt;/p&gt;

\[\tau=\mu\left(\frac{\partial u}{\partial y}+\frac{\partial v}{\partial x}\right)\]

\[Friction\ Force=\mu\nabla^2\vec{V}=\nabla\tau\]

&lt;p&gt;We can also define the second coefficient of viscosity as λ.&lt;/p&gt;

\[\xi=\lambda+\frac{2}{3}\mu\]

&lt;h3 id=&quot;reynolds-number&quot;&gt;Reynold’s Number&lt;/h3&gt;

&lt;p&gt;The ratio between viscous forces and inertial forces. The lower the Reynold’s number, the more dominant viscous effects become. The Reynold’s number can also show when a flow transitions from laminar to turbulent flow. Here, µ is the dynamic viscosity.&lt;/p&gt;

\[Re=\ \frac{\rho U_\infty L}{\mu}\]

&lt;p&gt;At very low Re, we get the Stokes equations. At very high Re, we get the Euler equations (potential flow theory).&lt;/p&gt;

&lt;h3 id=&quot;low-reynolds-number-flow-stokes-flow&quot;&gt;Low Reynold’s Number Flow (Stokes’ Flow)&lt;/h3&gt;

&lt;p&gt;This is the exact opposite regime of potential flow theory, in which viscous forces dominate over inertia forces. This is usually associated with low velocity, small scale, or highly viscous flows. Some applications can include:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Fully developed duct flow&lt;/li&gt;
  &lt;li&gt;Flow about immersed bodies (i.e. small particle dynamics)&lt;/li&gt;
  &lt;li&gt;Lubrication theory&lt;/li&gt;
  &lt;li&gt;Flow through porous media (mostly used for civil engineering)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Under the above assumption (i.e. very low Re), the momentum equation reduces to the following:&lt;/p&gt;

\[\nabla P\approx\mu\nabla^2V\]

&lt;h3 id=&quot;low-reynolds-number-flow-over-a-sphere&quot;&gt;Low Reynold’s Number Flow Over a Sphere&lt;/h3&gt;

&lt;p&gt;By solving stokes equations with the boundary conditions for viscous flow past a sphere (i.e. zero velocity at the wall), the following stream function can be calculated:&lt;/p&gt;

\[\psi=\frac{1}{4}Ua^2{sin}^2(\theta)\left[\frac{a}{r}-\frac{3r}{a}+\frac{2r^2}{a^2}\right]\]

&lt;p&gt;This can be compared to the stream function found by applying potential flow theory about a sphere (i.e. flow is tangent to the wall):&lt;/p&gt;

\[\psi=\frac{1}{2}Ur^2{sin}^2(\theta)\left[1-\frac{a^3}{r^3}\right]\]

&lt;p&gt;Solving the first equation for shear and pressure drag, we find an expression for the total drag on a sphere in the low Reynold’s number limit:&lt;/p&gt;

\[F=4\pi\mu Ua+2\pi\mu Ua\]

&lt;p&gt;Where the first term is the viscous contribution to drag, and the second term is the pressure contribution to drag. This is normalized by the area and dynamic pressure to find the drag coefficient.&lt;/p&gt;

\[C_d=\frac{2F}{\rho U^2\pi a^2}=\frac{24}{Re}\]

&lt;p&gt;This equation underpredicts drag for Reynold’s numbers larger than 1, since separation and wakes introduce greater pressure drag.&lt;/p&gt;

&lt;h3 id=&quot;steady-flow-between-infinite-plates&quot;&gt;Steady Flow between Infinite Plates&lt;/h3&gt;

&lt;p&gt;Another class of problem in which viscous forces dominate. We take the bottom plate to be stationary and assume some steady velocity for the top plate. There can also be a pressure gradient in the direction parallel to the plates. Due to viscosity, the motion of the top plate drags the top layer of fluid along with it. Eventually, some sort of velocity profile develops along this direction.&lt;/p&gt;

&lt;p&gt;In the limit that the top plate’s velocity tends to zero we get a Hagen-Poiseuille flow problem (the only thing that can drive the fluid forward is a pressure gradient). In the limit that the pressure gradient tends to zero we get a Couette flow problem (velocity of the top plate drives flow).&lt;/p&gt;

&lt;p&gt;The general solution of the velocity profile is expressed below. The first equation is the general solution, while the second equation takes the lower wall to be stationary. Where \(τ_o\) is the shear stress at the wall where y=0, and \(u_o\) is the velocity at the wall where y=0.&lt;/p&gt;

\[u\left(y\right)=\ -\frac{1}{2\mu}\left(-\frac{dP}{dx}\right)y^2+\frac{\tau_o}{\mu}y+u_o\]

\[u\left(y\right)=\ +\frac{1}{2\mu}\left(-\frac{dP}{dx}\right)y(h-y)+U\frac{y}{h}\]

&lt;p&gt;We can also solve for the volume flow rate per unit span by integrating over y.&lt;/p&gt;

\[Q=U\frac{h}{2}+\frac{h^3}{12\mu}\left(-\frac{dP}{dx}\right)\]

&lt;h3 id=&quot;unsteady-flow--infinite-plates&quot;&gt;Unsteady Flow &amp;amp; Infinite Plates&lt;/h3&gt;

&lt;p&gt;There are two problems within this category, known as Stokes 1st problem (an impulsively started plate) and Stokes’s 2nd problem (an oscillating plate). Unlike the previous problem, which solves for some steady state condition, these problems deal with transient situations.&lt;/p&gt;

&lt;h4 id=&quot;1st-problem&quot;&gt;1st Problem:&lt;/h4&gt;

&lt;p&gt;Stoke’s first problem covers the scenario of an impulsively started plate.&lt;/p&gt;

\[\frac{u(y,t)}{U}=1-erf{\left(\frac{\eta}{2}\right)}\]

\[erf{\left(x\right)}=\ \frac{2}{\sqrt\pi}\int_{0}^{x}{e^{-x^2}}dx\]

\[\eta=\ \frac{y}{\sqrt{\nu t}}\]

&lt;p&gt;As time increases, the penetration height will increase. At infinite time, the entire fluid moves with velocity U. The above solution represents a non-dimensionalized solution, where η represents the ratio of position to penetration height scaling.&lt;/p&gt;

&lt;h4 id=&quot;2nd-problem&quot;&gt;2nd Problem:&lt;/h4&gt;

&lt;p&gt;Motion of the bottom plate is defined as the following:&lt;/p&gt;

\[U\left(t\right)=\ U_o\cos(\omega t)\]

&lt;p&gt;The velocity profile above the plate and the stress at the wall can be solved to show the following:&lt;/p&gt;

\[u\left(y,t\right)=U_oe^{-y\sqrt{\frac{\omega}{2v}}}cos\left(\omega t-y\sqrt{\frac{\omega}{2v}}\right)\]

\[\tau_{wall}=\mu\frac{\partial u}{\partial y}=U_o\sqrt{\rho\mu\omega}sin\left(\omega t-\frac{\pi}{4}\right)\]

&lt;p&gt;The amplitude of the velocity oscillation decreases with distance from the plate. The ratio of viscosity to frequency determines the penetration height. Note that this ratio also affects a phase lead/lag, which changes with height, represented within the cosine term.&lt;/p&gt;

&lt;h2 id=&quot;pipes&quot;&gt;Pipes&lt;/h2&gt;

&lt;p&gt;Although infinite plates are useful for understanding some of the concepts, they aren’t exactly reflective of real life. What we do see plenty of though, is flow through pipes.&lt;/p&gt;

&lt;h3 id=&quot;hagen-poiseuille-circular-pipe-flow-model&quot;&gt;Hagen-Poiseuille Circular Pipe Flow Model&lt;/h3&gt;

&lt;p&gt;Pressure driven viscous pipe flow. Given L is the length of pipe, Q is the volume flow rate, and some known diameter, we can find the pressure drop. Assumes laminar flow.&lt;/p&gt;

\[∆P= 8μLQπR4\]

\[u\left(r\right)=\ -\frac{1}{4\mu}\left(-\frac{\partial P}{\partial x}\right)\left(r_o^2-r^2\right)\]

\[Q=\ \frac{\pi R^4}{8\mu}\left(\frac{\partial P}{\partial x}\right)\]

\[C_f=-\frac{\tau_w}{\frac{(1}{2})\rho{U_{ave}}^2}=\frac{16}{Re_D}\]

&lt;p&gt;Note that this may not be valid for short pipes, flow near the entrance, and fluids with low viscosity, or flow in a wide pipe. If flow is turbulent, you should switch over to the Darcy-Weisbach approach.&lt;/p&gt;

&lt;h3 id=&quot;more-realistic-pipe-flow-analysis&quot;&gt;More Realistic Pipe Flow Analysis&lt;/h3&gt;

&lt;p&gt;For flow (both laminar and turbulent) in a pipe of constant diameter D, we can express the pressure across a given length as:&lt;/p&gt;

\[\frac{∆P}{L}=f_d\frac{(1/2)ρU^2}{D}\]

&lt;p&gt;Where fd is the Darcy friction factor. In the laminar regime, the Darcy Friction factor is equal to \(\frac{f_D=64}{Re}\). For turbulent regime values, the friction factor is dependent on the surface roughness. Look up results in a Moody Diagram.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;To be inserted, Moody Diagram&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;More commonly, pressure loss per unit length is replaced with head loss per unit length, S, where head loss is calculated as:&lt;/p&gt;

\[∆h= ρg∆P\]

\[S=\frac{∆h}{L}=f_d\frac{1}{2g}\frac{V^2}{D}\]

&lt;p&gt;Note that the friction factor in the turbulent regime can be calculated with turbulent flow theory and is not simply an empiric fit!&lt;/p&gt;

&lt;h3 id=&quot;colebrook-interpolation-formula-turbulent--transition-regime&quot;&gt;Colebrook Interpolation Formula (Turbulent &amp;amp; Transition Regime)&lt;/h3&gt;

&lt;p&gt;Provides an easy way to find the friction factor for a given surface roughness and Reynold’s number. \(\Lambda\) here is the friction factor.&lt;/p&gt;

\[\frac{1}{\Lambda^{1/2}}\approx-2.0\log_{10}{\left(\frac{k/D}{3.7}+\frac{2.51}{Re_D\sqrt\Lambda}\right)}-0.8\]

&lt;h3 id=&quot;hydraulic-diameter&quot;&gt;Hydraulic Diameter&lt;/h3&gt;

&lt;p&gt;For non-circular pipes, an equivalent diameter can be found, known as the hydraulic diameter. This allows you to analyze the pipe as if it were circular.&lt;/p&gt;

\[\rho\left(\frac{\partial u_e}{\partial t}+u\frac{\partial u_e}{\partial x}\right)=-\frac{\partial P}{\partial x}\]

&lt;h2 id=&quot;boundary-layers&quot;&gt;Boundary Layers&lt;/h2&gt;

&lt;p&gt;Boundary layers are an incredibly important phenomena arising due to viscous forces. As before, we require that the velocity of the fluid at the wall is equal to the velocity of the wall. Only through BL analysis can we determine things like the lift, drag, and heat flux of objects moving through a fluid (such as a wing).&lt;/p&gt;

&lt;p&gt;For now, we’ll focus on laminar boundary layers, however, it is possible for something known as &lt;strong&gt;Boundary Layer Separation&lt;/strong&gt; to occur. When this happens, the fluid ceases to flow past objects in a nice smooth fashion, and trips into turbulent flow. This leads to the topic of &lt;strong&gt;Tubulent Boundary Layer&lt;/strong&gt;, which is a whole other beast.&lt;/p&gt;

&lt;h3 id=&quot;2d-boundary-layer-similarity-solutions&quot;&gt;2D Boundary Layer Similarity Solutions&lt;/h3&gt;

&lt;p&gt;In most cases, it is easier to create the following similarity variables, defined using the velocity potential:&lt;/p&gt;

\[u=\ \frac{\partial\psi}{\partial y}\]

\[v=-\frac{\partial\psi}{\partial x}\]

\[\psi\left(y,x\right)=\ U_\infty l\left(x\right)f(\eta)\]

\[\eta=\frac{y}{l(x)}=\frac{y}{x}\sqrt{\frac{Ux}{v}}=\frac{y}{x}\sqrt{Re}\]

\[l\left(x\right)\cong\ \sqrt{\frac{\nu x}{U_\infty}}\]

&lt;p&gt;Here, l(x) is proportional the height of the boundary layer, making η a normalized value for our position in the boundary layer. In addition, f(η) and η are both dimensionless. We should also be able to see that:&lt;/p&gt;

\[f\left(\eta\right)\cong \psi\]

\[f^\prime\left(\eta\right) \cong u,\ v\]

\[f^{\prime\prime}\left(\eta\right)\cong \tau\]

&lt;p&gt;Re-writing the Prandtl boundary layer equations in terms of our similarity variables, we find an exact solution:&lt;/p&gt;

\[\dddot{f}\left(\eta\right)+f\left(\eta\right)\ddot{f}\left(\eta\right)=0\]

&lt;h3 id=&quot;falkner-skan-2d-solution&quot;&gt;Falkner-Skan 2D Solution&lt;/h3&gt;

&lt;p&gt;The Falkner-Skan solution describes boundary layer flow over a wedge. It is a generalization of the Blasius flat plate boundary layer. Using the same similarity definition as above, the exact solution takes the following form. As with the Blasius solution, a numerical approach is required to find a solution.&lt;/p&gt;

\[\dddot{f}+f\ddot{f}+\beta(1+{\dot{f}}^2)=0\]

&lt;p&gt;The velocity in the free stream (i.e. ur in the direction of πB) can be represented by the following equation, as a function of the turning angle:&lt;/p&gt;

\[u_e=Kx^m\]

\[\beta=\frac{2m}{1+m}\]

&lt;p&gt;In the limiting case where B = 0, you get the Blasius flat plate general solution. In the limit that B = 1, you get stagnation point flow. There are tabulated values for the velocity thickness, displacement thickness, momentum thickness, and friction coefficient for a range of B values.&lt;/p&gt;

&lt;h3 id=&quot;blasius-solution-a-2d-flat-plate-1st-order-solution&quot;&gt;Blasius Solution a 2D Flat Plate (1st Order Solution)&lt;/h3&gt;

&lt;p&gt;The Blasius solution is an exact differential solution of the boundary layer equations for flow over a flat plate, however, solving it requires a numerical approach.&lt;/p&gt;

\[\frac{\delta}{x}=\frac{5}{\sqrt{Re}}\]

\[\frac{\delta^\ast}{x}=\frac{1.72}{\sqrt{Re}}\]

\[\frac{\theta}{x}=\frac{0.664}{\sqrt{Re}}\]

\[c_f=\frac{0.664}{\sqrt{Re}}\]

&lt;h3 id=&quot;approximate-solutions-to-2d-boundary-layer&quot;&gt;Approximate Solutions to 2D Boundary Layer&lt;/h3&gt;

&lt;p&gt;Thwaites method uses the Von-Karman integral equations to approximate the boundary layer characteristics. The Von Karman integral relation (steady flow with impermeable wall):&lt;/p&gt;

\[\frac{c_f}{2}=\frac{d\theta}{dx}+(2+H)\frac{\theta}{U}\frac{dU}{dx}\]

&lt;p&gt;This equation is still an exact relationship. Thwaites method is to make the following approximation: (where P(x) is any generic function of x, and is there to characterize the changes in the velocity profile shape in the boundary layer as a function of the x position)&lt;/p&gt;

\[u(x,y)\approx U\left(x\right)f(\eta,P\left(x\right))\]

&lt;p&gt;In the case of Thwaites method, the following parameter is defined:&lt;/p&gt;

\[\lambda=\left(\frac{\theta}{\delta}\right)^2\frac{\delta^2}{v}\frac{dU_e}{dx}=\frac{\theta^2}{v}\frac{dU_e}{dx}\]

&lt;p&gt;The Von-Karman integral relation can then be re-written, and we see that the terms of the original expression are going to be proportional to the parameter defined above.&lt;/p&gt;

\[\frac{\tau_w\theta}{\mu U}=\frac{U\theta}{v}\frac{d\theta}{dx}+(2+H)\frac{\theta^2U^\prime}{v}\]

\[\frac{\tau_w\theta}{\mu U}\approx Shear\ Factor\ Correlation=S(\lambda)\]

\[H=\ \frac{\delta^\ast}{\theta}\approx Shape\ Factor\ Correlation=H(\lambda)\]

&lt;p&gt;For an external flow problem, the following expression for momentum thickness can be derived:&lt;/p&gt;

\[\theta^2=\frac{0.45v}{U_e^6(x)}\int_{0}^{x}{U_e^5(x\prime)}dx\prime\]

&lt;p&gt;The displacement thickness can be solved by using the following shape factor correlation, as a function of λ.&lt;/p&gt;

\[\delta^\ast=\theta H\left(\lambda\right)\]

\[H\left(\lambda\right)=2+4.14z-83.5z^2+854z^3-3337z^4+4576z^5\]

\[z=0.25-\lambda\]

&lt;p&gt;The laminar boundary layer separates when λ = -0.09.&lt;/p&gt;

&lt;h3 id=&quot;pressure-gradient-effects&quot;&gt;Pressure Gradient Effects&lt;/h3&gt;

&lt;p&gt;There are three regimes for the pressure gradient term: favorable (less than zero), adverse (greater than zero), and neutral (equal to zero).&lt;/p&gt;

&lt;p&gt;An adverse pressure gradient can cause boundary layer separation. Separation occurs at the point where the wall shear stress is equal to zero (slope of the velocity profile is zero), that is:&lt;/p&gt;

\[\tau_w=\mu\frac{du}{dy}=0\]

&lt;h3 id=&quot;axis-symmetric-3d-boundary-layers&quot;&gt;Axis-Symmetric 3D Boundary Layers&lt;/h3&gt;

&lt;p&gt;The boundary layer equations for an axisymmetric steady flow without swirl can be shown to be equal to the following:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Axisymmetric steady flow without swirl:&lt;/strong&gt; in other words, flow only occurs in the radial or axial direction, and never in azimuth.&lt;/p&gt;
&lt;/blockquote&gt;

\[\frac{\partial(r_ou)}{\partial x}+r_o\frac{\partial v}{\partial y}=0\]

\[\rho\left(u\frac{\partial u}{\partial x}+v\frac{\partial u}{\partial y}\right)=\rho u_e\frac{\partial u_e}{\partial x}+\mu\frac{\partial^2u}{\partial y^2}\]

&lt;p&gt;The above equations can be transformed into an equivalent set of 2D boundary layer equations with the Mangler Transformation of the coordinate frame.&lt;/p&gt;

&lt;h3 id=&quot;fanno-flow&quot;&gt;Fanno Flow&lt;/h3&gt;

&lt;p&gt;Associated with one dimensional flow with friction. Friction tends to drive flow eventually towards sonic conditions, regardless of whether flow starts out subsonic or supersonic. Given conditions at a point (1) in a pipe, you can solve for the sonic conditions (*). If you then know something about conditions at another point (2), you can use the sonic conditions to backtrack and find all other properties at that second point. In a Fanno flow table, you will usually find the following relations:&lt;/p&gt;

\[M_1\ \ \ \ \ \frac{fL}{D}\ \ \ \ \ \frac{P}{P^\ast}\ \ \ \ \ \ \frac{T}{T^\ast}\ \ \ \ \ \ \frac{P_0}{P_0^\ast}\]

&lt;h3 id=&quot;rayleigh-flow&quot;&gt;Rayleigh Flow&lt;/h3&gt;

&lt;p&gt;Like Fanno flow, where heat addition tends to drive flow towards sonic conditions, regardless of initial velocity. Knowing heat input can allow you to find change in total temperature between two points. From there you can backtrack and solve for all other properties at those two points like how you would do it for Fanno flow.&lt;/p&gt;

\[T_{t,2}=\frac{q}{c_p}+T_{t,1}\]

&lt;h3 id=&quot;laminar-free-stream-shear-flow-jets-wakes-mixing-layers&quot;&gt;Laminar Free Stream Shear Flow (Jets, Wakes, Mixing Layers)&lt;/h3&gt;

&lt;p&gt;A class of problems involving a large unbounded region and either excess momentum (i.e. a jet or plume) or a momentum deficit (i.e. wake). This section will be completed at a later date.&lt;/p&gt;

&lt;h3 id=&quot;drag-acting-on-a-body-in-a-uniform-stream&quot;&gt;Drag Acting on a Body in a Uniform Stream&lt;/h3&gt;

\[D = \int{\rho u (U_{\infinity}-u)}dS\]
</content>
 </entry>
 
 <entry>
   <title>Compressible Flow</title>
   <link href="https://ludavid15.github.io//compressible/"/>
   <updated>2021-05-09T00:00:00-07:00</updated>
   <id>https://ludavid15.github.io//compressible</id>
   <content type="html">&lt;p&gt;While viscous flow deals with flows that are very slow, compressible flow is for your rockets and airplanes. In this Reynold’s number regime, the density of a fluid cannot assumed to be constant, but luckily we can ignore viscous effects.&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#stagnation-properties&quot; id=&quot;markdown-toc-stagnation-properties&quot;&gt;Stagnation Properties&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#waves&quot; id=&quot;markdown-toc-waves&quot;&gt;Waves&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#acoustic-wave-theory&quot; id=&quot;markdown-toc-acoustic-wave-theory&quot;&gt;Acoustic Wave Theory&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#method-of-characteristics&quot; id=&quot;markdown-toc-method-of-characteristics&quot;&gt;Method of Characteristics&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#shocks&quot; id=&quot;markdown-toc-shocks&quot;&gt;Shocks&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#normal-shocks&quot; id=&quot;markdown-toc-normal-shocks&quot;&gt;Normal Shocks&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#oblique-shocks&quot; id=&quot;markdown-toc-oblique-shocks&quot;&gt;Oblique Shocks&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#detached-shock&quot; id=&quot;markdown-toc-detached-shock&quot;&gt;Detached Shock&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#expansion-fans&quot; id=&quot;markdown-toc-expansion-fans&quot;&gt;Expansion Fans&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#prandtl-meyer-function&quot; id=&quot;markdown-toc-prandtl-meyer-function&quot;&gt;Prandtl-Meyer Function&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#reflections&quot; id=&quot;markdown-toc-reflections&quot;&gt;Reflections&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#interactions-of-shockwaves&quot; id=&quot;markdown-toc-interactions-of-shockwaves&quot;&gt;Interactions of Shockwaves&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#expansion-wave-interactions-method-of-characteristics&quot; id=&quot;markdown-toc-expansion-wave-interactions-method-of-characteristics&quot;&gt;Expansion Wave Interactions (Method of Characteristics)&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#compressible-boundary-layers&quot; id=&quot;markdown-toc-compressible-boundary-layers&quot;&gt;Compressible Boundary Layers&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#adiabatic-wall-temperature&quot; id=&quot;markdown-toc-adiabatic-wall-temperature&quot;&gt;Adiabatic Wall Temperature&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;One easy way to group topics in compressible flow is into 1D compressible flow, and everything else. This is because you’ll often find 1D compressible flow topics in an introductory fluid mechanics course.&lt;/p&gt;

&lt;h3 id=&quot;stagnation-properties&quot;&gt;Stagnation Properties&lt;/h3&gt;

&lt;p&gt;For any steady state fluid in motion, we can define stagnation/total properties. These reflect the actual values if the fluid were brought to rest isentropically.&lt;/p&gt;

\[\frac{T_{Total}}{T}=\ \left(\frac{P_{Total}}{P}\right)^\frac{\gamma-1}{\gamma}=\left(\frac{\rho_{Total}}{\rho}\right)^{\gamma-1}=1+\left(\frac{\gamma-1}{2}\right)M^2\]

&lt;p&gt;Note that the stagnation properties are frame dependent and thus not intrinsic thermodynamic properties.&lt;/p&gt;

&lt;h2 id=&quot;waves&quot;&gt;Waves&lt;/h2&gt;
&lt;p&gt;In the context of fluid dynamics, a wave is simply a disturbance which propagates. This disturbance can have many properties and effects on the fluid as it passes through:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;It can increase/decrease a property of the fluid (density, pressure, etc.)&lt;/li&gt;
  &lt;li&gt;It can change the velocity of the fluid&lt;/li&gt;
  &lt;li&gt;The magnitude of the change can be large or small&lt;/li&gt;
  &lt;li&gt;The shape of the disturbance can be continuous or discontinuous&lt;/li&gt;
  &lt;li&gt;It can be isentropic/increase entropy&lt;/li&gt;
  &lt;li&gt;It can propagate faster than the local acoustic speed or at the acoustic speed.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;By this definition, a shock is a type of wave. Although shocks are often introduced as “stationary” objects, this is because we have shifted our frame of reference such that this the case. A shock can be stationary (like at the inlet of a ramjet), or a shock can propagate (like out from an explosion).&lt;/p&gt;

&lt;p class=&quot;message&quot;&gt;
Another way to think of waves is as the propagation of information. Here&apos;s an example you might be familiar with: take a water droplet hitting the surface of a pond. Waves carry information about the event (the falling water) outwards. The speed at which the wave moves out is the speed at which this information is carried. 

Every fluid has a local &quot;acoustic speed&quot; or speed of sound. This is the maximum speed at which waves can propagate. So here&apos;s a question for you, what happens when a disturbing even (like an airplane) moves faster than the local speed of sound? 
&lt;/p&gt;

&lt;h3 id=&quot;acoustic-wave-theory&quot;&gt;Acoustic Wave Theory&lt;/h3&gt;

&lt;p&gt;An acoustic wave is the propagation of wave with small magnitude through a medium. This wave travels at the local acoustic speed of the medium and is adiabatic (i.e. the energy of the medium before and after the wave has passed through remains constant). 
Given the initial conditions about the displacement and rate, the solution for the propagation of that disturbance can be found (d’Alembert’s Formula).&lt;/p&gt;

\[∆p(x,t=0)=f(x)\]

\[\frac{∂∆p}{∂t}(x,t=0)=g(x)\]

\[∆p(x,t)=\frac{f(x)-a_∞t+f(x+a_∞t)}{2}+\frac{1}{2a_∞} \int_{x-a_∞t}^{x+a_∞t} gs \ ds\]

&lt;p&gt;The fundamental result is that the initial disturbance splits into a left running and right running portion. The fluid velocity, pressure and density can also be related to one another.&lt;/p&gt;

\[∆u= ±\frac{a_∞}{ρ_∞}∆ρ\]

\[∆ρ= ±\frac{1}{a_∞^2}∆P\]

\[∆ρ= ±\frac{1}{ρ_∞a_∞}∆P\]

&lt;p&gt;In deriving the above equation, we’ve assumed small amplitudes, meaning that the local speed of sound remains constant through the disturbance.&lt;/p&gt;

&lt;p&gt;If we remove this assumption, the local speed at which the disturbance propagates will be proportional to the magnitude and shape of the disturbance. This leads to finite strength waves and the method of characteristics.&lt;/p&gt;

&lt;h3 id=&quot;method-of-characteristics&quot;&gt;Method of Characteristics&lt;/h3&gt;

&lt;p&gt;Alright here’s where it get complicated. It turns out that when we no longer assume a constant speed of sound, the equations are a tad unsolvable as they are. To this end, mathemeticians have defined a way around this. Instead of solving the entire system for every point in space, we can define some &lt;em&gt;characteristic lines&lt;/em&gt;. We can apply a constraint (i.e. some property is constant along the line), and this gives us the final equation we need to solve the system. Then if we define many lines, we can nearly cover the entire region we are solving for. By applying constraints at their intersection points, we can solve a big system of equations and have an approximate solution to our problem.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1D Unsteady MOC&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;More details incoming!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2D Steady MOC&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;More details incoming!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Minimum Length Nozzle Calculation using MOC&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;With MOC, it is possible to design a nozzle such that the local curvature exactly cancels any incident expansion waves (these result from the diverging section right after the throat). 
 &lt;/p&gt;
&lt;h2 id=&quot;shocks&quot;&gt;Shocks&lt;/h2&gt;
&lt;p&gt;Shocks occur when objects travel faster than the acoustic speed of the fluid it’s in (speed measured relative to the fluid). This leads to a sudden discontinuity in the fluid’s properties as it transitions from supersonic to subsonic velocities.&lt;/p&gt;

&lt;h3 id=&quot;normal-shocks&quot;&gt;Normal Shocks&lt;/h3&gt;
&lt;p&gt;Across a normal shock: total temperature remains constant, total pressure decreases, but static pressure and static temperature increase. Density increases, speed decreases. 
Derivation of Normal Shock Equations:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Continuity Equation: 				\(\rho_1u_1=\rho_2u_2\)&lt;/li&gt;
  &lt;li&gt;Momentum Conservation Equation:		\({P_1+\rho}_1{u_1}^2=P_2+\rho_2{u_2}^2\)&lt;/li&gt;
  &lt;li&gt;Energy Conservation Equation		\(h_1+\frac{1}{2}u_1^2=h_2+\frac{1}{2}u_2^2\)&lt;/li&gt;
  &lt;li&gt;Ideal Gas Law					\(PV=nRT\)&lt;/li&gt;
  &lt;li&gt;Calorically Perfect Gas Assumption		\(h=\ C_pT\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The above represents 5 equations with 5 unknowns (assuming we know the properties at state 1, upstream of the shock). They can be solved to show the following equations:&lt;/p&gt;

\[\frac{P_2}{P_1}=1+\frac{2\gamma}{\gamma+1}\left(M_1^2-1\right)\]

\[\frac{T_2}{T_1}=\left[1+\frac{2\gamma}{\gamma+1}\left(M_1^2-1\right)\right]\left[\frac{2+(\gamma-1)M_1^2}{(\gamma+1)M_1^2}\right]\]

\[\frac{\rho_2}{\rho_1}=\frac{u_1}{u_2}=\frac{(\gamma+1)M_1^2}{2+(\gamma-1)M_1^2}\]

\[{M_2}^2=\frac{1+\frac{\gamma-1}{2}M_1^2}{\gamma M_1^2-\frac{\gamma-1}{2}}\]

&lt;p&gt; &lt;/p&gt;
&lt;h3 id=&quot;oblique-shocks&quot;&gt;Oblique Shocks&lt;/h3&gt;

&lt;p&gt;Supersonic flow over an angle. From the conservation equations, there are two equally valid solutions to an oblique shock problem, a strong solution and a weak solution. It is also possible that for a given combination of turning angle and incoming Mach number, there is no solution. Instead, the oblique shock becomes a detached or bow shock.&lt;/p&gt;

\[M_{n,1}=M_1\sin{\left(\sigma\right)}\]

\[M_2=\ \frac{M_{2n}}{\sin(\sigma-\delta)}\]

\[\tan{\left(\delta\right)}=2\cot(\sigma)\left[\frac{M_1^2{sin}^2\left(\sigma\right)-1}{M_1^2\left(\gamma+cos\left(2\sigma\right)\right)+2}\right]\]

&lt;p&gt;Unless there is some downstream flow feature to support the strong shock, the weak solution is typically what develops. 
The presence of a shock introduces a sudden change in the fluid properties, including pressure. This leads to the creation of wave drag.&lt;/p&gt;

&lt;p&gt;There are some important takeaways from the above figure.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;The red line denotes the maximum shock wave angle that is possible for a given incoming Mach number and deflection angle. If either one is increased while the other is kept constant, the shock will detach.&lt;/li&gt;
  &lt;li&gt;After a strong shock, the fluid is always subsonic.&lt;/li&gt;
  &lt;li&gt;fter a weak shock, the fluid can be either subsonic OR supersonic. This is the region bounded by the red and blue dotted lines.&lt;/li&gt;
  &lt;li&gt;The strong limit is the normal shock.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;detached-shock&quot;&gt;Detached Shock&lt;/h3&gt;

&lt;p&gt;The detached or bow shock is just an oblique shock problem in which a range of deflection angles (0 to 90 degrees) are present. At the centerline, fluid flow is perfectly perpendicular to the bow shock, and so it is treated as a normal shock. Traveling away from the center, the fluid flow has velocity partially parallel to the shock. This is equivalent to an oblique shock at some deflection angle. Infinitely far away, the deflection angle reaches 0 degrees and hence no shock develops.&lt;/p&gt;

&lt;p&gt;Notice that there are two regions behind the bow shock, a subsonic flow region, and a supersonic flow region. The dividing line between these two regimes is defined by the point along the bow shock where M2 = 1, or the blue dotted line in the figure above.&lt;/p&gt;

&lt;h3 id=&quot;expansion-fans&quot;&gt;Expansion Fans&lt;/h3&gt;
&lt;p&gt;The exact opposite of an oblique shock, in which the boundary curves away from the flow direction. An expansion fan is formed as a continuous spread of Mach/Acoustic waves, each providing some infinitesimal change to the fluid properties. Thus, flow through an expansion fan is isentropic.&lt;/p&gt;

&lt;h3 id=&quot;prandtl-meyer-function&quot;&gt;Prandtl-Meyer Function&lt;/h3&gt;
&lt;p&gt;The flow angle can be related to the local Mach number by applying continuity and conservation laws across an expansion wave. The resulting expression is the Prandtl-Meyer Function.&lt;/p&gt;

\[\theta_2-\theta_1=v\left(M_2\right)-v(M_1)\]

\[v\left(M\right)=\ \sqrt{\frac{\gamma+1}{\gamma-1}}arctan\sqrt{\frac{\gamma-1}{\gamma+1}(M^2-1)}-arctan\sqrt{M^2-1}\]

&lt;h3 id=&quot;reflections&quot;&gt;Reflections&lt;/h3&gt;

&lt;p&gt;At a solid boundary, waves reflect in a like manner. That is, a shock reflects as a shock, and an expansion wave reflects as an expansion wave. This maintains the kinematic constraint that flow near a wall must be parallel to it (i.e. no penetration).
At a free boundary, waves reflect in opposite manners. A shock reflects as an expansion wave, while an expansion wave reflects and converges as a shock. Across a free boundary, the pressure must be equal, and the flow in both regions must be parallel.&lt;/p&gt;

&lt;h3 id=&quot;interactions-of-shockwaves&quot;&gt;Interactions of Shockwaves&lt;/h3&gt;

&lt;p&gt;TBD&lt;/p&gt;

&lt;h3 id=&quot;expansion-wave-interactions-method-of-characteristics&quot;&gt;Expansion Wave Interactions (Method of Characteristics)&lt;/h3&gt;

&lt;p&gt;TBD&lt;/p&gt;

&lt;h2 id=&quot;compressible-boundary-layers&quot;&gt;Compressible Boundary Layers&lt;/h2&gt;

&lt;p&gt;The key feature of compressible boundary layers is that temperature and enthalpy changes cannot be decoupled from the velocity profile. Thus, even if the wall is adiabatic, the flow itself is neither adiabatic or isentropic (viscous dissipation). Consider the steady case where Prandtl number is equal to 1 (not a bad assumption with gases). This is also known as the Crocco-Busemann Relations.&lt;/p&gt;

\[\Pr{=\ \frac{\mu C_p}{k}}\]

&lt;p&gt;For an arbitrary pressure gradient, the temperature distribution takes the following form. This condition is satisfied for isentropic flow outside the boundary layer.&lt;/p&gt;

\[T=T_e\left[1+\frac{\gamma-1}{2}M_e^2\left(1-\frac{u^2}{U_e^2}\right)\right]\]

&lt;p&gt;For this scenario, the adiabatic wall temperature is equal to the stagnation temperature of the free stream. Recovery factor is 1.&lt;/p&gt;

&lt;p&gt;The second scenario is for zero pressure gradient.&lt;/p&gt;

\[T-T_w=\left(T_{oe}-T_w\right)\frac{u}{U_e}-\frac{u^2}{2C_p}\]

&lt;p&gt;The similar solution to the adiabatic wall temperature can be found for cases of Prandtl number larger than one with the following expression.&lt;/p&gt;

\[T_{aw}=T_e\left[1+\frac{\gamma-1}{2}\sqrt{Pr}M_e^2\right]\]

&lt;h4 id=&quot;adiabatic-wall-temperature&quot;&gt;Adiabatic Wall Temperature&lt;/h4&gt;

&lt;p&gt;This is the wall temperature for a fluid flow such that there is no net heat transfer into or out of the wall. If a system is let to run until equilibrium, this is the steady state temperature the immersed object will reach.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Turbulent Flow</title>
   <link href="https://ludavid15.github.io//turbulent/"/>
   <updated>2021-05-08T00:00:00-07:00</updated>
   <id>https://ludavid15.github.io//turbulent</id>
   <content type="html">&lt;p&gt;In general, turbulent flow is modeled statistically. Averages values are used instead of exact ones. Before laminar flow becomes fully turbulent, it experiences transition. Transition begins with flow instability. The point at which a flow trips into instability (critical point) is distinct from the point at which flow transitions fully to turbulence (transition point).&lt;/p&gt;

&lt;!--more--&gt;

&lt;h4 id=&quot;squires-law&quot;&gt;Squire’s Law&lt;/h4&gt;
&lt;p&gt;For two-dimensional parallel flow, the minimum critical unstable Reynold’s number occurs for a two-dimensional disturbance propagating in the same direction. Really all that this Law states is that a turbulence is tripped in the direction of disturbances.&lt;/p&gt;

&lt;h4 id=&quot;orr-sommerfeld-equation&quot;&gt;Orr-Sommerfeld Equation&lt;/h4&gt;
&lt;p&gt;The equation describing the velocity distribution of a two-dimensional disturbance propagating in the same direction as a two-dimensional parallel flow can found to be exactly:&lt;/p&gt;

\[\left(U-c\right)\left(\phi^{\prime\prime}-\alpha^2\phi\right)-U^{\prime\prime}\phi+i\frac{\mathbit{\nu}}{\alpha}\left(\phi^{\prime\prime\prime\prime}-2\alpha^2\phi^{\prime\prime}+\alpha^4\phi\right)=\ 0\]

\[\Psi\left(x,y,t\right)=\ \phi\left(y\right)exp\left(i\left[\alpha x-\beta t\right]\right)\]

\[c=\sfrac{\beta}{\alpha}\]

&lt;p&gt;Where U is the velocity of the free stream, α is the wavenumber, c is the wave speed, and the frequency, ω = αc. The primes denote differentiation with respect to y. This is a fourth order linear differential equation. Disturbances must vanish at walls and an infinity. The temporal growth and spatial growth of disturbances are functions of the following form:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Temporal: \(f\left(Re,\ \alpha,\ c_r,\ c_i\right)=0\)&lt;/li&gt;
  &lt;li&gt;Spatial: \(g\left(Re,\ \alpha_r,\ \alpha_i,\ \omega\right)=0\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Temporal neutral stability occurs when ci is equal to zero, while spatial neutral stability occurs for αi equal to zero. Instability begins at ci greater than zero. A full analytical solution of the Orr-Sommerfeld equation is non-trivial. In general, a non-dimensionalized version of the Orr-Sommerfeld equation can be written and can be plotted.&lt;/p&gt;

&lt;h4 id=&quot;wavenumber&quot;&gt;Wavenumber&lt;/h4&gt;

&lt;p&gt;The wavenumber is the waves per unit space. It is distinct from frequency, which is the waves per unit time.&lt;/p&gt;

&lt;h4 id=&quot;rayleigh-inviscid-stability-theory&quot;&gt;Rayleigh Inviscid Stability Theory&lt;/h4&gt;

&lt;p&gt;This is the limiting case where the viscous term in the Orr-Sommerfeld equation is neglected. In particular, the following five theorems are outlined:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;It is necessary for instability that the velocity profile have a point of inflection.&lt;/li&gt;
  &lt;li&gt;It is further necessary for instability that the numerical value of U’ of the vorticity be a maximum at the point of inflection.&lt;/li&gt;
  &lt;li&gt;If a point of inflection exists, it is further necessary that U’’(U-UPI) &amp;lt; 0 somewhere on the profile.&lt;/li&gt;
  &lt;li&gt;If U(y) possesses an inflection point, a neutral disturbance may exist who phase velocity is given by cr.
  The phase velocity of an amplified disturbance must always lie between the minimum and maximum values of U(y).&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;predicting-instability--transition-in-practice&quot;&gt;Predicting Instability &amp;amp; Transition in Practice&lt;/h4&gt;
&lt;p&gt;It was found that for many different profiles and conditions, the critical transition Reynold’s number seems to depend only on the shape factor. Thus, if the shape factor can be found, one can predict the point of instability and transition. 
Several models have been proposed to find an equivalent transition point. Wazzan uses a similar approach to instability and finds a transition Reynold’s number as a function of the shape factor. There is no universal curve that accounts for free stream turbulence.&lt;/p&gt;

&lt;h4 id=&quot;improving-stability&quot;&gt;Improving Stability&lt;/h4&gt;
&lt;p&gt;A favorable pressure gradient (decreasing pressure) delays the onset of instability, or in cases bring a flow back into stability. Boundary layers in gases are stabilized by cooling the wall, while boundary layers in liquids are stabilized by heating the wall.&lt;/p&gt;

&lt;h3 id=&quot;transition-to-turbulence&quot;&gt;Transition to Turbulence&lt;/h3&gt;
&lt;p&gt;The steps leading to fully developed turbulence are as follows:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Instability&lt;/li&gt;
  &lt;li&gt;Non-linear development waves (Tollmien-Schlichting Waves)&lt;/li&gt;
  &lt;li&gt;Three-dimensional instability and streamwise vortices&lt;/li&gt;
  &lt;li&gt;Formation of turbulent spots&lt;/li&gt;
  &lt;li&gt;Fully developed turbulence&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;reynolds-averaged-navier-stokes-equation-rans&quot;&gt;Reynolds-Averaged Navier Stokes Equation (RANS)&lt;/h3&gt;

&lt;p&gt;These are time averaged forms of the Navier-Stokes equations. Properties of the fluid are expressed in terms of an average and fluctuation term. An especially interesting result is the resultant equation for local stress.&lt;/p&gt;

\[\tau=\ \mu\left[\frac{\partial\bar{u}}{\partial\bar{y}}+\frac{\partial\bar{v}}{\partial\bar{x}}\right]-\rho\bar{u\prime v\prime}\]

&lt;p&gt;The first term is the laminar stress, while the second term is an equivalent turbulent “Reynolds Stress”. Importantly, note that it is independent of viscosity. This means that in regions dominated by the Reynold’s stress, viscosity of the fluid is unimportant.&lt;/p&gt;

&lt;h4 id=&quot;wall-bounded-turbulent-flow&quot;&gt;Wall Bounded Turbulent Flow&lt;/h4&gt;

&lt;p&gt;Near the wall, fluctuations must be near zero, so laminar contributions are more important. Away from the wall, turbulent stress dominates. The velocity profile from a wall then has three components, a viscous dominates inner layer, a turbulent dominated outer layer, and an overlap layer. First, we define the friction velocity:&lt;/p&gt;

\[v^\ast=\sqrt{\frac{\tau_w}{\rho}}\]

&lt;p&gt;The average velocity and position are also re-written.&lt;/p&gt;

\[u^+=\frac{\bar{u}}{v^\ast}\]

\[y^+=\frac{\rho v^\ast y}{\mu}\]

&lt;p&gt;The following is equation can then model the inner layer, overlap layer, and outer layer.&lt;/p&gt;

\[u^+=\frac{1}{k}\ln{\left(y^+\right)}+B+\frac{2\Pi}{k}f(\eta)\]

\[f\left(\eta\right)=\sin^2{\left(\frac{\pi}{2}\eta\right)}\]

&lt;p&gt;Where k and B are universal constants equal to 0.41 and 5.0 respectively. The first term captures the logarithmic relationship in the overlap section, while the second capture the diverging effect in the outer layer.&lt;/p&gt;

&lt;p&gt;Very, very near the wall, viscous and laminar forces dominate. The velocity profile in this region is linear and proportional to the wall stress. It is called the viscous sublayer.&lt;/p&gt;

\[\tau_w=\mu\frac{\bar{u}}{\bar{y}}\]

\[u^+=y^+\]

&lt;h4 id=&quot;turbulent-pipe-flow&quot;&gt;Turbulent Pipe Flow&lt;/h4&gt;

&lt;p&gt;Using the above model, you can actually derive an expression for the Darcy-friction factor from the flow equation. Note that this is for a smooth pipe, and so when possible, you should still reference a moody chart. In any case, the following is useful for seeing that the Darcy-Friction is not just an empirically derived fit.&lt;/p&gt;

\[\frac{1}{\Lambda^{1/2}}=2.0\log_{10}{\left({Re}_D\Lambda^\frac{1}{2}\right)}-0.8\]

&lt;p&gt;Notably the following trends come out:&lt;/p&gt;

\[\tau\approx0.0396\rho^{3/4}\mu^{7/4}D^{-1/4}{U_{avg}}^{7/4}\]

&lt;h4 id=&quot;turbulent-boundary-layers&quot;&gt;Turbulent Boundary Layers&lt;/h4&gt;

&lt;p&gt;Using the wall bounded turbulent model, the skin coefficient term can be approximated in terms of the boundary layer thickness Reynolds number. Meanwhile, the momentum thickness is evaluated by using a one-seventh power law profile taken from pipe flow data.&lt;/p&gt;

\[C_f=2\frac{d\theta}{dx}\]

\[\frac{\bar{u}}{U_e}\approx\left(\frac{y}{\delta}\right)^{1/7}\]

\[C_f\approx0.020{Re}_\delta^{-1/6}\]

\[{Re}_\delta\approx0.16{Re}_x^{6/7}\]

</content>
 </entry>
 
 <entry>
   <title>Non-Dimensional Numbers</title>
   <link href="https://ludavid15.github.io//fluidnumbers/"/>
   <updated>2021-05-07T00:00:00-07:00</updated>
   <id>https://ludavid15.github.io//reference</id>
   <content type="html">&lt;p&gt;Non-dimensional simply means unitless. Why unitless? Because we’re taking the ratio of two similar properties and comparing their relative magnitude.&lt;/p&gt;

&lt;p&gt;There’s a whole bunch of these, but here are the main ones that you might come across.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h4 id=&quot;reynolds-number&quot;&gt;Reynold’s Number&lt;/h4&gt;

\[\frac{\rho UL}{\mu}\]

&lt;p&gt;Ratio of viscous forces to inertia forces. Determines flow regime (Laminar, turbulent, etc.).&lt;/p&gt;

&lt;h4 id=&quot;mach-number&quot;&gt;Mach Number&lt;/h4&gt;

\[\frac{u}{a}\]

&lt;p&gt;Ratio of flow velocity to speed of sound. The higher the Mach number, the more irreversible the flow becomes.&lt;/p&gt;

&lt;h4 id=&quot;knudsen-number&quot;&gt;Knudsen Number&lt;/h4&gt;

\[\frac{\lambda}{L}\]

&lt;p&gt;Ratio of molecular mean free path to characteristic length. Determines transition from gas dynamics to continuum mechanics.&lt;/p&gt;

&lt;h4 id=&quot;prandtl-number&quot;&gt;Prandtl Number&lt;/h4&gt;

\[\frac{C_p\mu}{k}\]

&lt;p&gt;Ratio of momentum diffusivity to thermal diffusivity. This number relates the size of momentum to thermal boundary layers, or the ratio of convection to conduction.&lt;/p&gt;

&lt;h4 id=&quot;nusselt-number&quot;&gt;Nusselt Number&lt;/h4&gt;

\[\frac{hL}{k}\]

&lt;p&gt;Ratio of convective to conductive heat transfer. Since a fluid’s speed affects the convection coefficient, the Nusselt Number is very similar to the Prandtl number.&lt;/p&gt;

&lt;h4 id=&quot;stokes-number&quot;&gt;Stokes Number&lt;/h4&gt;

\[\frac{t_0 u_0}{l_0}\]

&lt;p&gt;Ratio of the characteristic time of a particle to a characteristic time of the flow. In other words, the effect of drag on a particle’s motion. On on extreme a particle’s motion follows the fluid streamlines and on the other extreme, it continues on its original trajectory.&lt;/p&gt;

&lt;h2 id=&quot;fluid-statics&quot;&gt;Fluid Statics&lt;/h2&gt;

&lt;p&gt;Forces always act perpendicular to the surface. Given atmospheric surface pressure (free surface) the pressure at a depth (h) will be:&lt;/p&gt;

\[P=\ \gamma h\]

&lt;p&gt;Where \(\gamma\) is the specific gravity of the liquid, (1 for water). For submerged plate of area, A, total resultant force is equal to:&lt;/p&gt;

\[F_r=\gamma h_cA\]

&lt;p&gt;Where hc is the depth of the centroid of the plate. This total force DOES NOT act through the centroid however, instead it acts at through a point where the total moment is equal to zero (center of pressure or can think of this as the centroid of the pressure distribution). If the plate is symmetric, this will coincide with the centroid. 
For curved surfaces, use the following force balance approach:&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Jet Engines</title>
   <link href="https://ludavid15.github.io//jetEngines/"/>
   <updated>2021-05-06T00:00:00-07:00</updated>
   <id>https://ludavid15.github.io//jets</id>
   <content type="html">&lt;p&gt;Alright, let’s talk about jet engines. Why are they everywhere? What’s the big deal? What happened to propellers!?&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;Before getting started, a few definitions that will be relevant:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;TSFC&lt;/strong&gt; - Thrust specific fuel consumption&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;SFC&lt;/strong&gt; - Specific fuel consumption&lt;/p&gt;

&lt;p&gt;For the sake of simplicity, jet engines can be analyzed as a quasi 1 dimensional system. In other words we only need to consider velocities in one direction. This makes our math much easier.&lt;/p&gt;

&lt;h3 id=&quot;fundamentals&quot;&gt;Fundamentals&lt;/h3&gt;

&lt;p&gt;Most of these equations are rooted by a fairly simple conservation of energy/momentum principle. Hence, we can expect to see a lot of energy (\(v^2\)) and momentum (\(\dot{m}v\)) terms&lt;/p&gt;

\[F_{uninstalled}=\dot{m_9}u_9-\dot{m_0}u_0-A_{exit}(P_9-P_0)\]

\[F_{gross}=\dot{m_9}u_9-A_{exit}(P_9-P_0)\]

\[\mathrm{TSFC}=\ \frac{\dot{m_f}}{T}=\frac{1}{g Isp_f}=\frac{f}{g Isp_{air}}\]

&lt;h3 id=&quot;combustion&quot;&gt;Combustion&lt;/h3&gt;

&lt;p&gt;Combustion is still the driving force behind all jet engines. The energy added to the air gets converted into kinetic energy by a nozzle, thereby producing thrust.&lt;/p&gt;

\[C_xH_y+\left(x+\frac{y}{4}\right)\left(O_2+{3.76N}_2\right)\leftrightarrow xCO_2+\left(\frac{y}{2}\right)H_2O+(x+\frac{y}{4})N_2\]

\[\phi=\ \frac{f}{f_{stoich}}\]

\[f_{stoich}=\ \frac{M_{Fuel}}{(x+\frac{y}{4})(M_{O2}+3.76M_{N2})}\]

&lt;p&gt;Combustion does not always happen to completion and fuels are not made of a singular type of hydrocarbon. This means that as equivalence ratio tends to 1, actual flame temperature is lower than the ideal value.&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Equivalence Ratio&lt;/td&gt;
      &lt;td&gt;Type of Combustion Environment&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;\(\phi&amp;lt;1\)&lt;/td&gt;
      &lt;td&gt;Fuel Lean&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;\(\phi=1\)&lt;/td&gt;
      &lt;td&gt;Stoichiometric&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;\(\phi&amp;gt;1\)&lt;/td&gt;
      &lt;td&gt;Fuel Rich&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;adiabatic-flame-temperature&quot;&gt;Adiabatic Flame Temperature&lt;/h3&gt;

\[Q_R=Energy\ gained\ in\ combustion=\sum{(nh_{f,\ products})}-\sum{(nh_{f,\ reactants})}\]

\[Q_R+{\sum{nc_p(T_2-T_f)}}_{Products}=\ {\sum{nc_p(T_1-T_f)}}_{Reactants}\]

&lt;p&gt;In other words, energy is released by combustion reaction, and this energy goes into heating up the products. Note that for the above equation we assume that cp does not vary with temperature (even though it does!).&lt;/p&gt;

&lt;h3 id=&quot;ideal-turbojet-cycle&quot;&gt;Ideal Turbojet Cycle&lt;/h3&gt;

&lt;p&gt;For each stage in a turbojet, we can abstract the relative change in temperature and pressure of air passing through. In this way, if we know the initial conditions of incoming air, we can easily find the temperature and pressure at any stage. Of note, we are comparing stagnation temperatures and stangation pressures (since this a measure of the “total” energy.)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/jetBasic.png&quot; alt=&quot;turbojet&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;Diffuser&lt;/td&gt;
      &lt;td&gt;Compressor&lt;/td&gt;
      &lt;td&gt;Burner&lt;/td&gt;
      &lt;td&gt;Turbine&lt;/td&gt;
      &lt;td&gt;Nozzle&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;π (Pressure Ratio)&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;\({\tau_c}^{\gamma/(\gamma-1)}\)&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;\({\tau_t}^{\gamma/(\gamma-1)}\)&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;τ (Temp Ratio)&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;\(\tau_c\)&lt;/td&gt;
      &lt;td&gt;\(\tau_b\)&lt;/td&gt;
      &lt;td&gt;\(\tau_t\)&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Where τ &amp;amp; π are defined as the ratio of stagnation temperatures and pressures across the stage. The relationship between pressure ratio and temperature ratio is established by assuming assumed isentropic processes. We also define a unique value called the recovery temperature/pressure ratio, which is the ratio of stagnation temperature/pressure to local temperature/pressure at station 0.&lt;/p&gt;

\[\frac{T_{t0}}{T_0}=1+\frac{\gamma-1}{2}M^2=\ \tau_r\]

\[\tau_\lambda=\tau_r\tau_c\tau_b=\frac{T_{t4}}{T_0}\]

&lt;p&gt;Note that for an ideal turbojet without an afterburner, the ratio of outlet state temperature to inlet temperature is the same as burner temperature ratio.&lt;/p&gt;

\[\tau_b=\frac{T_9}{T_0}\]

\[Isp_{air}=\ \frac{a_0M_0}{g}\left(\sqrt{\frac{\tau_b(\tau_r\tau_c\tau_t-1)}{\tau_r-1}}-1\right)=\frac{T}{\dot{m_0}g}\]

&lt;p&gt;Assuming all fuel is burned in combustor, where f is the fuel to air ratio.&lt;/p&gt;

\[f=\ \frac{c_pT_0}{Q_R}\tau_r\tau_c(\tau_b-1)\]

&lt;p&gt;Also, if turbine work is equal to compressor work:&lt;/p&gt;

\[\tau_r=\ \left[1-\frac{\tau_c-1}{\tau_c\tau_b}\right]\]

&lt;p&gt;\(Isp_{air}\) for an ideal turbojet can then be solved if we are given the recovery temperature ratio, compressor ratio and the maximum temperature at station 4 after the burner.&lt;/p&gt;

\[Isp_{air}=\ \frac{a_0M_0}{g}\left(\sqrt{\frac{1}{\tau_r-1}\left[\tau_\lambda\left(1-\frac{1}{\tau_r\tau_c}\right)-\tau_r(\tau_c-1)\right]}-1\right)\]

&lt;p&gt;We can also find the ratio of outlet to inlet velocity&lt;/p&gt;

\[\frac{u_9}{u_0}=\ \left(\frac{M_9}{M_0}\right)\sqrt{\frac{\gamma_9R_9T_9}{\gamma_0R_0T_0}}=\ \sqrt{\frac{\tau_b(\tau_r\tau_c\tau_t-1)}{\tau_r-1}}\]

&lt;p&gt;Which can be found by first realizing that the following holds true&lt;/p&gt;

\[\left(\frac{P_{t9}}{P_9}\right)^\frac{\gamma-1}{\gamma}=\frac{T_{t9}}{T_9}=\ \frac{T_0}{T_9}\tau_r\tau_d\tau_c\tau_b\tau_t\tau_n\]

&lt;h3 id=&quot;engine-efficiencies&quot;&gt;Engine Efficiencies&lt;/h3&gt;

&lt;p&gt;These are weights which represent the % of energy lost.&lt;/p&gt;

&lt;dl&gt;
  &lt;dt&gt;Propulsive Efficiency&lt;/dt&gt;
  &lt;dd&gt;
\[\eta_p=\frac{P_{prop}}{P_{KE}}\cong\frac{2\frac{u_o}{u_e}}{1+\frac{u_o}{u_e}}\]
  &lt;/dd&gt;
  &lt;dt&gt;Thermal Efficiency&lt;/dt&gt;
  &lt;dd&gt;
\[\eta_{th}=\frac{P_{KE}}{P_{in}}=\frac{\left\{\left(\dot{m_0}+\dot{m_f}\right)\frac{ u_e^2}{2}-\dot{m_0}\frac{ u_0^2}{2}\right\}}{\dot{m_f}Q_R}=1-\frac{T_9-T_0}{T_{t4}-T_{t3}}=1-\frac{1}{\tau_r\tau_c}\]
  &lt;/dd&gt;
  &lt;dt&gt;Total Efficiency&lt;/dt&gt;
  &lt;dd&gt;
\[\eta_0=\eta_{th}\eta_p=\frac{P_{Prop}}{P_{in}}=\ \frac{Thrust\ast u_0}{\dot{m_f}Q_R}\]
  &lt;/dd&gt;
&lt;/dl&gt;

&lt;h3 id=&quot;real-component-analysis&quot;&gt;Real Component Analysis&lt;/h3&gt;

&lt;p&gt;These efficiency terms calculate losses at each engine stage (since nothing can truly be 100% efficient in real life).&lt;/p&gt;

\[\eta_d=\ \frac{\left(\frac{P_{t2}}{P_0}\right)^\frac{\gamma-1}{\gamma}-1}{\frac{\gamma-1}{2}{M_0}^2}\]

\[\eta_c=\ \frac{\left(\pi_c\right)^\frac{\gamma-1}{\gamma}-1}{\tau_c-1}\]

\[\eta_b=\frac{c_pT_0}{Q_Rf}\tau_r\tau_c(\tau_b-1)\]

\[\eta_t=\ \frac{\left(\pi_c\right)^\frac{\gamma-1}{\gamma}-1}{\tau_c-1}\]

\[\eta_t=\ \frac{\left(NPR\frac{P_0}{P_9}\right)^\frac{\gamma-1}{\gamma}-\left(\pi_n\right)^\frac{\gamma-1}{\gamma}}{\left(NPR\frac{P_0}{P_9}\right)^\frac{\gamma-1}{\gamma}-1}\ \ \ \ \ \ \ \ \ \ \ \ NPR=\ \frac{P_{t5}}{P_0}\]

&lt;h3 id=&quot;ramjets&quot;&gt;Ramjets&lt;/h3&gt;

&lt;p&gt;Ramjets function like a turbojet, but do not include a turbine or compressor. Most of the original equations still apply. Set \(\tau_c= \tau_t=1\).&lt;/p&gt;

\[Isp_{air}=\ \frac{a_0M_0}{g}\left(\sqrt{\tau_b}-1\right)\]

\[TSFC=\frac{f}{a_0M_0}\left[\frac{1}{\sqrt{\tau_b}-1}\right]\]

&lt;p&gt;Note that ramjet combustors tend to operate at a higher equivalence ratio. This means that some fuel remains un-combusted, and thus we need to revisit certain assumptions we made about turbojets. In particular, we must use \(∆T_{equilibrium}\). This value will depend on initial temperature, and equivalence ratio.&lt;/p&gt;

&lt;p&gt;When considering a real ramjet, diffuser and nozzle are still largely adiabatic, but there is an associated drop in total pressure&lt;/p&gt;

&lt;h3 id=&quot;afterburners&quot;&gt;Afterburners&lt;/h3&gt;

&lt;p&gt;An afterburner is like attaching a ramjet to the back of a turbojet. Turbojet exhaust is combusted again, increasing thrust at the cost of efficiency.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/afterBurner.png&quot; alt=&quot;afterburner&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

\[\tau_b\tau_{ab}=\frac{T_9}{T_0}\]

\[Isp_{air}=\ \frac{a_0M_0}{g}\left(\sqrt{\frac{\tau_{ab}}{\tau_r-1}\left[\tau_\lambda\left(1-\frac{1}{\tau_r\tau_c}\right)-\tau_r(\tau_c-1)\right]}-1\right)\]

\[TSFC=\ \frac{1}{g{Isp}_{air}}\frac{c_pT_0}{\dot{Q_R}}\left[\tau_r\tau_c\left(\tau_b-1\right)+\tau_r\tau_c\tau_b\tau_t(\tau_{ab}-1)\right]\]

&lt;h3 id=&quot;turbofans&quot;&gt;Turbofans&lt;/h3&gt;

&lt;p&gt;A turbofan makes use of the turbine in a turbojet to generate shaft power which drives a ducted fan. It provides increased efficiency over a regular turbojet. Most commercial passenger planes fly with turbofan engines.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/turboFan.png&quot; alt=&quot;turboFan&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

\[\alpha=\ \frac{air\ flow\ rate\ through\ bypass\ cycle}{air\ flow\ rate\ through\ turbojet\ cycle}\]

\[Thrust=\ \dot{m_0}u_9+\alpha\dot{m_0}u_{19}-(1+\alpha)\dot{m_0}u_0\]

&lt;p&gt;Alpha is defined as the bypass ratio. Flow through the center should be treated like flow through the turbojet. Flow through the fan can be treated like flow through a compressor. Note that for the following equations we assume to interference in exhaust from the bypass and the turbojet.
Assume: Work absorbed by turbine = work done by compressor + work done by fan.&lt;/p&gt;

\[\dot{m_0}\left(h_{t3}-h_{t2}\right)+\ \alpha\dot{m_0}\left(h_{t13}-h_{t2}\right)=\ \eta_{mechanical}\dot{m_0}(1+f)\left(h_{t4}-h_{t5}\right)\]

\[\tau_t=1-\frac{\tau_r\left[\left(\tau_r-1\right)+\alpha(\tau_f-1)\right]}{\eta_{mechanical}(1+f)\tau_\lambda}\]

&lt;p&gt;If ideal, since no combustion occurs, T19 = T0.&lt;/p&gt;

\[Isp_{air}=\ \frac{a_0M_0}{g}\left[\frac{1+f}{1+\alpha}\left(\frac{u_9}{u_0}\right)+\frac{\alpha}{1+\alpha}\left(\frac{u_{19}}{u_0}\right)-1\right]\]

\[\frac{u_{19}}{u_0}=\ \left(\frac{M_{19}}{M_0}\right)\sqrt{\frac{\gamma_{19}R_{19}T_{19}}{\gamma_0R_0T_0}}\]

&lt;p&gt;As with a regular turbojet cycle, we can solve for the M19 and the ratio of temperatures by using the following setup. Notice that for an ideal scenario, the ratio of temperatures before and after the fan is 1, since no combustion occurs, thus you only need to find M19 using the relationships below.&lt;/p&gt;

\[\left(\frac{P_{t19}}{P_{19}}\right)^\frac{\gamma-1}{\gamma}=\frac{T_{t19}}{T_{19}}=1+\frac{\gamma-1}{2}{M_{19}}^2\]

\[(\frac{P_0}{P_{19}}\pi_r\pi_d\pi_{fan}\pi_n)^\frac{\gamma-1}{\gamma}=\frac{T_0}{T_{19}}(\tau_r \tau_{fan})\]

&lt;h3 id=&quot;turboprops&quot;&gt;Turboprops&lt;/h3&gt;

&lt;p&gt;Turboprops operate on a similar idea to turbofans, in that the turbine from the turbojet cycle drives a larger propeller out in front, which is ultimately responsible for generating most of the thrust. Unlike a turbofan, the blades do not spin in a duct. Notice that for this analysis we break the turbine into two parts, the first (4 to 4.5) drives the compressor, while the second (4.5 to 5) drives the propeller.&lt;/p&gt;

\[T_{prop}u_0=\ \dot{m_0}(1+f)\alpha\eta_{mechanical,\ LPT}\eta_{LPT}\eta_{gearbox}\eta_{propeller}(h_{t4.5}-h_{9s})\]

&lt;p&gt;Where LPT stands for low pressure turbine (which drives propeller)&lt;/p&gt;

\[Power\ Split:\ \alpha=\ \frac{h_{t4.5}-h_{t5s}}{h_{t4.5}-h_{9s}}\]

&lt;h3 id=&quot;inletsdiffusers&quot;&gt;Inlets/Diffusers&lt;/h3&gt;

&lt;p&gt;Shock Ramp Inlets take advantage of oblique shocks to achieve near isentropic compression and minimize drag.&lt;/p&gt;

\[\frac{\dot{m}}{A}=MP_t\sqrt{\frac{\gamma}{RT_t}}\left[1+\frac{\gamma-1}{2}M^2\right]^\frac{-\gamma-1}{2(\gamma-1)}\]

\[c_{pr}=\frac{P_2-P_1}{q_1}\]

&lt;p&gt;Starting Problem refers to the issue of how we can transition from subsonic to supersonic flow on a converging-diverging inlet. In general, it involves the questions of how to “swallow the shock”.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Overspeed – By increasing M0 the bow shock moves closer towards the inlet.&lt;/li&gt;
  &lt;li&gt;Kantrowitz Donaldson Inlet – fixed geometry CD inlet with an enlarged throat that places starting shock in the diverging section.&lt;/li&gt;
  &lt;li&gt;Variable Geometry Inlet – For maximum efficiency, starting shock should occur in the throat. Thus, throat begins initially enlarged to swallow the shock, and then closes to push the shock upstream closer to the throat.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;combustors&quot;&gt;Combustors&lt;/h3&gt;

&lt;p&gt;Law of mass action presents a way to calculate reaction rate. Equilibrium occurs when rate of products becoming reactants equals the rate of reactants becoming products.&lt;/p&gt;

\[r_{foward}=k_{forward}\left[A\right]^a\left[B\right]^b\]

\[K=\ \frac{k_{forward}}{k_{reverse}}=\frac{\left[C\right]^c\left[D\right]^d}{\left[A\right]^a\left[B\right]^b}\]

&lt;p&gt;Note that equilibrium constant can also be represented with partial pressure, or mole fraction.
Laminar Flame Speeds tend to be on the order of 0.1-3 m/s, which is much slower than flight speeds. To prevent blowout, flame holders are sometimes required to slow down the flow. These also exert a drag on the flow, resulting in the following equation:&lt;/p&gt;

\[\frac{P_{t4}}{P_{t3}}=\frac{\left(1+\gamma{M_4}^2\left(1-\frac{C_d}{2}\right)\right)}{\left(1+\gamma{M_4}^2\right)}\left[\frac{1+\frac{\gamma-1}{2}{M_4}^2}{1+\frac{\gamma-1}{2}{M_3}^2}\right]^\frac{\gamma}{\gamma-1}\]

&lt;h3 id=&quot;axial-compressors&quot;&gt;Axial Compressors&lt;/h3&gt;

&lt;p&gt;Compressors consist of multiple stages. Each stage involves 1 rotor, followed by 1 stator. Rotor drives the fluid, giving it angular velocity, and increases total pressure. Stator converts extra angular velocity into an increase in static pressure but does no work on the fluid itself. Multi-staging is necessary to avoid boundary layer separation in rotor (which faces an adverse pressure gradient). We’ll define the absolute fluid velocity as \(C\).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/rotAndStat.png&quot; alt=&quot;rotor and stator&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;dl&gt;
  &lt;dt&gt;Fluid Velocity Relative to Rotor&lt;/dt&gt;
  &lt;dd&gt;
\[W=C-U\]
  &lt;/dd&gt;
&lt;/dl&gt;

\[\tau=\ \dot{m}[r_2C_{\theta,2}-r_1C_{\theta,1}]\]

\[h_{t2}-h_{t1}=\ \omega[r_2C_{\theta,2}-r_1C_{\theta,1}]\]

&lt;p&gt;Assume that C1 = C3 and Cz remains constant from stage 1 through stage 3. For small changes in stage pressure, and where stage efficiency is all the same, stage efficiency nstage is approximately equal to polytrophic compressor efficiency etc.&lt;/p&gt;

\[\beta_1=\alpha_2\]

\[\beta_2=\alpha_1\]

\[\frac{P_{t3}}{P_{t1}}=\left[1+\eta_{stage}\frac{U\Delta C_\theta}{c_pT_{t1}}\right]^\frac{\gamma}{\gamma-1}\]

\[\frac{T_{t2}}{T_{t1}}=1+\frac{U^2}{c_pT_{t1}}\left[1+\frac{C_z}{U}\left(\tan{\left(\beta_2\right)}-\tan(\alpha_1)\right)\right]\]

&lt;p&gt;It is also useful to define unitless parameters to characterize axial compressor performance. Increasing the flow coefficient decreases total temperature rise and work contribution of the rotor.&lt;/p&gt;

&lt;dl&gt;
  &lt;dt&gt;Flow Coefficient&lt;/dt&gt;
  &lt;dd&gt;
\[\phi=\ \frac{C_z}{U}\]
  &lt;/dd&gt;
  &lt;dt&gt;Stage Loading Factor&lt;/dt&gt;
  &lt;dd&gt;
\[\psi= \frac{\Delta h_t}{U^2} = 1+\phi(\tan(\beta_2)-\tan(\alpha_1)\]
  &lt;/dd&gt;
&lt;/dl&gt;

&lt;h3 id=&quot;degree-of-reaction-for-compressor&quot;&gt;Degree of Reaction for Compressor&lt;/h3&gt;

&lt;p&gt;Define as the ratio of static enthalpy rise over the rotor to total static enthalpy change in the stage. Usually we try to design this number to be equal to 50%.&lt;/p&gt;

\[R=\ \frac{h_2-h_1}{h_3-h_1}\]

&lt;h3 id=&quot;axial-turbines&quot;&gt;Axial Turbines&lt;/h3&gt;

&lt;p&gt;Calculations for an axial turbine is very similar to an axial compressor. In a turbine, a stator (or a nozzle) gives angular velocity to fluid flow, which drives the rotors. Since there is no adverse pressure gradient, fewer stages are needed.&lt;/p&gt;

\[R^o\ =1-\frac{C_{\theta2}-C_{\theta3}}{2U}\]

&lt;dl&gt;
  &lt;dt&gt;Impulse Stage&lt;/dt&gt;
  &lt;dd&gt;Entire static enthalpy drop happens over the stator/nozzle. Used when trying to minimize the number of stages (maximizing specific work per stage).&lt;/dd&gt;
  &lt;dt&gt;50% Degree of Reaction Stage&lt;/dt&gt;
  &lt;dd&gt;static enthalpy drop is split evenly between stator and rotor. Use to minimize losses and maximize isentropic efficiency.&lt;/dd&gt;
&lt;/dl&gt;

&lt;h3 id=&quot;component-matching&quot;&gt;Component Matching&lt;/h3&gt;

&lt;p&gt;With the above equations, we can enforce the following constraints which allow us to solve the combined equations:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Turbine Angular Shaft Speed = Compressor Angular Shaft Speed&lt;/li&gt;
  &lt;li&gt;Constant mass flow rate of air&lt;/li&gt;
  &lt;li&gt;Work extracted by turbine = work done by compressor&lt;/li&gt;
&lt;/ol&gt;
</content>
 </entry>
 

</feed>
