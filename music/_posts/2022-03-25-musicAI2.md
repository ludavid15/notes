---
layout: post
title: Music and AI - Part 2
permalink: /musicAI2/
mathjax: true
except_separator: <!--more-->
categories: music
---

This post explores a variety of tried and tested approaches to music generation with deep learning. Although each example can stand alone in theory, they are presented in an order that gradually introduces new concepts and challenges. As we go through each example, we will tag the challenges which apply to each one. 

1. *Creatio Ex nihilo*  (creation from nothing)
2. Length variability 
3. Content variability (i.e. is it deterministic?)
4. Expressiveness
5. Melody-harmony consistency
6. Control
7. Style transfer
8. Structure
9. Originality
10. Incrementality
11. Interactivity
12. Adaptability
13. Explainability 

### Example 1 - Introduction with Bach (1, 2, 3)

For the first example, we'll walk through a very simple and intuitive deep learning setup. Here are the parameters:

1. **Music Structure** - 4 measures of SATB in 4/4 time
2. **ML Architecture** - Feedforward neural network with 1 hidden layer
3. **Input** - (One hot encoding for pitch at each time step) x number of input voices
4. **Output** - (One hot encoding for pitch at each time step) x number of output voices
5. **Training Data** - Bach chorales, with each voice extracted and transposed into all keys.

Even before we consider the musical merit of any generated output, we can notice that there will be intrinsic limitations to this method. First, it is deterministic. For each unique input there will only ever be 1 output. Maybe this ok for something like this, but what if our input was a chord progression and our desired ouput was a melody? Many different melodies are possible for the same progression. Here we run into our first challenge - how can we generate a wide variety of content from limited inputs? (*creatio ex-nihilo* and content variability)

### Example 2 - Decoder Feedfoward (2, 3)

The basic idea here is to first train an autoencoder, which if you remember, learns the important "features" in its hidden layer. To generate unique outputs, we simply turn this around - the hidden layer becomes the input (i.e. a seed). The seed is fed-forward through the decoder, and we get a unique output. Of course this is still deterministic, but it overcomes the *creatio ex-nihilo* issue. (Technically we're not starting from *true nothing*, but then what does? Most randomly generated content, like a minecraft world, starts from a seed anyway). 

> The DeepHear system by Sun uses this approach to generate ragtime music. They use Scott Joplin songs as the training data, and a stacked autoencoder with a hidden layer size of 16. Due to the small size of this hidden layer, there is a high amount of plagiarism (around 60%).

### Example 3 - Sampling

