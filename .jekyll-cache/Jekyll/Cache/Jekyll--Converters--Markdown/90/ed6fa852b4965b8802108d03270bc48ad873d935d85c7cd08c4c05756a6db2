I"N_<p>At its core, machine learning is a <strong>statistical science</strong>, and like statistics, a great deal of care must be taken when formatting and analyzing data. They way we chose to quantify abstract topics and/or measure error will have a significant impact on the quality of our result.</p>

<p>This post lays a stronger mathematical foundation for machine learning, but if you are just looking for a high level overview of what machine learning is, I recommend reading this post on <a href="/notes/mlintroduction">how to think about machine learning</a>.</p>

<p>For a discussion of machine learning as a wandering exploration of linear algrebra, see the post on <a href="/notes/linearAlgebra">linear algebra</a>. In fact, I’d recommend starting on that page first! Matrices are the bedrock of machine learning.</p>

<!--more-->

<h2 id="part-1---basic-architectures">Part 1 - Basic Architectures</h2>

<blockquote>
  <p>On the linear algrebra post, we’ve talked a lot about what we can do with matrices, and we’ve done this because many problems can be solved without reaching for a neural network that has millions of weights which need to be optimized. Just something to keep in mind!</p>
</blockquote>

<h3 id="linear-regression">Linear Regression</h3>

<p>To start, let’s review the most basic type of machine learning problem - linear regression. The aim is to find a linear best-fit relationship between (x) and (y). Note that (x) can be a vector.</p>

\[h(x) = b + \theta_1x_1 + ... + \theta_nx_n = b + \sum_{i=1}^{n}theta_1x_i\]

<p>Where \(h\) is the model, $b$ is an offset, and the \(\theta\)’s are the weights to be learned.</p>

<p>Sometimes, the weights are represented by the character \(w\), which makes sense.</p>

<h3 id="k-means-clustering">K-Means Clustering</h3>

<p>Minimizes the intra-cluster variance. The strength of clustering algorithms lies in the fact that it is an unsupervised learning method, i.e., data does not have to come pre-labeled. The process goes:</p>

<ol>
  <li>Propose N cluster centers.</li>
  <li>Assign every pixel to the closest cluster center.</li>
  <li>Calculate new cluster centers using the average of assigned pixels.</li>
  <li>Repeat until centers have stabilized.</li>
</ol>

<p>For data classification, there typically needs to be as many dimensions as independent features (N) we’d like to distinguish. This means that for a task like image classification, we’ll need to find a way to transform a 2D image into a single point in 2D dimensional space.</p>

<h3 id="feed-forward-neural-networks">Feed Forward Neural Networks</h3>

<p>Networks are function approximators. Each node consists of any number of inputs and any number of outputs, but is itself a simple activation function (relu, sigmoid, tangent, etc.) These functions generally produce an output in the range of 0 to 1 or -1 to 1. For each node, there are a series of weights and offsets to be calculated/tuned by the learning process.</p>

<p><img src="../images/dnn.png" alt="deep neural net" class="center-image" /></p>

<p>The benefit of deep nets is that they can separate non-linear shapes, at the downside of long computation times and unreliable convergence of results. Also, results depend a lot on how error is measured, the function of each node, etc.</p>

<blockquote>
  <p>Back in the day, pre-training a neural network demonstrated that these could actually be trained efficiently, but since then other strategies have taken over. These include batch normalization and deep residual learning.</p>
</blockquote>

<h3 id="mathematical-fundamentals-for-nns">Mathematical Fundamentals for NN’s</h3>

<p>A neural network (deep or otherwise), can be broken down into this simple equation:</p>

\[y = h(x) = AF(b + Wx)\]

<p>Where $h(x) = y$ is the model to be trained, $b$ is some kind of offset (sometimes ignored), $W$ the set of weights to be calculated, $x$ the set of inputs, and $AF$ is some activation function. If this looks familiar, it’s because this is just a slightly modified linear regression! This mathematical basis should also reveal that neural networks are deterministic - the same input will always produce the same output!</p>

<p>But what purpose does the non-linear activation function serve? Well it turns out, without the non-linearity of the activation function, the composition of two linear functions is just yet another linear function. In other words, the activation function is ultimately what allows a NN to accomplish complex tasks.</p>

<p>Depending on the type of task we are training our Neural Network to do, there are different ways to encode our solution, which demand different types of activation functions, which demand different cost functions. These are outlined here:</p>

<table>
  <thead>
    <tr>
      <th>Task</th>
      <th>Output</th>
      <th>Target Encoding</th>
      <th>Activation Function</th>
      <th>Cost Function</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Regression</td>
      <td>Real</td>
      <td>Real</td>
      <td>Identity</td>
      <td>Mean squared error</td>
    </tr>
    <tr>
      <td>Classification</td>
      <td>Binary</td>
      <td>0,1</td>
      <td>Sigmoid</td>
      <td>Cross Entropy</td>
    </tr>
    <tr>
      <td>Classification</td>
      <td>Single Label</td>
      <td>One-hot</td>
      <td>Sigmoid</td>
      <td>Cross Entropy</td>
    </tr>
    <tr>
      <td>Classification</td>
      <td>Many Label</td>
      <td>Many-hot</td>
      <td>Softmax</td>
      <td>Cross Entropy</td>
    </tr>
  </tbody>
</table>

<p><strong>Consider:</strong> Why do we use one-hot encoding, and not just assign different numbers to things? For example, if we wanted to classify apples from bannanas from oranges, why can’t we use the labels 0, 1, 2?</p>

<p><strong>Answer:</strong> Numbers are in sequence, and when we encode three different objects as 0,1,2 we’ve accidently introduced the concept of order, where in reality there is none (sometimes).</p>

<h3 id="a-note-on-activation-functions">A Note on Activation Functions</h3>

<p>On hidden nodes, the ReLU or tanh function is almost always better than the sigmoid function.</p>

<p><strong>Sigmoid Function</strong></p>

<p>The sigmoid function ranges from 0 to 1:</p>

\[h(x) = \frac{1}{1-e^{-x}}\]

<p><strong>Rectified Linear Unit - ReLU</strong></p>

<p>Unlike the tanh or sigmoid function which approaches a slope of zero at the extremes, ReLU maintains a constant slope, which usually allows machine learning algorithms to converge faster.</p>

<p><strong>Tanh Function</strong></p>

<p>Hyperbolic tangent and unlike Relu or Sigmoid, this function ranges from -1 to 1.</p>

<p><strong>Softmax</strong></p>

<p>The Softmax functions converts a vector of numbers into a vector of probabilities which sum to one. (Good for a final layer when making predictions)</p>

<h3 id="overfitting">Overfitting</h3>

<p>Overfitting is a common issue of machine learning algorithms, where we increase the accuracy with respect to the training data, at the cost of decreased predictive accuracy. This exists because we expect some random error in the training data. When an algorithm is overfit, it tries to accomodate this random noise, and can lose track of the global trends.</p>

<p>An overfit model is also said to have high <strong>variance</strong>. A tell-tale sign of high variance is having low error on the training set, but high error on the dev or test set.</p>

<h3 id="receiver-operator-characteristic-curve">Receiver Operator Characteristic Curve</h3>

<p>The R.O.C plots the probability of correct classification vs the probability of false positive. In an ideal case, the area under the curve will be equal to 1. A random guesser achieves a straight line on this plot, so a classifier needs to beat this result. Placement along the curve is also important, and changes depending on the application.</p>

<p><img src="../images/roc.png" alt="roc curve" class="center-image" /></p>

<h3 id="embeddings">Embeddings</h3>

<p>Remember when we defined a one-hot encoding for our multi-classification tasks? One property of this method is that all encodings are equidistant from one another. This may be desireable sometimes, but in certain applications, this is not a good strategy. For example, in language processing, we’d like certain word pairs to be more closely associated than others (i.e. apple/orange vs apple/llama).</p>

<p>To solve this problem, we can use <em>embeddings</em> to represent distinct items. An embedding is a dense vector, where each dimension represents the “something-ness” of that class. For example, maybe the first dimension represents “animal-ness”, and the second represents “food-ness”.</p>

<p>In practice, these dimensions are not defined by us, but identified through an algorithm (duh!) and don’t always reflect concepts we know. To create embedding vectors for each label, first let’s define some variables:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>O_i     #one-hot vector representing word [i]
E       #embedding matrix of shape (n,m)
</code></pre></div></div>

<p>Where n is the dimension of our embedding vectors, and m is the number of words. Then the embedded representation can be calculated with:</p>

\[e_i = E \cdot O_i\]

<p>Next let’s frame the problem statement which will yield the embedding matric E. Given some context, we’d like to predict a target word to fit that context.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Inputs = e_1, e_2, e_3, ... e_7     //context
Outputs = e_t                       //target
</code></pre></div></div>

<p>The input and output can be connected using a basic feed forward network, maybe something like this</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>layer1 = Dense(100, 70, ReLU)
layer2 = Softmax
</code></pre></div></div>

<p>And finally, we initialize E with random variables, and allow the algorithm to train E along with the network.</p>

<blockquote>
  <p>It turns out, if we’re only trying to learn embeddings, we don’t need that much “context” - it can be as little as a single random word selected from nearby the target! More context tends to be required if we’re also trying to learn a language model (with grammer).</p>
</blockquote>

<h2 id="part-2---deep-learning-architectures">Part 2 - Deep Learning Architectures</h2>

<p>Deep learning algorithms are more powerful, but messier, versions of their linear algebra counterparts. A lot of optimization and more complex architectures are used to learn more abstract behaviors. A few common deep learning architectures are:</p>

<ol>
  <li>Feedforward NN’s</li>
  <li>Autoencoders</li>
  <li>Restricted Boltzman Machine</li>
  <li>Recurrent Neural Network</li>
</ol>

<h3 id="multi-layer-nn-aka-feedforward-neural-network">Multi-Layer NN aka Feedforward Neural Network</h3>

<p>A Feedforward neural network is also your classic “deep” learning network. It’s called deep because there are additional hidden layers between the input and output. In general, adding more layers is not the same as adding more nodes to an existing layer, and the relationship between the two is still being explored today. That being said, adding more layers tends to be more efficient than adding more nodes to existing layers.</p>

<h3 id="batch-normalization-for-deep-nns">Batch Normalization for Deep NN’s</h3>

<p>When we train a neural network, we tune each node with the assumption that everywhere else remains static. In truth, the entire set of weights are changed in each step. This can be problematic for training deep networks, because when we tune weights in the early layers, we drastically change the distribution of inputs into the deeper layers. In this sense, we can end up “chasing a moving target” (to quote Jason Brownlee).</p>

<p>The solution to this is called batch normalization. This simple idea is that we normalize the output of every layer (technically not the output, actually we normalize the input to the activation function). We then give this normalized distribution some trainable weight and bias, before it gets passed through.</p>

<h3 id="autoencoders">Autoencoders</h3>

<p>An autoencoders is a form of unsupervised learning. The goal is to compress and decompress information, which forces the algorithm to find key features to “encode” useful patterns. These can be implemented as a deep neural net, but one in which the output has the same dimension as the input. Additionally, the hidden layer(s) must have fewer nodes than either the input or output.</p>

<p>There are two flavors of autoencoders:</p>
<ul>
  <li>Regularized autoencoders, or sometimes called sparse autoencoders, are effective for classification tasks.</li>
  <li>Variational autoencoders use probability distributions instead of discrete variables, and are effective for generating new content.</li>
</ul>

<h3 id="restricted-boltzmann-machine-rbm">Restricted Boltzmann Machine (RBM)</h3>

<p>A restricted Boltzmann machine has two layers - a visible layer, and a hidden layer. Every node between the two layers are connected, but none of the nodes within a layer are connected.</p>

<p>The general idea behind a RBM is that there are hidden triggers which result in the data we see. The weights tie each cause (hidden layer) to each effect (visible layer). These result in probabilities, so we just have to tune our weights until the predicted probability of each event matches the probability distribution we see in our training data!</p>

<blockquote>
  <p>The words “trigger” and “result-in” are here to illustrate the idea, but in reality no causal relationship is being proven here! A more accurate version would be to say that there are hidden “indicators” which “correlate to” the data we see.</p>
</blockquote>

<p>One advantage to unsupervised learning with an RBM is that results can be obtained with only a few examples. Today, training is performed using an algorithm called <strong>constrastive divergence</strong>, which overcomes some of the scaling issues with RBM’s.</p>

<h3 id="recurrent-neural-networks-rnn">Recurrent Neural Networks (RNN)</h3>

<p>Before we jump into an RNN, consider a simple sentence generation program, which predicts the next word based only on the last word it encountered. Maybe the output looks something like this:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt; he drinks f("drinks")
&gt; he drinks water f("water")
&gt; he drinks water park f("park")
</code></pre></div></div>

<p>This is clearly limited because each prediction is made without the context of the rest of the sentence (“drinks” and “water” go together, as does “water” and “park”, but all three certainly do not make sense together!). Flip this around in terms of a learning algorithm and you can run into the same problem.</p>

<p>A recurrent neural networks is structured such that the output of a hidden layer is used as an additional input back into the same hidden layer. This allows them to learn based on the current AND previous state. But what does the previous state depend on? The state before that. So by recusion, an RNN learns on the entire sequence. Hence’s RNN’s are useful when data is temporal.</p>

<p>The output layer of an RNN is usually just the input layer but shifted by one step. Think about it with this example: If the sequence to be predicted by the RNN is ABCD, then for every step of the sequence, a trained RNN would generate:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>y(A) = AB
y(AB) = ABC
y(ABC) = ABCD
</code></pre></div></div>

<p>See how the input sequence can also act as the labeled output used in a supervised learning algorithm?</p>

<p class="message">
Long Short Term Memory is the preferred training algorithm for RNN's. This helps reduce amplification or minimization due to recursion (e.g. 2x2x2x2 grows very quickly, while 0.5 * 0.5 * 0.5 shrinks very quickly). LSTM's also solve the issue of long term memory. Even though a basic RNN should "in theory" be able to remember information from long ago, in practice they are unable to. 
</p>

<p>Also note, RNN’s can be bi-directional! This is good for natural language processing applications, where a word later in the sentence could be relevant to a word earlier in the sentence. The downside to a bi-directional RNN is that the complete sequence is required before an output can be created. This can be a problem for real-time applications.</p>

<h3 id="long-short-term-memory">Long Short Term Memory</h3>

<p>For this topic, I recommend reading colah’s blog post on <a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="noopener noreferrer">understanding LSTM’s</a>. He explains it much better than I can, plus he’s got pictures to go along with.</p>

<p>But in summary, within an LSTM there are two additional variables called the hidden state, and the cell state, which are used to carry long term, and short term signals respectively. A series of gates, like a forget gate and an update gate, determine how much these signals are modified at each step.</p>

<h3 id="attention-model">Attention Model</h3>

<p>An attention model is basically any model which includes an “attention parameter”. This is a learned variable which describes how “important” something is to something else.</p>

<p>A basic implementation of attention might look like this.</p>

<p><img src="../images/attentionmodel.png" alt="Attention Model" class="center-image" /></p>

<p>Where <strong>a</strong> is the activation output from a bi-directional RNN, and <strong>S</strong> is the state output from a forward only RNN. The input to each block <strong>S</strong> will be called the <em>context</em>, which is computed as the sum of attention weighted activations.</p>

\[c^{&lt;1&gt;} = \sum_{t=1} \alpha^{&lt;1,t&gt;} a^{&lt;t&gt;}\]

<p>Since alpha is a weighting term, it also makes sense to make sure the vector of alphas will sum to one, like with a softmax function. Now that’s all set up, the only remaining question is how to actually compute each attention parameter. Turns out, this can be done by training a small neural network.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Input = S_t_prev, a_t
Output = e_t
model = Dense(2, 1)
</code></pre></div></div>

<p>Keeping in mind that the output <code class="language-plaintext highlighter-rouge">e_t</code> needs to be passed through a softmax before we actually get alpha. By this point, you can probably tell that this is a lot of computation. The results are maybe better than something we could obtain with a simpler network, but this is a <em>quadratic</em> time algorithm (very costly!).</p>

<h3 id="convolutional-neural-networks">Convolutional Neural Networks</h3>

<p>The principle of a CNN is that a smaller matrix (aka, kernel, feature detector, filter), is passed over (i.e. convolved ) with the raw data. This is repeated over and over, and eventually passed through a fully connected layer (like in regular Neural Networks).</p>

<blockquote>
  <p>In a sense, convolutional networks juxtapose recurrent networks. Where RNN’s are deep, CNNs are shallow.</p>
</blockquote>

<p>The key to CNN’s is the kernel matrix. Different kernels can be trained to identify different “features” from the data, ranging from the very basic (e.g. an edge or a corner), to more advanced objects (e.g. an eye or a nose), and finally to the most high level (e.g. a face).</p>

<p>CNN’s are an effective tool for processing very large images, that would take up too much memory using a standard deep neural net.  This is accomplished by:</p>

<ol>
  <li>Parameter sharing - only a few filters of all the same parameters are used everywhere.</li>
  <li>Low connectivity - not every pixel depends on every other pixel, only its neighbors.</li>
</ol>

<h3 id="cnn-is-3d">CNN is 3D</h3>

<p>Although we think of images as 2D, there are actually three layers in a standard RBG layer, one for each color. This means that images are actually (h, w, d) matrices, and when we perform convolutions, our filters also need to be three-dimensional.</p>

<p>Because of how convolutions work, doing so shrinks the height and width of our image. To avoid this, we can add “padding” to the original image.</p>

<ul>
  <li>Valid - no padding</li>
  <li>Same - enough padding to keep original dimensions.</li>
</ul>

<p>The output image will have a number of channels equal to the number of filters we apply. So for instance, an input image that is (10, 10, 3), convolved with five filters that are (3, 3, 3), will produce an output of shape (8, 8,5 ), assuming that we did not add any padding.</p>

<h3 id="unit-or-pointwise-convolutions">Unit or Pointwise Convolutions</h3>

<p>Consider what happens when you use a (1x1) kernel. The output doesn’t get reduced in dimension, but the number of <em>channels</em> is changed depending on the number of kerenels. This type of convolution is often used to reduce the # of channels, and you can think of it as a channel-wise version of a pooling layer.</p>

<blockquote>
  <p>Pooling layers are “kernels” which use the function max or average. They are used to reduce the height and width of an input, but not the number of channels.</p>
</blockquote>

<h3 id="transpose-convolution">Transpose Convolution</h3>

<p>Tranpose convolution is the opposite of regular convolution. Instead of shrinking the dimension of an input image, we increase the dimension by multiplying each input by a filter/kernel. This type of CNN is used when we start with something small, and want to increase its size.</p>

<p>Segmantic segmention is one such application for this type of convolution. In segmentation segmention, we often start with a regular CNN to first shrink/identify the input, and then grow it out again to it’s original dimension for pixel classification.</p>

<h3 id="residual-connections">Residual Connections</h3>

<p>In a deep convolutional neural network, a residual connection (or sometimes called a “skip connection”) is a connection from an earlier layer, to a later layer. For instance, the input to layer 4 is usually the output from layer 3, but a residual connection means it might also receive the output from layer 1 or layer 2. In effect, residual connections allows us to train deeper networks!</p>

<blockquote>
  <p>These work sort of like bypass diodes in a solar panel, which provide a path for the current to continue flowing, even if the cell becomes faulty.</p>
</blockquote>

<h3 id="transformer-network">Transformer Network</h3>

<p>A transformer network is a CNN inspired, attention-based approach to natural language processing. In a transformer network, we do away with the recursive component all together, and instead play a game of “word association”.</p>

<h3 id="compound-architectures">Compound Architectures</h3>

<p>In recent years, many people have proposed combined approaches, which make use of more than one architecture. There is for instance, something called an RNN Encoder-Decoder, which attempts to learn the relationship between two different encodings of two different sequences.</p>

<p>Or to express it another way, the goal is to encode the sequence learned by one RNN into another sequence produced by another RNN. The main application here being translation, where two languages expressing the same idea can have entirely different lengths and grammers.</p>

<h3 id="generative-adversarial-modeling">Generative Adversarial Modeling</h3>

<p>A generative adversarial model, or GAN, is a method to train a generative modeling algorithm. GAN’s consist of two parts - a generative modeling program to create plausible examples, and a supervised learning/classification program that tries to distinguish the fake ones from the real ones. They are trained against one another (hence adversarial), until the classifier is no longer able to distinguish between the two.</p>

:ET