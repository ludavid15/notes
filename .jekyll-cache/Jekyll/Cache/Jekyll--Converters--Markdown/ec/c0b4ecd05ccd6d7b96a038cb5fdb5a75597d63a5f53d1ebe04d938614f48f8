I"d+<p>At its core, machine learning is a <strong>statistical science</strong>, and like most elements of statistics, a great deal of care must be taken when formatting and analyzing data. They way we chose to quantify abstract topics and/or measure error will have a significant impact on the quality of our result.</p>

<p>This article takes the traditional view of machine learning, where we organize the sub-disciplines by objectives and data structure. For a discussion of machine learning as a wandering exploration of linear algrebra, see the post on <a href="/notes/linearAlgebra/">linear algebra</a>. In fact, I’d recommend starting on that page first! Matrices are the bedrock of machine learning.</p>

<p>Or if you are just looking for a high level overview of what machine learning is, I recommend readying this post on <a href="/notes/howTomachineLearning/">how to think about machine learning</a>.</p>

<!--more-->

<h3 id="linear-regression">Linear Regression</h3>

<p>To start, let’s review the most basic type of machine learning problem is - linear regression. The aim is to find a linear best-fit relationship between (x) and (y).</p>

\[h(x) = b + \theta_1x_1 + ... + \theta_nx_n = b + \sum_{i=1}^{n}theta_1x_i\]

<p>Where \(h\) is the model, $b$ is an offset, and the \(\theta\)’s are the weights to be learned.</p>

<h2 id="section-2---machine-learning-algorithms">Section 2 - Machine Learning Algorithms</h2>

<p>So far we’ve talked a lot about what we can do with matrices, and the reason we’ve done this is because many problems can be solved without reaching for a neural network with billions of weights that need to be optimized. This section takes the more traditional approach to machine learning, where we divide algorithms according to their objectives.</p>

<ol>
  <li>Supervised Learning</li>
  <li>Unsurpervised Learning</li>
  <li>Reinforcement Learning</li>
</ol>

<h3 id="k-means-clustering">K-Means Clustering</h3>

<p>Minimizes the intra-cluster variance. The strength of clustering algorithms lies in the fact that it is an unsupervised learning method, i.e., data does not have to come pre-labeled. The process goes:</p>

<ol>
  <li>Propose N cluster centers.</li>
  <li>Assign every pixel to the closest cluster center.</li>
  <li>Calculate new cluster centers using the average of assigned pixels.</li>
  <li>Repeat until centers have stabilized.</li>
</ol>

<p>For data classification, there typically needs to be as many dimensions as independent features (N) we’d like to distinguish. This means that for a task like image classification, we’ll need to find a way to transform a 2D image into a single point in 2D dimensional space.</p>

<h3 id="neural-networks-and-deep-nets">Neural Networks and Deep Nets</h3>

<p>Networks are function approximators. Each node consists of any number of inputs and any number of outputs, but is itself a simple activation function (relu, sigmoid, tangent, etc.) These functions generally produce an output in the range of 0 to 1 or -1 to 1. For each node, there are a series of weights and offsets to be calculated/tuned by the learning process.</p>

<p><img src="../images/dnn.png" alt="deep neural net" class="center-image" /></p>

<p>The benefit of deep nets is that they can separate non-linear shapes, at the downside of long computation times and unreliable convergence of results. Results depend a lot on how error is measured, the function of each node, etc.</p>

<blockquote>
  <p>Back in the day, pre-training a neural network demonstrated that these could actually be trained efficiently, but since then other strategies have taken over. These include batch normalization and deep residual learning.</p>
</blockquote>

<h3 id="mathematical-fundamentals-for-nns">Mathematical Fundamentals for NN’s</h3>

<p>A neural network (deep or otherwise), can be broken down into this simple equation:</p>

\[y = h(x) = AF(b + Wx)\]

<p>Where $h(x) = y$ is the model to be trained, $b$ is some kind of offset (sometimes ignored), $W$ the set of weights to be calculated, $x$ the set of inputs, and $AF$ is some activation function. If this looks familiar, it’s because this is just a slightly modified linear regression! This mathematical basis should also reveal that neural networks are deterministic - the same input will always produce the same output!</p>

<p>Depending on the type of task we are training our Neural Network to do, there are different ways to encode our solution, which demand different types of activation functions, which demand different cost functions. These are outlined here:</p>

<table>
  <thead>
    <tr>
      <th>Task</th>
      <th>Output</th>
      <th>Target Encoding</th>
      <th>Activation Function</th>
      <th>Cost Function</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Regression</td>
      <td>Real</td>
      <td>Real</td>
      <td>Identity</td>
      <td>Mean squared error</td>
    </tr>
    <tr>
      <td>Classification</td>
      <td>Binary</td>
      <td>0,1</td>
      <td>Sigmoid</td>
      <td>Cross Entropy</td>
    </tr>
    <tr>
      <td>Classification</td>
      <td>Single Label</td>
      <td>One-hot</td>
      <td>Sigmoid</td>
      <td>Cross Entropy</td>
    </tr>
    <tr>
      <td>Classification</td>
      <td>Many Label</td>
      <td>Many-hot</td>
      <td>Softmax</td>
      <td>Cross Entropy</td>
    </tr>
  </tbody>
</table>

<h3 id="overfitting">Overfitting</h3>

<p>Overfitting is a common issue of machine learning algorithms, where we increase the accuracy with respect to the training data, at the cost of decreased predictive accuracy. This exists because we expect some random error in the training data. When an algorithm is overfit, it tries to accomodate this random noise, and loses track of the global trends.</p>

<h3 id="receiver-operator-characteristic-curve">Receiver Operator Characteristic Curve</h3>

<p>The R.O.C plots the probability of correct classification vs the probability of false positive. In an ideal case, the area under the curve will be equal to 1. A random guesser achieves a straight line on this plot, so a classifier needs to beat this result. Placement along the curve is also important, and changes depending on the application.</p>

<p><img src="../images/roc.png" alt="roc curve" class="center-image" /></p>

<h3 id="deep-learning-architectures">Deep Learning Architectures</h3>

<p>Deep learning algorithms are more powerful, but messier, versions of their linear algebra counterparts. A lot of optimization and more complex architectures are used to learn more abstract behaviors. A few common deep learning architectures are:</p>

<ol>
  <li>Feedforward NN’s</li>
  <li>Autoencoders</li>
  <li>Restricted Boltzman Machine</li>
  <li>Recurrent Neural Network</li>
</ol>

<h3 id="multi-layer-nn-aka-feedforward-neural-network">Multi-Layer NN aka Feedforward Neural Network</h3>

<p>A Feedforward neural network has also been referred to as a “deep” learning network, because there are additional hidden layers between the input and output. In general, adding more layers is not the same as adding more nodes to an existing layer, and the relationship between the two is still being explored today.</p>

<h3 id="autoencoders">Autoencoders</h3>

<p>An autoencoders is a type of unsupervised learning. The goal is to compress and decompress information, which forces the algorithm to find key features to “encode” useful patterns. These can be implemented as a deep neural net, but one in which the output has the same dimension as the input. Additionally, the hidden layer(s) must have fewer nodes than either the input or output.</p>

<p>There are two flavors of autoencoders:</p>
<ul>
  <li>Regularized autoencoders, or sometimes called sparse autoencoders, are effective for classification tasks.</li>
  <li>Variational autoencoders use probability distributions instead of discrete variables, and are effective for generating new content.</li>
</ul>

<h3 id="restricted-boltzmann-machine-rbm">Restricted Boltzmann Machine (RBM)</h3>

<p>A restricted Boltzmann machine has two layers - a visible layer, and a hidden layer. Every node between the two layers are connected, but none of the nodes within a layer are connected.</p>

<p>The general idea behind a RBM is that there are hidden triggers which result in the data we see. The weights tie each cause (hidden layer) to each effect (visible layer). These result in probabilities, so we just have to tune our weights until the predicted probability of each event matches the probability distribution we see in our training data!</p>

<blockquote>
  <p>The words “trigger” and “result-in” are here to illustrate the idea, but in reality no causal relationship is being proven here! A more accurate version would be to say that there are hidden “indicators” which “correlate to” the data we see.</p>
</blockquote>

<p>One advantage to unsupervised learning with an RBM is that results can be obtained with only a few examples. Today, training is performed using an algorithm called <strong>constrastive divergence</strong>, which overcomes some of the scaling issues with RBM’s.</p>

<p>Energy Equation</p>

\[E(v,h) = -a^Tv - b^Th - v^TWh\]

<h3 id="recurrent-neural-networks-rnn">Recurrent Neural Networks (RNN)</h3>

<p>Before we jump into an RNN, consider a simple sentence generation program, which predicts the next word based only on the last word it encountered. Maybe the output looks something like this:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt; he drinks f("drinks")
&gt; he drinks water f("water")
&gt; he drinks water park f("park")
</code></pre></div></div>

<p>This is clearly limited because each prediction is made without the context of the rest of the sentence (“drinks” and “water” go together, as does “water” and “park”, but all three certainly do not make sense together!). Flip this around in terms of a learning algorithm and you can run into the same problem.</p>

<p>A recurrent network networks is structured such that the output of a hidden layer is used as an additional input back into the same hidden layer. This allows them to learn based on the current AND previous state. But what does the previuos state depend on? The state before that. So by recusion, RNN’s learn on the entire sequence.</p>

<p>The output layer of an RNN is usually just the input layer but shifted by one step. Think about it with this example: If the sequence to be predicted by the RNN is ABCD, then for every step of the sequence, a trained RNN would generate:</p>

<p>A-&gt;AB, AB-&gt;ABC, ABC-&gt;ABCD, etc. See how the input sequence can also act as the labeled output used in a supervised learning algorithm?</p>

<p class="message">
Long Short Term Memory is the preferred training algorithm for RNN's. This helps reduce amplification or minimization due to recursion (e.g. 2x2x2x2 grows very quickly, while 0.5 * 0.5 * 0.5 shrinks very quickly).
<p>

### Convolutional Neural Networks





</p></p>
:ET