I"Ù-<p>In previous posts, we explored the field of dynamics, which taught us how to calculate the position, velocity, and acceleration of an object given a set of driving forces. The topic of control theory flips this process around, and seeks an answer to the question: what type of force will produce the desired motion?</p>

<p>In other words, if dynamics is the study of rules, controls is the study of how we use those rules to achieve results.</p>

<!--more-->

<h3 id="the-goals-of-control-theory">The Goals of Control Theory</h3>

<p>Let‚Äôs explore the above statement further. In dynamics, we‚Äôre usually given a system of parts, a set of forces \(f(x, t)\), and are asked to calculate \(x(t)\), \(v(t)\), and \(a(t)\). Now we could just as easily reverse this around (given, \(a(t)\), \(v(t)\), \(x(t)\), find \(f(t)\), but this doesn‚Äôt seem very interesting, nor is this really what control theory is.</p>

<p>The key idea that control theory introduces is of a <em>desired</em> motion or state, which we‚Äôll define with \(x'(t)\), \(v'(t)\), \(a'(t)\) (not be confused with derivatives). Thus, a better problem statement would be: find f(t) that minimizes error between our desired state and actual state.</p>

\[min | x(t) - x'(t) | + | v(t) - v'(t) | + | a(t) - a'(t) |\]

<p>This is a bit more realistic because ‚Äúclose‚Äù is way easier than exactly equal. But as any engineer may point out, we are not only interested in the answer - the margins are just as important. Thus control theory seeks to understand how systems responds to inputs. Then, we can take these theories and design controllers to achieve particular goals.</p>

<p>The design of a controller should strive to achieve the following:</p>

<ol>
  <li>Stable</li>
  <li>Tracking ‚Äì keeping y(t) close to command input</li>
  <li>Regulation ‚Äì keeping y(t) constant in the presence of disturbances</li>
  <li>Control Effort ‚Äì keeping u(t) to a minimum</li>
</ol>

<h3 id="modeling-systems-with-differential-equations">Modeling Systems with Differential Equations</h3>

<p>It goes without saying that highly complex systems are difficult to model, but that‚Äôs largely because of the number of interactions which exist. Depending on the system, a few common relationships are likely to be present:</p>

<ol>
  <li>State relationships - The interest you make on your savings is related to how much money you have saved (the state).</li>
  <li>Rate relationships - Aerodynamic drag increase with speed, making it a rate relationship.</li>
  <li>Acceleration relationships - Damping mechanisms are acceleration relationships, often used to counteract sudden changes.</li>
</ol>

<p>These relationships can be linear, exponential, logarithmic, etc.</p>

<h3 id="linear-first-and-second-order-systems">Linear First and Second Order Systems</h3>

<h4 id="first-order">First order</h4>

<p>Differential Equation</p>

\[b\frac{\partial x}{\partial t}+kx=0\]

<p>Transfer Function</p>

\[H(s)=\ \frac{a}{s+\sigma}\]

<p>Poles</p>

\[-\sigma\]

\[\sigma=\frac{k}{b}\]

<p>Impulse Response Curve</p>

\[x\left(t\right)=ae^{-t/\tau}\]

<dl>
  <dt>Time Constant</dt>
  <dd>A term defined only for first order systems, after œÑ seconds, only 37% of initial value remains</dd>
</dl>

\[\tau=\ 1/\sigma\]

<p>Step Response Curve</p>

\[y\left(t\right)=\frac{a}{\sigma}\left(1-e^{-t/\tau}\right)\]

<h4 id="second-order-systems">Second Order Systems</h4>

<p>Differential Equation</p>

\[m\frac{\partial^2x}{\partial t^2}+b\frac{\partial x}{\partial t}+kx=0\]

<p>Transfer Function</p>

\[H(s)=\ \frac{\omega_n^2}{s^2+2\zeta\omega_ns+\omega_n^2}\]

\[H(s)=\ \frac{\sigma^2+\omega^2}{(s+\sigma)^2+\omega^2}\]

<p>Poles</p>

\[-\sigma\pm j\omega\]

\[\sigma=\ \zeta\omega_n\]

\[\omega=\ \omega_n\sqrt{1-\zeta^2}\]

\[\omega_n=\sqrt{\frac{k}{m}}\]

\[\xi=\frac{b}{2\sqrt{km}}\]

<p>Impulse Response Curve</p>

\[x\left(t\right)=\ \frac{\omega_n}{\sqrt{1-\zeta^2}}e^{\frac{-\zeta}{\sqrt{1-\zeta^2}}\omega t}\sin{\omega t}\]

<p>Step Response Curve</p>

\[Mp=\ e^\frac{-\zeta\pi}{\sqrt{1-\zeta^2}}\]

\[Rise\ Time\ \tau_r\cong\ \frac{1.8}{\omega_n}\]

\[Settle\ Time\ \tau_s\cong\ \frac{4.6}{\sigma}\]

\[Peak\ Time\ \tau_p=\ \frac{\pi}{\omega}\\]

<h3 id="laplace-transform">Laplace Transform:</h3>
<p>Most important take away is that in the Laplace domain, derivation is represented by multiplication, while integration is represented by division.</p>

<p>\mathcal{L}\left(\dot{x}(t)\right)=sX(s)+x(0_+)</p>

<p>\mathcal{L}\left[\int_{0}^{t}x\left(t\right)dt\right]=\frac{X(s)}{s}</p>

<h3 id="final-value-theorem--initial-value-theorem">Final Value Theorem &amp; Initial Value Theorem:</h3>

<p>Where F(s) is the transfer function of the system defined by f(t).</p>

<p>f\left(\infty\right)=\ \lim\below{s\rightarrow0}{sF(s)}</p>

<p>f\left(0\right)=\ \lim\below{s\rightarrow\infty}{sF(s)}</p>

<h3 id="stability">Stability:</h3>

<dl>
  <dt>A system can be stable, unstable, or marginally stable. </dt>
  <dt>Stable</dt>
  <dd>All poles must be in the LHP
Marginally Stable</dd>
  <dd>There are no poles in the RHP</dd>
  <dd>There are poles on the imaginary axis</dd>
  <dd>Poles on the imaginary axis are non-repeated 
Unstable</dd>
  <dd>Any pole in the RHP makes a system unstable</dd>
</dl>

<blockquote>
  <p>Theorem: Given a system represented by a denominator in expanded form, it is not stable if any coefficients of sn are zero or negative.</p>
</blockquote>

<h3 id="undershoot">Undershoot</h3>
<p>Typical in non-minimum phase systems (defined as having a zero in the RHP).</p>

<h3 id="poles--zeros">Poles &amp; Zeros</h3>
<p>A pole is a value of s such that the denominator of the transfer function will be equal to zero. Meanwhile, a zero is defined as a value of s such that the numerator of the transfer function will be equal to zero.</p>

<h3 id="routh-stability-criterion">Routh Stability Criterion</h3>
<p>Number of sign changes is equal to the number of poles in the RHP.</p>

<blockquote>
  <p>IMPORTANT: Unstable pole/zero cancellation is not a valid method for achieving stability</p>
</blockquote>

<p>Feedback Control Systems:</p>

<p>CL Transfer Function Numerator</p>

<table>
  <tbody>
    <tr>
      <td>¬†</td>
      <td>R</td>
      <td>W</td>
      <td>V</td>
    </tr>
    <tr>
      <td>Y</td>
      <td>GD</td>
      <td>G</td>
      <td>-GD</td>
    </tr>
    <tr>
      <td>E</td>
      <td>1</td>
      <td>-G</td>
      <td>GD</td>
    </tr>
    <tr>
      <td>U</td>
      <td>D</td>
      <td>-GD</td>
      <td>-D</td>
    </tr>
  </tbody>
</table>

<p>Where the denominator is the same for all: 1+GD</p>

<h3 id="system-type">System Type</h3>
<p>A transfer function and the system it represents is said to be type k if a polynomial input of tk results in an output converging to a nonzero constant. In practice,</p>

\[H\left(s\right)\ is\ type\ K\ \Leftrightarrow\ H\left(s\right)\ has\ K\ zeros\ @\ origin\]

<p>For inputs of magnitude lower than k, output will converge to zero. For inputs of magnitude greater than k, output will diverge.</p>

<h3 id="steady-state-error">Steady State Error:</h3>
<p>In most cases, steady state error can be found by multiplying the E/R by R to yield E and applying the final value theorem. The below equations are simply shortcuts, that can be used by identifying the system type.</p>

\[Position\ Constant\ K_p=\ \lim\below{s\longrightarrow0}{L(s)}\]

\[Velocity\ Constant\ K_v=\ \lim\below{s\longrightarrow0}{sL\left(s\right)}\]

\[Acceleration\ Constant\ K_a=\ \lim\below{s\longrightarrow0}{s^2L(s)}\bigm\]

<h3 id="pid-control">PID Control:</h3>

<p>Classic and very fundamental method of controller. PID stands for proportional, integral, and derivative. Each serves a different purpose for maintaining stability.</p>

\[D\left(s\right)=\ K_P+\frac{K_I}{s}+sK_D\\]

\[H\left(s\right)=\ \frac{s}{as^3+\left(b+K_D\right)s^2+\left(c+K_P\right)s+K_I}\]

<table>
  <thead>
    <tr>
      <th>Increase</th>
      <th>Effect</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>\(K_P\)</td>
      <td>Faster Convergence</td>
    </tr>
    <tr>
      <td>¬†</td>
      <td>More oscillations for convergence</td>
    </tr>
    <tr>
      <td>¬†</td>
      <td>No effect on settling time</td>
    </tr>
    <tr>
      <td>\(K_D\)</td>
      <td>Faster convergence</td>
    </tr>
    <tr>
      <td>¬†</td>
      <td>Less oscillation</td>
    </tr>
    <tr>
      <td>\(K_I\)</td>
      <td>More oscillations</td>
    </tr>
    <tr>
      <td>¬†</td>
      <td>No steady state error</td>
    </tr>
  </tbody>
</table>

<h3 id="lead-lag-compensator">Lead-Lag Compensator</h3>

<p>Lead compensators improve transient response and is a variety of PD control, while lag compensators improve steady state response, and is a variety of PI control.</p>

\[Lead\ Compensator:\ D\left(s\right)=K\frac{\left(s-z\right)}{\left(s-p\right)}\ where\ z&lt;p\]

\[Lag\ Compensator:\ D\left(s\right)=K\frac{\left(s-z\right)}{\left(s-p\right)}\ where\ p&lt;z\]

\[\alpha=\ \frac{z}{p}\]

<h3 id="root-locus">Root Locus</h3>
<p>A root locus plot is defined as the plot of the roots of 1+KL(s) on the complex plane as K tends from -‚àû to +‚àû. When drawing a root locus, follow these rules:</p>

<p>Define: m zeroes and n poles.</p>

<ol>
  <li>The root locus is symmetric about the real axis</li>
  <li>The root locus starts from n poles of L(s). m branches approach m zeros of L(s). n-m branches go to infinity.</li>
  <li>The portion of the real axis to the left of an odd number of poles and zeroes is part of the root locus. (Plot the poles/zeroes of L(s) that are on the real axis and label them A, B, C from right to left. Then the segments, AB, CD, ‚Ä¶ are part of the root locus.)</li>
  <li>There are n-m branches of the root locus that approach the following asymptotes</li>
</ol>

\[s=\ \alpha+\sqrt[n-m]{K}e^{j\theta}\]

\[\alpha=\ \frac{\sum P-\sum Z}{n-m}\]

\[\theta=\ \frac{2l-1}{n-m}\pi\ \ \ \ \ \ l=arbitrary\ integer\]

<ol>
  <li>Departure angles measured from poles, arrival angles measured at zeros. q is the multiplicity of each pole/zero.</li>
</ol>

\[q\phi_K=\sum{\angle\left(p_k-z_i\right)-\sum{\angle\left(p_k-p_i\right)+\left(2l-1\right)\pi}}\\]

\[q\psi_K=\sum{\angle\left(z_k-p_i\right)-\sum{\angle\left(z_k-z_i\right)+(2l-1)\pi}}\]

<h3 id="bode-plots">Bode Plots</h3>

<p>Bode plots are simply plots of magnitude vs frequency and phase angle vs frequency.</p>

<h3 id="nyquist-plots">Nyquist Plots</h3>
<p>A Nyquist plot is L(jw) on the complex plane as frequency tends from minus infinity to positive infinity. Motivation for using Nyquist plots is that we can determine closed loop stability by examining the open loop (L(jw)). Can be sketched from the bode plots, or by mapping a plot of the range of frequencies.</p>

\[Z=P-N\]

<p>Where Z is the number of unstable closed loop poles. P is the number of unstable open loop poles, and N is the number of counterclockwise encirclements of -1.</p>

<h3 id="stability-margins">Stability Margins</h3>

\[\left|L\left(j\omega_c\right)\right|=1\]

\[\angle L\left(j\omega_p\right)=\ -180\]

\[Gain\ Margin=\ \frac{1}{\left|L\left(j\omega_p\right)\right|}\]

\[Phase\ Margin=\ \angle L\left(j\omega_c\right)+180\cong100\zeta\]

\[\omega_{c\ }\cong\frac{\omega_n}{1+\zeta^2}\]

<p>Where \(\omega_c\) is defined as the gain crossover frequency and \(\omega_p\) is defined to be the phase crossover frequency. On a Nyquist plot, gain crossover frequency is when the graph crosses a circle of radius 1, and phase crossover is when the it crosses the negative real axis. Gain margin is the maximum factor which gain can be increased without making CLS unstable. Phase margin is the maximum angle by which phase can be decreased without making CLS unstable.</p>

:ET