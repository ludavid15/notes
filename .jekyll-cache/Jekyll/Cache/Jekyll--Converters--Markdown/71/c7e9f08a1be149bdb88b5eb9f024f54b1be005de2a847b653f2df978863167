I"Æ<p>Although there are many interpretations of Bayes Theorem, letâ€™s start with this one: Bayes Theory gives us a way to update a prediction based on observation of new evidence.</p>

<!--more-->

<h3 id="basic-mathematical-statement">Basic Mathematical Statement</h3>

<p>The probability of A given B, is equal to the probability of B given A, times the probability of A, divided by the probability of B.</p>

\[P(A|B) = \frac{P(B|A)P(A)}{P(B)}\]

<table>
  <thead>
    <tr>
      <th>The Prior Probability</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>P(A)</td>
    </tr>
    <tr>
      <td>I think of this like the original estimate. This is what we are going to be updating, when we take into account new information about how B relates to A.</td>
    </tr>
  </tbody>
</table>

<table>
  <thead>
    <tr>
      <th>The Posterior Probability</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>P(A|B)</td>
    </tr>
    <tr>
      <td>This is what we are solving for. In the absense of observed data, we would be solving for P(A). But if we have some observation B, now we can solve for a conditional probability, i.e. the probability of A given B.</td>
    </tr>
  </tbody>
</table>

<table>
  <thead>
    <tr>
      <th>The Likelihood</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>P(B|A)</td>
    </tr>
    <tr>
      <td>This term is called the liklihood because it is equal to the liklihood of A given a fixed B.</td>
    </tr>
  </tbody>
</table>

:ET